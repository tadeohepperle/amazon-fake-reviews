{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "CUDA_LAUNCH_BLOCKING=1"
      ],
      "metadata": {
        "id": "nXTkNDCVbpjA"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCMpCNKVccFg",
        "outputId": "1392ad92-c143-453f-e8ec-0319850ea9b9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install binclass-tools"
      ],
      "metadata": {
        "id": "4KivRX-yC0Q0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "R5EIgqmDcEUi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import typing\n",
        "import transformers\n",
        "from transformers import TFAutoModel, AutoTokenizer, BertTokenizer, AutoConfig, BertModel\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My Drive/FintechDS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsj3kKyIc-6a",
        "outputId": "eea06358-04d5-4d3e-fefe-a8d95aa88037"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/FintechDS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load data"
      ],
      "metadata": {
        "id": "0kOOrYFbj2YW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "g2DpCBqccEUn"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\n",
        "    \"data/transformed/df.csv\",\n",
        "    dtype={\n",
        "        \"product_title\": str,\n",
        "        \"review_title\": str,\n",
        "        \"review_text\": str,\n",
        "        \"product_id\": str,\n",
        "    },\n",
        ")\n",
        "reviews_scraped = pd.read_csv(\n",
        "    \"data/transformed/reviews_scraped.csv\",\n",
        "    dtype={\"review_title\": str, \"review_text\": str, \"product_id\": str},\n",
        ")\n",
        "\n",
        "reviews_scraped.fillna(0,inplace= True)\n",
        "df.fillna(0,inplace=True)\n",
        "df = df[0:8000]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJS9orGf8khl",
        "outputId": "7013434b-effc-43d0-a263-12fca1130267"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'rating', 'verified', 'PRODUCT_CATEGORY', 'product_id',\n",
              "       'review_title', 'review_text', 'cat_0', 'cat_1', 'cat_2', 'cat_3',\n",
              "       'cat_4', 'cat_5', 'cat_6', 'cat_7', 'cat_8', 'cat_9', 'cat_10',\n",
              "       'cat_11', 'cat_12', 'cat_13', 'cat_14', 'cat_15', 'cat_16', 'cat_17',\n",
              "       'cat_18', 'cat_19', 'cat_20', 'cat_21', 'cat_22', 'cat_23', 'cat_24',\n",
              "       'cat_25', 'cat_26', 'cat_27', 'cat_28', 'cat_29', 'label',\n",
              "       'text_sentiment', 'text_subjectivity', 'rating_count', 'rating_avg',\n",
              "       'rating1', 'rating2', 'rating3', 'rating4', 'rating5', 'product_title'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reviews_scraped.columns "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eR_UJsd-8mre",
        "outputId": "67cb5d18-7295-4201-ef70-42736f5e32a3"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'product_id', 'review_title', 'rating_count',\n",
              "       'rating_avg', 'rating1', 'rating2', 'rating3', 'rating4', 'rating5',\n",
              "       'helpful', 'verified', 'review_text', 'rating', 'text_sentiment',\n",
              "       'text_subjectivity'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAGcO0hbcEUu"
      },
      "source": [
        "### Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "id": "1nSr7Y6-cEUw"
      },
      "outputs": [],
      "source": [
        "BERT_TOKENIZER_LENGTH: int = 256\n",
        "BERT_EMBEDDING_SIZE : int = 768\n",
        "DEVICE :torch.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "BERT_TOKENIZER = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "BERT_CONFIG, _ = AutoConfig.from_pretrained('bert-base-uncased', output_attention=True, return_unused_kwargs=True)\n",
        "SCRAPED_REVIEW_LIMIT = 10\n",
        "BATCH_SIZE=256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJPsdMIqcEUx"
      },
      "source": [
        "### Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "wIqU78JOcEUy"
      },
      "outputs": [],
      "source": [
        "from typing import TypedDict\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from dataclasses import dataclass\n",
        "\n",
        "\n",
        "class BertInput(TypedDict):\n",
        "    attention_mask: torch.Tensor\n",
        "    \"\"\"shape: (1,MAX_SEQUENCE_LENGTH_BERT_TOKENIZER)\"\"\"\n",
        "    input_ids: torch.Tensor\n",
        "    \"\"\"shape: (1,MAX_SEQUENCE_LENGTH_BERT_TOKENIZER)\"\"\"\n",
        "\n",
        "\n",
        "class BertInputBatch:\n",
        "    def __init__(self, attention_mask: torch.Tensor, input_ids: torch.Tensor) -> None:\n",
        "        self.attention_mask = attention_mask\n",
        "        self.input_ids = input_ids\n",
        "\n",
        "    @staticmethod\n",
        "    def from_batch_encoding(\n",
        "        batch_encoding: transformers.tokenization_utils_base.BatchEncoding,\n",
        "    ):\n",
        "        return BertInputBatch(\n",
        "            torch.tensor(batch_encoding[\"attention_mask\"]).to(DEVICE),\n",
        "            torch.tensor(batch_encoding[\"input_ids\"]).to(DEVICE),\n",
        "        )\n",
        "\n",
        "    attention_mask: torch.Tensor\n",
        "    input_ids: torch.Tensor\n",
        "\n",
        "    @property\n",
        "    def shape(self) -> torch.Size:\n",
        "        return self.input_ids.shape\n",
        "\n",
        "    def __getitem__(self, i: int) -> BertInput:\n",
        "        return {\n",
        "            \"attention_mask\": self.attention_mask[i : i + 1, :],\n",
        "            \"input_ids\": self.input_ids[i : i + 1, :],\n",
        "        }\n",
        "\n",
        "\n",
        "# class ReviewDataSetItemInput(TypedDict):\n",
        "#     \"\"\"one fake/real review with X context reviews from the same product\"\"\"\n",
        "\n",
        "#     product_title_bert_input: BertInput\n",
        "#     review_title_bert_input: BertInput\n",
        "#     review_text_bert_input: BertInput\n",
        "\n",
        "#     review_features: torch.Tensor\n",
        "#     \"\"\"shape: (4)    Rating [1-5; 1] + Verified Purchase [0-1; 1] + SA Valence + Subjectivity [0.0-1.0; 2]\"\"\"\n",
        "\n",
        "#     product_features: torch.Tensor\n",
        "#     \"\"\"shape: (37)    Ratings (1-5) Ratio [0.0-1.0]; 5] + Rating Avg [f64; 1] + Rating Count [u64; 1] + Category [u64; 30]\"\"\"\n",
        "\n",
        "#     scraped_review_features: torch.Tensor\n",
        "#     \"\"\"shape: (X, 4)    Rating [1-5; 1] + Verified Purchase [0-1; 1] + SA Valence + Subjectivity [0.0-1.0; 2]\"\"\"\n",
        "\n",
        "#     scraped_helpful: torch.Tensor\n",
        "#     \"\"\"shape: (X, 1)    Helpfulness [u64; 1]\"\"\"\n",
        "\n",
        "#     scraped_review_texts: BertInputBatch\n",
        "\n",
        "#     scraped_review_titles: BertInputBatch\n",
        "\n",
        "PACKED_DATASET_ROW_SIZE = 37 + 4 + 6 * BERT_TOKENIZER_LENGTH + SCRAPED_REVIEW_LIMIT * (1 + 4 + 4 * BERT_TOKENIZER_LENGTH)\n",
        "\n",
        "class ReviewsDataSet(Dataset):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        df: pd.DataFrame of size M with columns:\n",
        "            - rating (1-5)\n",
        "            - verified (0-1)\n",
        "            - product_id (str)\n",
        "            - review_title (str)\n",
        "            - review_text (str)\n",
        "            - cat_0 - cat_29 (0-1)\n",
        "            - label (0-1)\n",
        "            - text_sentiment (0.0-1.0)\n",
        "            - text_subjectivity (0.0-1.0)\n",
        "            - rating_count (u64)\n",
        "            - rating_avg (1.0-5.0)\n",
        "            - rating1 - rating5  (0.0-1.0)\n",
        "            - product_title (str)\n",
        "\n",
        "        reviews_scraped:  pd.DataFrame of size N with columns:\n",
        "            - product_id (str)\n",
        "            - review_title (str)\n",
        "            - review_text (str)\n",
        "            - helpful (u64)\n",
        "            - verified (0-1)\n",
        "            - rating (1-5)\n",
        "            - text_sentiment (0.0-1.0)\n",
        "            - text_subjectivity (0.0-1.0)\n",
        "    \"\"\"\n",
        "\n",
        "    df: pd.DataFrame\n",
        "    reviews_scraped: pd.DataFrame\n",
        "\n",
        "    df_product_title_encoded: BertInputBatch\n",
        "    \"\"\"shape: (N, MAX_SEQUENCE_LENGTH_BERT_TOKENIZER)\"\"\"\n",
        "\n",
        "    df_review_title_encoded: BertInputBatch\n",
        "    \"\"\"shape: (N, MAX_SEQUENCE_LENGTH_BERT_TOKENIZER)\"\"\"\n",
        "\n",
        "    df_review_text_encoded: BertInputBatch\n",
        "    \"\"\"shape: (N, MAX_SEQUENCE_LENGTH_BERT_TOKENIZER)\"\"\"\n",
        "\n",
        "    review_feature_vector: torch.Tensor\n",
        "    \"\"\"shape: (N, 4)    Rating [1-5; 1] + Verified Purchase [0-1; 1] + SA Valence + Subjectivity [0.0-1.0; 2]\"\"\"\n",
        "\n",
        "    product_feature_vector: torch.Tensor\n",
        "    \"\"\"shape: (N, 37)    Ratings (1-5) Ratio [0.0-1.0]; 5] + Rating Avg [f64; 1] + Rating Count [u64; 1] + Category [u64; 30]\"\"\"\n",
        "\n",
        "    label_vector: torch.Tensor\n",
        "    \"\"\"shape: (N, 1) \"\"\"\n",
        "\n",
        "    scraped_review_feature_vector: torch.Tensor\n",
        "    \"\"\"shape: (M, 4)    Rating [1-5; 1] + Verified Purchase [0-1; 1] + SA Valence + Subjectivity [0.0-1.0; 2]\"\"\"\n",
        "\n",
        "    scraped_review_helpful: torch.Tensor\n",
        "    \"\"\"shape: (M, 1)    Helpfulness [u64; 1]\"\"\"\n",
        "\n",
        "    scraped_review_title_encoded: BertInputBatch\n",
        "    \"\"\"shape: (M, MAX_SEQUENCE_LENGTH_BERT_TOKENIZER)\"\"\"\n",
        "\n",
        "    scraped_review_text_encoded: BertInputBatch\n",
        "    \"\"\"shape: (M, MAX_SEQUENCE_LENGTH_BERT_TOKENIZER)\"\"\"\n",
        "\n",
        "    # product_id_indexes_map: dict[str, list[int]]\n",
        "    # \"\"\"For each product, maps the product id to the int indices for all scraped context reviews for this product\"\"\"\n",
        "\n",
        "    def __init__(self, df, reviews_scraped):\n",
        "\n",
        "        self.df = df\n",
        "        self.reviews_scraped = reviews_scraped\n",
        "        M = reviews_scraped.__len__()\n",
        "        N = df.__len__()\n",
        "\n",
        "        # use bert tokenizer to tokenize all strings of the\n",
        "        print(\n",
        "            f\"creating ReviewsDataSet (real/fake reviews: N={len(df)}, context reviews: M={len(reviews_scraped)}\"\n",
        "        )\n",
        "        print(f\"    bert tokeinzer working...\")\n",
        "\n",
        "        def bert_input_batch_tokenize(\n",
        "            #list_of_strings: list[str],\n",
        "            list_of_strings: list,\n",
        "        ) -> BertInputBatch:\n",
        "            list_of_strings = [str(e) for e in list_of_strings]\n",
        "            return BertInputBatch.from_batch_encoding(\n",
        "                BERT_TOKENIZER.batch_encode_plus(\n",
        "                    list_of_strings,\n",
        "                    max_length=BERT_TOKENIZER_LENGTH,\n",
        "                    pad_to_max_length=True,\n",
        "                    truncation=True,\n",
        "                    return_token_type_ids=False,\n",
        "                )\n",
        "            )\n",
        "\n",
        "        print(f\"    creating df_product_title_encoded...\")\n",
        "        self.df_product_title_encoded = bert_input_batch_tokenize(\n",
        "            df[\"product_title\"].tolist()\n",
        "        )\n",
        "\n",
        "        print(f\"    creating df_review_title_encoded...\")\n",
        "        self.df_review_title_encoded = bert_input_batch_tokenize(\n",
        "            df[\"review_title\"].tolist()\n",
        "        )\n",
        "\n",
        "        print(f\"    creating df_review_text_encoded...\")\n",
        "        self.df_review_text_encoded = bert_input_batch_tokenize(\n",
        "            df[\"review_text\"].tolist()\n",
        "        )\n",
        "\n",
        "        print(f\"    creating scraped_review_title_encoded...\")\n",
        "        self.scraped_review_title_encoded = bert_input_batch_tokenize(\n",
        "            reviews_scraped[\"review_title\"].tolist()\n",
        "        )\n",
        "\n",
        "        print(f\"    creating scraped_review_text_encoded...\")\n",
        "        self.scraped_review_text_encoded = bert_input_batch_tokenize(\n",
        "            reviews_scraped[\"review_text\"].tolist()\n",
        "        )\n",
        "\n",
        "        review_feature_cols = [\n",
        "            \"rating\",\n",
        "            \"verified\",\n",
        "            \"text_sentiment\",\n",
        "            \"text_subjectivity\",\n",
        "        ]\n",
        "        self.review_feature_vector = torch.tensor(df[review_feature_cols].to_numpy()).float().to(DEVICE)\n",
        "        self.label_vector = torch.tensor(df[[\"label\"]].to_numpy()).float().to(DEVICE)\n",
        "        self.scraped_review_feature_vector = torch.tensor(\n",
        "            reviews_scraped[review_feature_cols].to_numpy()\n",
        "        ).float().to(DEVICE)\n",
        "        self.scraped_review_helpful = torch.reshape(\n",
        "            torch.tensor(reviews_scraped[\"helpful\"].to_numpy()).float(), (M, 1)\n",
        "        ).to(DEVICE)\n",
        "\n",
        "        product_feature_cols = [\n",
        "            \"rating_count\",\n",
        "            \"rating_avg\",\n",
        "            \"rating1\",\n",
        "            \"rating2\",\n",
        "            \"rating3\",\n",
        "            \"rating4\",\n",
        "            \"rating5\",\n",
        "        ] + [f\"cat_{i}\" for i in range(0, 30)]\n",
        "        self.product_feature_vector = torch.tensor(df[product_feature_cols].to_numpy()).float().to(DEVICE)\n",
        "\n",
        "    #def __getitem__(self, index) -> tuple[torch.Tensor, torch.Tensor]:\n",
        "    def __getitem__(self, index):\n",
        "        product_id = self.df.loc[index, \"product_id\"]\n",
        "\n",
        "        # get indexes in scraped data where product id is the same\n",
        "        indices = torch.tensor(\n",
        "            reviews_scraped.index[\n",
        "                reviews_scraped[\"product_id\"] == product_id\n",
        "            ].to_numpy()\n",
        "        ).int().to(DEVICE)\n",
        "\n",
        "        def slice(tensor: torch.Tensor) -> torch.Tensor:\n",
        "            \"\"\"selects only the subset where index indicates product id is the same\"\"\"\n",
        "            return torch.index_select(tensor, 0, indices)\n",
        "\n",
        "        def zero_pad_ravel(tensor: torch.Tensor, X) -> torch.Tensor:\n",
        "            \"\"\"takes in a tensor of shape (N,D) appends zero elements or removes elements from the end to create an (X,D) shaped tensor and then reshapes that into a (X*D) shaped tensor\"\"\"\n",
        "            (N, D) = tensor.shape\n",
        "            return torch.reshape(\n",
        "                torch.nn.functional.pad(\n",
        "                    input=tensor[0:X, :],\n",
        "                    pad=(0, 0, 0, max(X - N, 0)),\n",
        "                    mode=\"constant\",\n",
        "                    value=0,\n",
        "                ),\n",
        "                (-1,),\n",
        "            )\n",
        "\n",
        "        # slice the tensors of relevant scraped reviews out of the total reviews:\n",
        "        scraped_helpful = slice(self.scraped_review_helpful)\n",
        "        _N = scraped_helpful.shape[0]  # is N\n",
        "        assert scraped_helpful.shape == (_N, 1)\n",
        "\n",
        "        scraped_review_features = slice(self.scraped_review_feature_vector)\n",
        "        assert scraped_review_features.shape == (_N, 4)\n",
        "\n",
        "        scraped_review_texts_att = slice(\n",
        "            self.scraped_review_text_encoded.attention_mask\n",
        "        )\n",
        "\n",
        "        assert scraped_review_texts_att.shape == (_N, BERT_TOKENIZER_LENGTH)\n",
        "\n",
        "        scraped_review_texts_ids = slice(self.scraped_review_text_encoded.input_ids)\n",
        "        assert scraped_review_texts_ids.shape == (_N, BERT_TOKENIZER_LENGTH)\n",
        "\n",
        "        scraped_review_titles_att = slice(\n",
        "            self.scraped_review_title_encoded.attention_mask\n",
        "        )\n",
        "        assert scraped_review_titles_att.shape == (_N, BERT_TOKENIZER_LENGTH)\n",
        "\n",
        "        scraped_review_titles_ids = slice(self.scraped_review_title_encoded.input_ids)\n",
        "        assert scraped_review_titles_ids.shape == (_N, BERT_TOKENIZER_LENGTH)\n",
        "\n",
        "        # combine all review data into a (X,) shaped tensor:\n",
        "        scraped_block = torch.cat(\n",
        "            (\n",
        "                scraped_helpful,\n",
        "                scraped_review_features,\n",
        "                scraped_review_texts_att,\n",
        "                scraped_review_texts_ids,\n",
        "                scraped_review_titles_att,\n",
        "                scraped_review_titles_ids,\n",
        "            ),\n",
        "            dim=1,\n",
        "        )\n",
        "        scraped_block_flat = zero_pad_ravel(scraped_block, SCRAPED_REVIEW_LIMIT)\n",
        "        assert scraped_block_flat.shape == (\n",
        "            SCRAPED_REVIEW_LIMIT * (1 + 4 + 4 * BERT_TOKENIZER_LENGTH),\n",
        "        )\n",
        "\n",
        "        product_title_bert_input_att = self.df_product_title_encoded[index][\n",
        "            \"attention_mask\"\n",
        "        ][0, :]\n",
        "        assert product_title_bert_input_att.shape == (BERT_TOKENIZER_LENGTH,)\n",
        "        product_title_bert_input_ids = self.df_product_title_encoded[index][\n",
        "            \"input_ids\"\n",
        "        ][0, :]\n",
        "        assert product_title_bert_input_ids.shape == (BERT_TOKENIZER_LENGTH,)\n",
        "        review_title_bert_input_att = self.df_review_title_encoded[index][\n",
        "            \"attention_mask\"\n",
        "        ][0, :]\n",
        "        assert review_title_bert_input_att.shape == (BERT_TOKENIZER_LENGTH,)\n",
        "        review_title_bert_input_ids = self.df_review_title_encoded[index][\"input_ids\"][\n",
        "            0, :\n",
        "        ]\n",
        "        assert review_title_bert_input_ids.shape == (BERT_TOKENIZER_LENGTH,)\n",
        "        review_text_bert_input_att = self.df_review_text_encoded[index][\n",
        "            \"attention_mask\"\n",
        "        ][0, :]\n",
        "        assert review_text_bert_input_att.shape == (BERT_TOKENIZER_LENGTH,)\n",
        "        review_text_bert_input_ids = self.df_review_text_encoded[index][\"input_ids\"][\n",
        "            0, :\n",
        "        ]\n",
        "        assert review_text_bert_input_ids.shape == (BERT_TOKENIZER_LENGTH,)\n",
        "\n",
        "        product_features = self.product_feature_vector[index]  # shape: (37)\n",
        "        assert product_features.shape == (37,)\n",
        "\n",
        "        review_features = self.review_feature_vector[index]  # shape: (4)\n",
        "        assert review_features.shape == (4,)\n",
        "\n",
        "        catted = torch.cat(\n",
        "            (\n",
        "                product_features,\n",
        "                review_features,\n",
        "                product_title_bert_input_att,\n",
        "                product_title_bert_input_ids,\n",
        "                review_title_bert_input_att,\n",
        "                review_title_bert_input_ids,\n",
        "                review_text_bert_input_att,\n",
        "                review_text_bert_input_ids,\n",
        "                scraped_block_flat,\n",
        "            ),\n",
        "            dim=0,\n",
        "        )\n",
        "        assert catted.shape == (PACKED_DATASET_ROW_SIZE,)\n",
        "        ##############################################################\n",
        "        ## Data layout in the catted tensor row, assuming BERT_TOKENIZER_LENGTH = 256 and SCRAPED_REVIEW_LIMIT = 10\n",
        "        ## | 37 | 4 | 256+256 | 256+256 | 256+256 | 10 * ( | 1 | 4 | 256+256 | 256+256 |)\n",
        "\n",
        "        label = self.label_vector[index]\n",
        "        return (catted, label)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return self.df.__len__()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaN9_42rcEU3"
      },
      "source": [
        "#### unpacking functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "id": "R7vexK9GcEU5"
      },
      "outputs": [],
      "source": [
        "def unpack_dataset_items(packed_batch_tensor: torch.Tensor):\n",
        "    \"\"\"\n",
        "    expects packed_batch_tensor to be of shape\n",
        "    \"\"\"\n",
        "    assert packed_batch_tensor.shape[1] == PACKED_DATASET_ROW_SIZE\n",
        "    (B, T) = packed_batch_tensor.shape\n",
        "\n",
        "    c: int = 0\n",
        "\n",
        "    def next(n: int) -> torch.Tensor:\n",
        "        nonlocal c\n",
        "        slice = packed_batch_tensor[:, c : c + n]\n",
        "        c += n\n",
        "        return slice\n",
        "\n",
        "    product_features = next(37)\n",
        "    assert product_features.shape == (B, 37)\n",
        "\n",
        "    review_features = next(4)\n",
        "    assert review_features.shape == (B, 4)\n",
        "\n",
        "    product_title_bert_input_att = next(BERT_TOKENIZER_LENGTH)\n",
        "    product_title_bert_input_ids = next(BERT_TOKENIZER_LENGTH)\n",
        "    review_title_bert_input_att = next(BERT_TOKENIZER_LENGTH)\n",
        "    review_title_bert_input_ids = next(BERT_TOKENIZER_LENGTH)\n",
        "    review_text_bert_input_att = next(BERT_TOKENIZER_LENGTH)\n",
        "    review_text_bert_input_ids = next(BERT_TOKENIZER_LENGTH)\n",
        "    assert (\n",
        "        product_title_bert_input_att.shape\n",
        "        == product_title_bert_input_ids.shape\n",
        "        == review_title_bert_input_att.shape\n",
        "        == review_title_bert_input_ids.shape\n",
        "        == review_text_bert_input_att.shape\n",
        "        == review_text_bert_input_ids.shape\n",
        "        == (B, BERT_TOKENIZER_LENGTH)\n",
        "    )\n",
        "\n",
        "    _scraped_block_flat = next(\n",
        "        SCRAPED_REVIEW_LIMIT * (1 + 4 + 4 * BERT_TOKENIZER_LENGTH)\n",
        "    )\n",
        "    assert _scraped_block_flat.shape == (\n",
        "        B,\n",
        "        SCRAPED_REVIEW_LIMIT * (1 + 4 + 4 * BERT_TOKENIZER_LENGTH),\n",
        "    )\n",
        "\n",
        "    scraped_block = torch.reshape(\n",
        "        _scraped_block_flat,\n",
        "        (B, SCRAPED_REVIEW_LIMIT, (1 + 4 + 4 * BERT_TOKENIZER_LENGTH)),\n",
        "    )\n",
        "    assert scraped_block.shape == (\n",
        "        B,\n",
        "        SCRAPED_REVIEW_LIMIT,\n",
        "        (1 + 4 + 4 * BERT_TOKENIZER_LENGTH),\n",
        "    )\n",
        "\n",
        "    scraped_helpful = scraped_block[:, :, 0:1]\n",
        "    assert scraped_helpful.shape == (B, SCRAPED_REVIEW_LIMIT, 1)\n",
        "\n",
        "    scraped_review_features = scraped_block[:, :, 1:5]\n",
        "    assert scraped_review_features.shape == (B, SCRAPED_REVIEW_LIMIT, 4)\n",
        "\n",
        "    scraped_review_title_bert_input_att = scraped_block[\n",
        "        :, :, 5 : 5 + BERT_TOKENIZER_LENGTH\n",
        "    ]\n",
        "    scraped_review_title_bert_input_ids = scraped_block[\n",
        "        :, :, 5 + BERT_TOKENIZER_LENGTH : 5 + 2 * BERT_TOKENIZER_LENGTH\n",
        "    ]\n",
        "    scraped_review_text_bert_input_att = scraped_block[\n",
        "        :, :, 5 + 2 * BERT_TOKENIZER_LENGTH : 5 + 3 * BERT_TOKENIZER_LENGTH\n",
        "    ]\n",
        "    scraped_review_text_bert_input_ids = scraped_block[\n",
        "        :, :, 5 + 3 * BERT_TOKENIZER_LENGTH : 5 + 4 * BERT_TOKENIZER_LENGTH\n",
        "    ]\n",
        "\n",
        "    return (\n",
        "        product_features,\n",
        "        review_features,\n",
        "        product_title_bert_input_att,\n",
        "        product_title_bert_input_ids,\n",
        "        review_title_bert_input_att,\n",
        "        review_title_bert_input_ids,\n",
        "        review_text_bert_input_att,\n",
        "        review_text_bert_input_ids,\n",
        "        (\n",
        "            scraped_helpful,\n",
        "            scraped_review_features,\n",
        "            scraped_review_title_bert_input_att,\n",
        "            scraped_review_title_bert_input_ids,\n",
        "            scraped_review_text_bert_input_att,\n",
        "            scraped_review_text_bert_input_ids,\n",
        "        ),\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuvMo8wicEU7"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "id": "FMnZowjDcEU8"
      },
      "outputs": [],
      "source": [
        "from collections import OrderedDict\n",
        "import torch.nn as nn\n",
        "#def create_mlp(layer_sizes: list[int]) -> nn.Sequential:\n",
        "def create_mlp(layer_sizes: list):\n",
        "    \"\"\"\n",
        "    creates an MLP with the given layer_sizes. The first element is the input size, the last one the output size\n",
        "    args:\n",
        "        layer_sizes: [input_dim, h1_dim, h2_dim, ...., out_dim]\"\"\"\n",
        "    assert layer_sizes.__len__() >= 2\n",
        "        \n",
        "    layers = []\n",
        "    for i in range(1, layer_sizes.__len__()):\n",
        "        layers.append((f\"hidden_layer_{i}\",nn.Linear(layer_sizes[i-1], layer_sizes[i]) ))\n",
        "        layers.append((f\"activation_{i}\",  nn.ReLU()))\n",
        "    return nn.Sequential(OrderedDict(layers))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "id": "pbDVbiKEcEU-"
      },
      "outputs": [],
      "source": [
        "class ReviewEncodingModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, freeze: bool = True, outdim=500) -> None:\n",
        "        super(ReviewEncodingModel, self).__init__()\n",
        "        self.bert = BertModel(BERT_CONFIG)\n",
        "        if freeze:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "        self.out_mlp = create_mlp([BERT_EMBEDDING_SIZE*2+4, outdim])\n",
        "    \n",
        "    def forward(self, review_features: torch.Tensor, \n",
        "               review_title_bert_input_att: torch.Tensor,\n",
        "               review_title_bert_input_ids: torch.Tensor,\n",
        "               review_text_bert_input_att: torch.Tensor,\n",
        "               review_text_bert_input_ids: torch.Tensor, ) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        args:\n",
        "            review_features: shape: (BATCH_SIZE, 5)\n",
        "            review_title_bert_input_att: shape: (BATCH_SIZE, BERT_TOKENIZER_LENGTH)\n",
        "            review_title_bert_input_ids: shape: (BATCH_SIZE, BERT_TOKENIZER_LENGTH)\n",
        "            review_text_bert_input_att: shape: (BATCH_SIZE, BERT_TOKENIZER_LENGTH)\n",
        "            review_text_bert_input_ids: shape: (BATCH_SIZE, BERT_TOKENIZER_LENGTH)\n",
        "        returns:\n",
        "            torch.Tensor of shape (BATCH_SIZE, OUTDIM)\n",
        "        \"\"\"\n",
        "\n",
        "        # max over all tokens in every dimension of the 768 dimensional embedding\n",
        "      \n",
        "        bert_title_embedding = self.bert(attention_mask=review_title_bert_input_att.int(), input_ids=review_title_bert_input_ids.int()).last_hidden_state[:,0,:]\n",
        "        assert bert_title_embedding.shape == (BATCH_SIZE, BERT_EMBEDDING_SIZE)\n",
        "\n",
        "        # max over all tokens in every dimension of the 768 dimensional embedding\n",
        "        bert_text_embedding = self.bert(attention_mask=review_text_bert_input_att.int(), input_ids=review_text_bert_input_ids.int()).last_hidden_state[:,0,:]\n",
        "        assert bert_title_embedding.shape == (BATCH_SIZE, BERT_EMBEDDING_SIZE)\n",
        "\n",
        "        # concat all on top of each other:\n",
        "        catted = torch.cat([bert_title_embedding, bert_text_embedding, review_features], dim=1)\n",
        "\n",
        "        # apply linear layer and relu:\n",
        "        return self.out_mlp(catted)\n",
        "\n",
        "        \n",
        "    def freeze_bert(self, freezed: bool) -> None:\n",
        "        for param in self.bert.parameters():\n",
        "                param.requires_grad =  not freezed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fake Detection Model"
      ],
      "metadata": {
        "id": "qNhRK1ra-SSD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "id": "6doON378cEVB"
      },
      "outputs": [],
      "source": [
        "REVIEW_ENCODING_MODEL_OUTDIM = 149\n",
        "# REVIEW_ENCODING_MODEL_OUTDIM + 1 has to be divisible by 3 for this to work, bc. we use 3 attention heads\n",
        "\n",
        "class FakeDetectionModel(torch.nn.Module):\n",
        "    review_encoding_model: ReviewEncodingModel\n",
        "    scraped_reviews_transformer: torch.nn.TransformerEncoderLayer\n",
        "    outmlp: nn.Sequential\n",
        "\n",
        "    def __init__(self):\n",
        "        super(FakeDetectionModel, self).__init__()\n",
        "        self.review_encoding_model: ReviewEncodingModel = ReviewEncodingModel(\n",
        "            freeze=True, outdim=REVIEW_ENCODING_MODEL_OUTDIM\n",
        "        )\n",
        "        self.scraped_reviews_transformer = torch.nn.TransformerEncoderLayer(\n",
        "            d_model=REVIEW_ENCODING_MODEL_OUTDIM+1, nhead=15, batch_first=True\n",
        "        )\n",
        "\n",
        "        LAST_FEATURES_DIM = 37 + (REVIEW_ENCODING_MODEL_OUTDIM + 1) + REVIEW_ENCODING_MODEL_OUTDIM +  BERT_EMBEDDING_SIZE\n",
        "        # LAST_FEATURES_DIM: product features + transformer output dimension + review encoded + bert embedding from product title\n",
        "        self.outmlp = create_mlp([LAST_FEATURES_DIM, 30, 20, 1])\n",
        "\n",
        "    def forward(self, packed_dataset_rows: torch.Tensor)-> torch.Tensor :\n",
        "        \"\"\" \"\n",
        "        args:\n",
        "            packed_dataset_row: torch.Tensor with shape (BATCH_SIZE, PACKED_DATASET_ROW_SIZE)\n",
        "        returns:\n",
        "            torch.Tensor with shape: (BATCH_SIZE,1)\n",
        "        \"\"\"\n",
        "        #print(\"packed_dataset_rows.shape\",packed_dataset_rows.shape )\n",
        "        #print(\"BATCH_SIZE, PACKED_DATASET_ROW_SIZE\", BATCH_SIZE, PACKED_DATASET_ROW_SIZE)\n",
        "\n",
        "\n",
        "        assert packed_dataset_rows.shape == (BATCH_SIZE, PACKED_DATASET_ROW_SIZE)\n",
        "        (\n",
        "            product_features,\n",
        "            review_features,\n",
        "            product_title_bert_input_att,\n",
        "            product_title_bert_input_ids,\n",
        "            review_title_bert_input_att,\n",
        "            review_title_bert_input_ids,\n",
        "            review_text_bert_input_att,\n",
        "            review_text_bert_input_ids,\n",
        "            (\n",
        "                scraped_helpful,\n",
        "                scraped_review_features,\n",
        "                scraped_review_title_bert_input_att,\n",
        "                scraped_review_title_bert_input_ids,\n",
        "                scraped_review_text_bert_input_att,\n",
        "                scraped_review_text_bert_input_ids,\n",
        "            ),\n",
        "        ) = unpack_dataset_items(packed_dataset_rows)\n",
        "\n",
        "        ### CREATE REVIEW ENCODING\n",
        "        review_encoding = self.review_encoding_model(review_features, review_title_bert_input_att, review_title_bert_input_ids, review_text_bert_input_att, review_text_bert_input_ids)  # type: ignore\n",
        "        \n",
        "        assert review_encoding.shape == (BATCH_SIZE, REVIEW_ENCODING_MODEL_OUTDIM)\n",
        "\n",
        "        ### CREATE REVIEW ENCODINGS FOR ALL SCRAPED REVIEWS\n",
        "        ### THEN COMBINE THEM AND THEIR HELPFULNESS VIA THE TRANSFORMER\n",
        "\n",
        "        # transform (BATCH_SIZE, SCRAPED_REVIEW_LIMIT, 5 + 4 * BERT_TOKENIZER_LENGTH) into (BATCH_SIZE, SCRAPED_REVIEW_LIMIT, REVIEW_ENCODING_MODEL_OUTDIM)\n",
        "        transformer_input = torch.zeros(\n",
        "            (BATCH_SIZE, SCRAPED_REVIEW_LIMIT, 1 + REVIEW_ENCODING_MODEL_OUTDIM)\n",
        "        ).to(DEVICE)\n",
        "        for i in range(SCRAPED_REVIEW_LIMIT):\n",
        "            transformer_input[:, i, :] = torch.cat(\n",
        "            [self.review_encoding_model(\n",
        "                scraped_review_features[:, i, :],\n",
        "                scraped_review_title_bert_input_att[:, i, :],\n",
        "                scraped_review_title_bert_input_ids[:, i, :],\n",
        "                scraped_review_text_bert_input_att[:, i, :],\n",
        "                scraped_review_text_bert_input_ids[:, i, :],\n",
        "            ), scraped_helpful[:,i,:]], dim=1 ) # type: ignore\n",
        "        # REVIEW_ENCODING_MODEL_OUTDIM + 1 has to be divisible by 3 for this to work, bc. we use 3 attention heads\n",
        "\n",
        "        transformer_output = self.scraped_reviews_transformer(transformer_input)[:,-1,:] # type: ignore\n",
        "        assert transformer_output.shape == (BATCH_SIZE, 1+ REVIEW_ENCODING_MODEL_OUTDIM)\n",
        "\n",
        "        ### CREATE BERT EMBEDDING FOR PRODUCT TITLE\n",
        "        bert_product_title_embedding = self.review_encoding_model.bert(attention_mask=product_title_bert_input_att.int(), input_ids=product_title_bert_input_ids.int()).last_hidden_state[:,0,:] # type: ignore\n",
        "        assert bert_product_title_embedding.shape == (BATCH_SIZE, BERT_EMBEDDING_SIZE)\n",
        "        # linear layer connection all\n",
        "\n",
        "        ### COMBINE PRODUCT INFORMATION (features + title), CONTEXT (other review's encodings and their helpfulness) and REVIEW ENCODING into a single scalar: the real vs. fake prediction\n",
        "        catted = torch.cat([product_features, bert_product_title_embedding, review_encoding, transformer_output],dim=1)\n",
        "        #return torch.sigmoid(self.outmlp(catted)) # type: ignore\n",
        "        return torch.relu(self.outmlp(catted))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUZPmd-OcEVB"
      },
      "source": [
        "### Running"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Datasets"
      ],
      "metadata": {
        "id": "kAxRw-zJBWX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = ReviewsDataSet(df, reviews_scraped)\n",
        "dataloader = DataLoader(dataset=dataset, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "gEKW5OnVrZkS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21fba3e2-e9b6-4689-8894-cddfe87f3a8f"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "creating ReviewsDataSet (real/fake reviews: N=8000, context reviews: M=99889\n",
            "    bert tokeinzer working...\n",
            "    creating df_product_title_encoded...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:2336: FutureWarning:\n",
            "\n",
            "The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    creating df_review_title_encoded...\n",
            "    creating df_review_text_encoded...\n",
            "    creating scraped_review_title_encoded...\n",
            "    creating scraped_review_text_encoded...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.utils.data as data\n",
        "train_set_size = int(len(dataset) * 0.7)\n",
        "val_set_size = len(dataset) - train_set_size\n",
        "train_dataset, val_dataset = data.random_split(dataset, [train_set_size, val_set_size])\n",
        "train_dataloader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE,drop_last=True, shuffle=True)\n",
        "\n",
        "new_val_set_size = int(len(val_dataset) * 0.66)\n",
        "test_set_size = val_set_size - new_val_set_size\n",
        "val_dataset, test_dataset = data.random_split(val_dataset, [new_val_set_size, test_set_size])\n",
        "val_dataloader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE,drop_last=True, shuffle=True)\n",
        "test_dataloader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE,drop_last=True, shuffle=True)"
      ],
      "metadata": {
        "id": "jAqnMWW_3J8q"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "id": "m_ep4QBkcEVC"
      },
      "outputs": [],
      "source": [
        "for (input, labels) in val_dataloader:\n",
        "    ( product_features,\n",
        "        review_features,\n",
        "        product_title_bert_input_att,\n",
        "        product_title_bert_input_ids,\n",
        "        review_title_bert_input_ids,\n",
        "        review_title_bert_input_ids,\n",
        "        review_text_bert_input_att,\n",
        "        review_text_bert_input_ids,\n",
        "        scraped_block ) = unpack_dataset_items(input)\n",
        "    # this is just a test if we can get items from the dataset\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "uWuURWqncEVD"
      },
      "outputs": [],
      "source": [
        "model = FakeDetectionModel().to(DEVICE)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('model_weights.pth'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTybdk4acsde",
        "outputId": "a7cd1ab6-9e41-4550-a7c6-3a6c6787c8f6"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRAIN"
      ],
      "metadata": {
        "id": "G2m16i2BFe-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "def metrics(y, y_hat):\n",
        "  y_hat = np.nan_to_num(y_hat, nan = 0.0001)\n",
        "  \n",
        "  return accuracy_score(y, y_hat.round()) * 100"
      ],
      "metadata": {
        "id": "9k3kIeGR0Ndm"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve, roc_auc_score, auc\n",
        "def metrics(y, y_hat, typeMetric = 'PRC' ):\n",
        "    \n",
        "    precision, recall, thresholds = precision_recall_curve(y, y_hat)\n",
        "\n",
        "    if typeMetric == 'f1':\n",
        "      fscore = (2 * precision * recall) / (precision + recall)\n",
        "      ix = np.argmax(fscore)\n",
        "      return  fscore[ix]\n",
        "    elif typeMetric == 'recall':\n",
        "      ix = np.argmax(recall)\n",
        "      return recall[ix]\n",
        "    elif typeMetric == 'precision':\n",
        "      ix = np.argmax(precision)\n",
        "      return precision[ix]\n",
        "    elif typeMetric == 'AUROC':\n",
        "      return roc_auc_score(y, y_hat)\n",
        "    elif typeMetric == 'PRC':\n",
        "      return auc(recall, precision)\n",
        "    elif typeMetric == 'acc':\n",
        "      return accuracy_score(y, y_hat.round()) * 100"
      ],
      "metadata": {
        "id": "3fNCwheWl9HY"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr = 1e-3)\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr = 1e-4)\n",
        "\n"
      ],
      "metadata": {
        "id": "_T3l8OY85e_E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4828ac27-dce9-4585-8828-2040582545de"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning:\n",
            "\n",
            "This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_f = nn.BCELoss()\n"
      ],
      "metadata": {
        "id": "23vVUx_KJvsr"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training loop"
      ],
      "metadata": {
        "id": "iLCg6GYzj_RT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from tqdm.notebook import tqdm_notebook\n",
        "# epochs = 5\n",
        "\n",
        "# process_factor = 1 # show every n times\n",
        "\n",
        "\n",
        "# pbarEpoch = tqdm_notebook(total = epochs)\n",
        "# pbarEpoch.set_description('Epoch: ')\n",
        "\n",
        "\n",
        "# for epoch in range(epochs):\n",
        "#   y_hat = []\n",
        "#   y = []\n",
        "#   flag = True\n",
        "\n",
        "#   loss_train = 0.0\n",
        "#   acc_train  = 0.0\n",
        "\n",
        "#   index = 0\n",
        "\n",
        "\n",
        "#   model.train()\n",
        "#   for (input, labels) in train_dataloader:\n",
        "    \n",
        "#     o = model(input)\n",
        "\n",
        "   \n",
        "\n",
        "#     # with torch.no_grad():\n",
        "#     #   print(model.state_dict())\n",
        "#     # o = torch.nan_to_num(o, 0.001)\n",
        "#     # labels = torch.nan_to_num(labels, 0.001)\n",
        "#     loss = loss_f(o, labels)\n",
        "\n",
        "    \n",
        "\n",
        "#     loss.backward()\n",
        "#     #torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "#     optimizer.step()\n",
        "#     optimizer.zero_grad()\n",
        "\n",
        "    \n",
        "    \n",
        "#     predicted = o.cpu().detach().numpy()\n",
        "#     ground_truth = labels.cpu().detach().numpy()\n",
        "#     if flag:\n",
        "#           y_hat = predicted\n",
        "#           y = ground_truth\n",
        "#           flag = False\n",
        "\n",
        "#     y_hat = np.append(y_hat, predicted)\n",
        "#     y = np.append(y, ground_truth)\n",
        "\n",
        "#     acc_train = metrics(y, y_hat)\n",
        "#     loss_train = loss.item()\n",
        "\n",
        "#     if (index) % process_factor == 0:\n",
        "      \n",
        "#       text = f'Training Stage ==> Epoch: {epoch} / {epochs - 1} | Step: {index} / {len(train_dataloader)} | Training loss: {loss.item():.5f} |  Training acc: {acc_train:.5f}'\n",
        "#       print(text)\n",
        "\n",
        "#     pbarEpoch.set_postfix({'Epoch':epoch,\n",
        "#             'Training loss': loss_train, \n",
        "#             'Training Acc': acc_train, \n",
        "#             'Step': index,\n",
        "#             'from': len(train_dataloader)\n",
        "#             })\n",
        "    \n",
        "    \n",
        "#     index+=1\n",
        "  \n",
        "#   text = f'Training Stage ==> Epoch: {epoch} / {epochs - 1} | Training loss: {loss_train:.5f} |  Training Accuracy: {acc_train:.5f}'\n",
        "#   print(text)\n",
        "\n",
        "# # VALIDATE    \n",
        "\n",
        "    \n",
        "\n",
        "#   index = 0\n",
        "#   y_hat = []\n",
        "#   y = []\n",
        "#   flag = True\n",
        "\n",
        "#   loss_val = 0.0\n",
        "#   acc_val  = 0.\n",
        "#   index = 0\n",
        "#   with torch.no_grad():\n",
        "#     model.eval()\n",
        "#     for (input, labels) in val_dataloader:\n",
        "#       o = model(input)\n",
        "#       # o = torch.nan_to_num(o, 0.001)\n",
        "#       loss = loss_f(o, labels)\n",
        "      \n",
        "      \n",
        "#       predicted = o.cpu().detach().numpy()\n",
        "#       ground_truth = labels.cpu().detach().numpy()\n",
        "#       if flag:\n",
        "#           y_hat = predicted\n",
        "#           y = ground_truth\n",
        "#           flag = False\n",
        "\n",
        "#       y_hat = np.append(y_hat, predicted)\n",
        "#       y = np.append(y, ground_truth)\n",
        "\n",
        "#       acc_val = metrics(y, y_hat)\n",
        "#       loss_val = loss.item()\n",
        "\n",
        "#       pbarEpoch.set_postfix({'Epoch':epoch,\n",
        "#             'Validation loss': loss_val, \n",
        "#             'Validation Acc': acc_val, \n",
        "#             'Step': index,\n",
        "#             'from': len(val_dataloader)\n",
        "#             })\n",
        "      \n",
        "#       index +=1 \n",
        "\n",
        "#     text = f'Validation Stage ==> Epoch: {epoch} / {epochs - 1} | Validation loss: {loss_val:.5f} |  Validation Accuracy: {acc_val:.5f}'\n",
        "#     print(text)\n",
        "\n",
        "#     pbarEpoch.update(1)\n",
        "#   pbarEpoch.close()"
      ],
      "metadata": {
        "id": "WmQ2jaVVi-a_"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.save(model.state_dict(), 'model_weights.pth')"
      ],
      "metadata": {
        "id": "5O3GmdK2-kck"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EVAL"
      ],
      "metadata": {
        "id": "ypiuA8iDFbvE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "id": "lBalDJJOcEVF"
      },
      "outputs": [],
      "source": [
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "model.eval()\n",
        "with torch.inference_mode():\n",
        "  for (input, labels) in test_dataloader:\n",
        "      o = model(input)\n",
        "      #print(o)\n",
        "      all_preds.append(torch.squeeze(o).cpu().detach().numpy().ravel())\n",
        "      all_labels.append(torch.squeeze(labels).cpu().detach().numpy().ravel())\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(test_dataloader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KV_YmQbVN14",
        "outputId": "ca7c1a70-5468-49cb-9e23-de2df8327ecb"
      },
      "execution_count": 180,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_labels = np.concatenate(all_labels)\n",
        "all_preds_np = np.concatenate(all_preds)\n"
      ],
      "metadata": {
        "id": "a3xGduPoNxYr"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import bctools as bc\n",
        "\n",
        "o = np.squeeze(all_preds_np)\n",
        "target = all_labels\n",
        "preds = all_preds_np\n",
        "auROC_test = bc.curve_ROC_plot(true_y= target, predicted_proba = preds, title = \"AUROC - Test\" )  \n",
        "auPRC_test = bc.curve_PR_plot(true_y= target, predicted_proba = preds,  beta = 1, title = \"AUPRC - Test\" )\n",
        "\n"
      ],
      "metadata": {
        "id": "6HgTCt0Ku3mr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0dbb86d8-b3f7-49b6-d2dc-f3e0dbe6affc"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"0485e005-26d3-4ae9-8735-13511c985ac7\" class=\"plotly-graph-div\" style=\"height:550px; width:550px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"0485e005-26d3-4ae9-8735-13511c985ac7\")) {                    Plotly.newPlot(                        \"0485e005-26d3-4ae9-8735-13511c985ac7\",                        [{\"customdata\":[[6.645580291748047],[5.645580291748047],[5.519873142242432],[5.519103527069092],[5.464385032653809],[5.463930130004883],[5.4412126541137695],[5.440756320953369],[5.422365188598633],[5.422110557556152],[5.329375267028809],[5.327904224395752],[5.186534881591797],[5.185052394866943],[5.112462997436523],[5.111052989959717],[5.034512519836426],[5.032870292663574],[4.849024772644043],[4.846911430358887],[4.272670745849609],[4.270205020904541],[4.22271728515625],[4.219615936279297],[4.091980934143066],[4.091197967529297],[3.8543219566345215],[3.854153633117676],[3.794757843017578],[3.7931857109069824],[3.7798314094543457],[3.778501033782959],[3.7558350563049316],[3.753959894180298],[3.753260612487793],[3.753159523010254],[3.7179317474365234],[3.7174324989318848],[3.71498966217041],[3.714216947555542],[3.6677186489105225],[3.6662962436676025],[3.6623144149780273],[3.6619315147399902],[3.652592897415161],[3.65120530128479],[3.6328210830688477],[3.632524251937866],[3.6092565059661865],[3.6084964275360107],[3.6017158031463623],[3.60103440284729],[3.59995174407959],[3.599717378616333],[3.5859034061431885],[3.5781052112579346],[3.568847179412842],[3.5559985637664795],[3.5421879291534424],[3.5389652252197266],[3.5368709564208984],[3.536691188812256],[3.5356569290161133],[3.535045623779297],[3.511101245880127],[3.5090150833129883],[3.5040102005004883],[3.4966020584106445],[3.4652910232543945],[3.460355758666992],[3.453972816467285],[3.4521074295043945],[3.4380974769592285],[3.4355812072753906],[3.376161575317383],[3.3739867210388184],[3.2902255058288574],[3.285686492919922],[3.194631576538086],[3.1942334175109863],[3.148263931274414],[3.147258758544922],[3.140949249267578],[3.1341018676757812],[3.060368537902832],[3.0587902069091797],[2.9904537200927734],[2.985889434814453],[2.83316707611084],[2.8277149200439453],[2.798856735229492],[2.7959108352661133],[2.632737159729004],[2.625443458557129],[2.3052024841308594],[2.290586471557617],[2.0824832916259766],[2.0422401428222656],[1.2527045011520386],[1.2500780820846558],[0.3812941610813141],[0.2520674765110016],[0.04956045001745224],[0.0]],\"hovertemplate\":\"Threshold: %{customdata:.4f} <br>False Positive Rate: %{x:.4f} <br>True Positive Rate: %{y:.4f}<extra></extra>\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"ROC Curve (AUC=0.779)\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.0,0.0,0.0,0.01694915254237288,0.01694915254237288,0.01694915254237288,0.01694915254237288,0.01694915254237288,0.01694915254237288,0.03389830508474576,0.03389830508474576,0.05084745762711865,0.05084745762711865,0.06779661016949153,0.06779661016949153,0.0847457627118644,0.0847457627118644,0.1016949152542373,0.1016949152542373,0.11864406779661017,0.11864406779661017,0.13559322033898305,0.13559322033898305,0.15254237288135594,0.15254237288135594,0.1694915254237288,0.1694915254237288,0.1864406779661017,0.1864406779661017,0.2033898305084746,0.2033898305084746,0.22033898305084745,0.22033898305084745,0.23728813559322035,0.23728813559322035,0.2542372881355932,0.2542372881355932,0.2711864406779661,0.2711864406779661,0.288135593220339,0.288135593220339,0.3050847457627119,0.3050847457627119,0.3220338983050847,0.3220338983050847,0.3559322033898305,0.3559322033898305,0.3728813559322034,0.3728813559322034,0.3898305084745763,0.3898305084745763,0.4067796610169492,0.4067796610169492,0.423728813559322,0.423728813559322,0.4406779661016949,0.4406779661016949,0.4915254237288136,0.4915254237288136,0.5084745762711864,0.5084745762711864,0.5254237288135594,0.5254237288135594,0.5423728813559322,0.5423728813559322,0.559322033898305,0.559322033898305,0.576271186440678,0.576271186440678,0.5932203389830508,0.5932203389830508,0.6271186440677966,0.6271186440677966,0.6440677966101694,0.6440677966101694,0.6610169491525424,0.6610169491525424,0.6779661016949152,0.6779661016949152,0.6949152542372882,0.6949152542372882,0.711864406779661,0.711864406779661,0.7288135593220338,0.7288135593220338,0.7457627118644068,0.7457627118644068,0.7627118644067796,0.7627118644067796,0.7796610169491526,0.7796610169491526,0.7966101694915254,0.7966101694915254,0.8305084745762712,0.8305084745762712,0.847457627118644,0.847457627118644,0.864406779661017,0.864406779661017,0.8813559322033898,0.8813559322033898,0.8983050847457628,0.8983050847457628,1.0],\"xaxis\":\"x\",\"y\":[0.0,0.0006770480704129993,0.06296547054840894,0.06296547054840894,0.15098171970209884,0.15233581584292485,0.1949898442789438,0.1963439404197698,0.23019634394041977,0.23019634394041977,0.3290453622207177,0.3290453622207177,0.4048747461069736,0.4048747461069736,0.43601895734597157,0.43601895734597157,0.4712254570074475,0.4712254570074475,0.5172647257955315,0.5172647257955315,0.5761679079214624,0.5761679079214624,0.5815842924847664,0.5815842924847664,0.5951252538930264,0.5951252538930264,0.6431956668923493,0.6431956668923493,0.6804333107650643,0.6804333107650643,0.6939742721733243,0.6939742721733243,0.7183480027081923,0.7183480027081923,0.7190250507786052,0.7190250507786052,0.7413676371022343,0.7413676371022343,0.7440758293838863,0.7440758293838863,0.7718348002708192,0.7718348002708192,0.7745429925524713,0.7745429925524713,0.7786052809749492,0.7786052809749492,0.7860528097494922,0.7860528097494922,0.7982396750169262,0.7982396750169262,0.8009478672985783,0.8009478672985783,0.8029790115098172,0.8029790115098172,0.8077183480027081,0.8077183480027081,0.8104265402843602,0.8104265402843602,0.8165199729180772,0.8165199729180772,0.8171970209884902,0.8171970209884902,0.8178740690589031,0.8178740690589031,0.8232904536222072,0.8232904536222072,0.8253215978334462,0.8253215978334462,0.8354773188896412,0.8354773188896412,0.8375084631008801,0.8375084631008801,0.8436018957345972,0.8436018957345972,0.8551117129316181,0.8551117129316181,0.8794854434664862,0.8794854434664862,0.8923493568043331,0.8923493568043331,0.8991198375084631,0.8991198375084631,0.9004739336492891,0.9004739336492891,0.9058903182125931,0.9058903182125931,0.913337846987136,0.913337846987136,0.926878808395396,0.926878808395396,0.9316181448882871,0.9316181448882871,0.9383886255924171,0.9383886255924171,0.9512525389302641,0.9512525389302641,0.955991875423155,0.955991875423155,0.974272173324306,0.974272173324306,0.984427894380501,0.984427894380501,0.98645903859174,1.0],\"yaxis\":\"y\",\"type\":\"scatter\",\"textposition\":\"top center\"},{\"line\":{\"color\":\"#20313e\",\"dash\":\"dash\"},\"mode\":\"lines\",\"name\":\"Baseline\",\"x\":[-1,2],\"y\":[-1,2],\"type\":\"scatter\",\"showlegend\":true}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"False Positive Rate\"},\"range\":[-0.03,1.0]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"True Positive Rate\"},\"range\":[0.0,1.03]},\"legend\":{\"tracegroupgap\":0,\"font\":{\"size\":9},\"yanchor\":\"top\",\"y\":0.18,\"xanchor\":\"right\",\"x\":0.97},\"title\":{\"text\":\"<b>AUROC - Test</b>\"},\"height\":550,\"width\":550,\"margin\":{\"l\":40,\"r\":40,\"t\":40,\"b\":40}},                        {\"displayModeBar\": true, \"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('0485e005-26d3-4ae9-8735-13511c985ac7');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"41b9f11f-aca1-4c00-98f0-b8c4bf74e66a\" class=\"plotly-graph-div\" style=\"height:550px; width:550px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"41b9f11f-aca1-4c00-98f0-b8c4bf74e66a\")) {                    Plotly.newPlot(                        \"41b9f11f-aca1-4c00-98f0-b8c4bf74e66a\",                        [{\"customdata\":[[0.0,0.9804181878526386],[0.04956045001745224,0.9755607633076665],[0.06677617877721786,0.9752176825184193],[0.11645498126745224,0.9748743718592966],[0.2520674765110016,0.9745308310991956],[0.3812941610813141,0.9748575259805566],[0.4378012716770172,0.9745137491616366],[0.45999136567115784,0.9741697416974171],[0.5709952116012573,0.9738255033557047],[0.5719679594039917,0.9734810339039947],[0.597030520439148,0.9731363331094695],[0.7631186246871948,0.972791400738999],[0.788314700126648,0.9724462365591398],[0.8088988065719604,0.9721008403361344],[0.8131140470504761,0.9717552118359114],[0.821090579032898,0.9714093508240834],[0.8529318571090698,0.9710632570659489],[0.9399183988571167,0.9707169303264893],[0.9947813749313354,0.9703703703703703],[1.0323599576950073,0.9700235769619401],[1.2500780820846558,0.9696765498652291],[1.2527045011520386,0.9700033704078194],[1.3581446409225464,0.9696561024949427],[1.3687857389450073,0.9693086003372681],[1.3877943754196167,0.9689608636977057],[1.3948172330856323,0.9686128923388458],[1.4011896848678589,0.9682646860229576],[1.4106806516647339,0.9679162445119891],[1.417739748954773,0.9675675675675675],[1.4484766721725464,0.9672186549509969],[1.4486712217330933,0.966869506423259],[1.4547518491744995,0.9665201217450119],[1.4759119749069214,0.96617050067659],[1.4768942594528198,0.9658206429780034],[1.507541537284851,0.965470548408937],[1.5110949277877808,0.9651202167287505],[1.5397089719772339,0.9647696476964769],[1.5575674772262573,0.9644188410708233],[1.5866068601608276,0.9640677966101694],[1.6354292631149292,0.963716514072567],[1.6593397855758667,0.9633649932157394],[1.7407454252243042,0.9630132337970818],[1.7549742460250854,0.9626612355736591],[1.7561510801315308,0.9623089983022071],[1.8046492338180542,0.9619565217391306],[1.814559817314148,0.9616038056405029],[1.9389456510543823,0.9612508497620667],[1.9857004880905151,0.9608976538592315],[2.0422401428222656,0.9605442176870748],[2.0824832916259766,0.960871044572984],[2.1098575592041016,0.9605173587474471],[2.1747608184814453,0.9601634320735445],[2.1797046661376953,0.9598092643051772],[2.181121826171875,0.9594548551959113],[2.1827526092529297,0.9591002044989776],[2.275510787963867,0.9587453119672691],[2.290586471557617,0.9583901773533424],[2.3052024841308594,0.9587171613783692],[2.3088436126708984,0.9583617747440274],[2.3365745544433594,0.9580061454421305],[2.354999542236328,0.9576502732240437],[2.3594703674316406,0.9572941578407926],[2.4233570098876953,0.9569377990430622],[2.4391517639160156,0.9565811965811967],[2.4414920806884766,0.9562243502051984],[2.442584991455078,0.9558672596647279],[2.4529380798339844,0.9555099247091033],[2.4654788970947266,0.9551523450872988],[2.495473861694336,0.9547945205479452],[2.5135631561279297,0.9544364508393285],[2.53369140625,0.9540781357093899],[2.53995418548584,0.9537195749057251],[2.561321258544922,0.953360768175583],[2.5807838439941406,0.9530017152658662],[2.6221160888671875,0.9526424159231296],[2.6241235733032227,0.9522828698935806],[2.625443458557129,0.9519230769230769],[2.629976272583008,0.9522500858811406],[2.632737159729004,0.9525773195876288],[2.7445011138916016,0.9522172567892747],[2.745767593383789,0.951856946354883],[2.7574291229248047,0.9514963880288957],[2.7708568572998047,0.9511355815554026],[2.7788591384887695,0.9507745266781411],[2.78055477142334,0.9504132231404959],[2.7814531326293945,0.9500516706854977],[2.7859840393066406,0.9496898690558235],[2.793386459350586,0.9493278179937953],[2.7959108352661133,0.9489655172413795],[2.798856735229492,0.949292859606761],[2.8016586303710938,0.9489302967563837],[2.8107213973999023,0.9485674836037279],[2.8163881301879883,0.9482044198895027],[2.819215774536133,0.9478411053540587],[2.8236427307128906,0.9474775397373877],[2.824467658996582,0.9471137227791221],[2.8277149200439453,0.9467496542185339],[2.83316707611084,0.9470771359391214],[2.8334760665893555,0.946712802768166],[2.8346681594848633,0.9463482173762547],[2.843449592590332,0.9459833795013851],[2.848311424255371,0.9456182888811915],[2.860017776489258,0.9452529452529452],[2.860165596008301,0.9448873483535529],[2.885451316833496,0.9445214979195562],[2.892557144165039,0.9441553936871315],[2.919741630554199,0.9437890353920888],[2.920135498046875,0.9434224227698715],[2.92080020904541,0.9430555555555555],[2.9222307205200195,0.9426884334838486],[2.9309520721435547,0.9423210562890896],[2.9342288970947266,0.9419534237052485],[2.9362010955810547,0.9415855354659248],[2.9396324157714844,0.9412173913043478],[2.9485645294189453,0.940848990953375],[2.9594335556030273,0.9404803341454925],[2.982720375061035,0.9401114206128134],[2.985889434814453,0.9397422500870777],[2.9904537200927734,0.9400696864111499],[2.9966325759887695,0.9397002439874521],[3.006732940673828,0.9393305439330544],[3.0089340209960938,0.9389605859783747],[3.0177507400512695,0.9385903698534542],[3.018704414367676,0.9382198952879581],[3.030130386352539,0.9378491620111732],[3.038005828857422,0.9374781697520084],[3.0471372604370117,0.9371069182389937],[3.05104923248291,0.9367354072002797],[3.053267478942871,0.9363636363636364],[3.0587902069091797,0.9359916054564533],[3.060368537902832,0.9363191042687193],[3.074237823486328,0.9359467973398671],[3.0752153396606445,0.9355742296918768],[3.08221435546875,0.935201401050788],[3.0826845169067383,0.9348283111422565],[3.0986557006835938,0.9344549596915528],[3.112813949584961,0.9340813464235623],[3.133488655090332,0.933707471062785],[3.1341018676757812,0.9333333333333333],[3.140949249267578,0.9336609336609336],[3.1431078910827637,0.9332865168539326],[3.147258758544922,0.9329118370214261],[3.148263931274414,0.9332396345748419],[3.149294853210449,0.9328646748681898],[3.155869483947754,0.9324894514767932],[3.1567935943603516,0.9321139641224059],[3.1683645248413086,0.9317382125263898],[3.1688804626464844,0.931362196409715],[3.1751232147216797,0.9309859154929578],[3.1768903732299805,0.9306093694963015],[3.1810302734375,0.9302325581395349],[3.192150115966797,0.9298554811420515],[3.1942334175109863,0.929478138222849],[3.194631576538086,0.9298059964726632],[3.201638698577881,0.9294283697953424],[3.209331512451172,0.9290504765266501],[3.2126846313476562,0.9286723163841808],[3.2126903533935547,0.928293889085129],[3.2407798767089844,0.9279151943462898],[3.2468743324279785,0.927536231884058],[3.2484474182128906,0.9271570014144271],[3.254260540008545,0.9267775026529891],[3.257803440093994,0.9263977353149327],[3.2607526779174805,0.9260176991150442],[3.26420259475708,0.9256373937677054],[3.265599250793457,0.9252568189868934],[3.2708983421325684,0.92487597448618],[3.271609306335449,0.9244948599787309],[3.278261661529541,0.924113475177305],[3.2792696952819824,0.9237318197942532],[3.281442642211914,0.9233498935415188],[3.2832908630371094,0.9229676961306356],[3.285686492919922,0.9225852272727272],[3.2902255058288574,0.9229129662522202],[3.296809673309326,0.9225302061122956],[3.297116279602051,0.9221471738357625],[3.297579765319824,0.9217638691322901],[3.2994165420532227,0.9213802917111348],[3.302248477935791,0.9209964412811388],[3.306163787841797,0.9206123175507298],[3.310059070587158,0.9202279202279203],[3.3144607543945312,0.9198432490203062],[3.3151402473449707,0.9194583036350678],[3.3173599243164062,0.9190730837789661],[3.3183069229125977,0.9186875891583451],[3.319913387298584,0.9183018194791295],[3.3210930824279785,0.9179157744468237],[3.321873664855957,0.917529453766512],[3.323477268218994,0.9171428571428571],[3.3244924545288086,0.9167559842801001],[3.326653480529785,0.9163688348820587],[3.330023765563965,0.9159814086521273],[3.3301868438720703,0.9155937052932761],[3.3388514518737793,0.91520572450805],[3.341338634490967,0.9148174659985683],[3.342054843902588,0.9144289294665233],[3.344822883605957,0.9140401146131805],[3.3461503982543945,0.9136510211393766],[3.3495125770568848,0.9132616487455196],[3.350043296813965,0.9128719971315884],[3.3517565727233887,0.9124820659971306],[3.3570923805236816,0.912091855041263],[3.360044002532959,0.9117013639626705],[3.3608531951904297,0.911310592459605],[3.365631580352783,0.910919540229885],[3.3678674697875977,0.9105282069708948],[3.3700942993164062,0.9101365923795829],[3.3702802658081055,0.9097446961524631],[3.371108055114746,0.9093525179856116],[3.3739867210388184,0.9089600575746671],[3.376161575317383,0.9092872570194385],[3.376377582550049,0.9088944904573281],[3.382204055786133,0.9085014409221902],[3.3826980590820312,0.908108108108108],[3.3831138610839844,0.9077144917087239],[3.3928170204162598,0.9073205914172376],[3.393360137939453,0.9069264069264068],[3.396533966064453,0.9065319379285456],[3.4078636169433594,0.9061371841155235],[3.4157180786132812,0.905742145178765],[3.4223666191101074,0.9053468208092486],[3.4224114418029785,0.9049512106975064],[3.4307146072387695,0.9045553145336226],[3.431485176086426,0.9041591320072332],[3.4318723678588867,0.9037626628075254],[3.4347124099731445,0.9033659066232356],[3.4354801177978516,0.9029688631426502],[3.4355812072753906,0.9025715320536037],[3.4380974769592285,0.9028985507246376],[3.4384727478027344,0.9025009061254078],[3.4398374557495117,0.9021029731689629],[3.440667152404785,0.9017047515415306],[3.4418458938598633,0.9013062409288823],[3.443819999694824,0.9009074410163339],[3.4469566345214844,0.9005083514887435],[3.447909355163574,0.9001089720305122],[3.4511632919311523,0.8997093023255813],[3.4521074295043945,0.8993093420574336],[3.4523019790649414,0.8996363636363637],[3.453972816467285,0.8999636231356857],[3.455399513244629,0.8995633187772926],[3.455807685852051,0.8991627229705133],[3.460355758666992,0.8987618353969409],[3.4652910232543945,0.8990892531876138],[3.4686808586120605,0.8986880466472303],[3.4698328971862793,0.8982865475756471],[3.471635341644287,0.8978847556528082],[3.4721546173095703,0.8974826705581904],[3.472507953643799,0.897080291970803],[3.474909782409668,0.8966776195691859],[3.478395938873291,0.8962746530314097],[3.4809274673461914,0.8958713920350748],[3.4811105728149414,0.89546783625731],[3.484722852706909,0.8950639853747715],[3.4855825901031494,0.894659839063643],[3.4898738861083984,0.8942553969996341],[3.490372657775879,0.8938506588579795],[3.4947869777679443,0.8934456243134383],[3.4966020584106445,0.893040293040293],[3.5040102005004883,0.8933675338951999],[3.506711959838867,0.8929618768328446],[3.506838798522949,0.8925559222588926],[3.5090150833129883,0.892149669845928],[3.511101245880127,0.8924770642201836],[3.513218402862549,0.8920704845814978],[3.5151150226593018,0.8916636063165626],[3.5163254737854004,0.8912564290962527],[3.516836643218994,0.8908489525909593],[3.5284643173217773,0.8904411764705882],[3.529067039489746,0.8900331004045605],[3.5303702354431152,0.8896247240618101],[3.535045623779297,0.889216047110784],[3.5356569290161133,0.889543446244477],[3.536691188812256,0.889134438305709],[3.5368709564208984,0.8894620486366986],[3.5389652252197266,0.8890527091780318],[3.5421879291534424,0.8893805309734514],[3.5441112518310547,0.8889708594614532],[3.5454092025756836,0.8885608856088562],[3.5461883544921875,0.8881506090808418],[3.550276279449463,0.8877400295420975],[3.55057430267334,0.8873291466568156],[3.550973892211914,0.8869179600886918],[3.5530991554260254,0.8865064695009243],[3.5546443462371826,0.8860946745562129],[3.5559985637664795,0.8856825749167592],[3.5565664768218994,0.8860103626943006],[3.568056106567383,0.8863383931877084],[3.568847179412842,0.8866666666666667],[3.5692341327667236,0.8862541682104482],[3.569488286972046,0.8858413639733136],[3.5781028270721436,0.8854282536151279],[3.5781052112579346,0.8850148367952523],[3.5859034061431885,0.885343228200371],[3.5873148441314697,0.8849294729027468],[3.592128038406372,0.8845154103230597],[3.5924227237701416,0.8841010401188708],[3.5927844047546387,0.8836863619472314],[3.5930604934692383,0.8832713754646839],[3.5993123054504395,0.8828560803272592],[3.599717378616333,0.8824404761904762],[3.59995174407959,0.8827688872348344],[3.6005516052246094,0.8823529411764707],[3.6006808280944824,0.8819366852886406],[3.60103440284729,0.8815201192250371],[3.6017158031463623,0.8818486768542676],[3.6029391288757324,0.8814317673378076],[3.604696750640869,0.8810145468108915],[3.605116844177246,0.8805970149253732],[3.6084964275360107,0.8801791713325868],[3.6092565059661865,0.8805078416728902],[3.610779047012329,0.8800896525961898],[3.612903594970703,0.8796711509715995],[3.613053798675537,0.8792523364485982],[3.6135456562042236,0.8788332086761407],[3.6135919094085693,0.8784137673026562],[3.6136257648468018,0.877994011976048],[3.6141557693481445,0.8775739423436916],[3.6179754734039307,0.8771535580524346],[3.6181142330169678,0.876732858748595],[3.618633985519409,0.8763118440779609],[3.6190569400787354,0.8758905136857892],[3.61920166015625,0.8754688672168043],[3.6243481636047363,0.875046904315197],[3.624532699584961,0.8746246246246245],[3.6274075508117676,0.8742020277882087],[3.62853741645813,0.873779113448535],[3.6286873817443848,0.8733558812476513],[3.632524251937866,0.8729323308270678],[3.6328210830688477,0.8732606242948477],[3.6336922645568848,0.8728367193378481],[3.6384129524230957,0.872412495295446],[3.638854503631592,0.8719879518072289],[3.6412429809570312,0.8715630885122411],[3.64152193069458,0.8711379050489826],[3.642146587371826,0.870712401055409],[3.644322633743286,0.870286576168929],[3.645092725753784,0.8698604300264051],[3.646531581878662,0.8694339622641509],[3.6506588459014893,0.8690071725179312],[3.65120530128479,0.8685800604229607],[3.651556968688965,0.8689081979599547],[3.652592897415161,0.8692365835222978],[3.6538658142089844,0.8688090737240076],[3.6541781425476074,0.8683812405446294],[3.657977819442749,0.8679530836171018],[3.658823251724243,0.8675246025738077],[3.660487174987793,0.8670957970465731],[3.6619315147399902,0.8666666666666667],[3.6623144149780273,0.8669950738916257],[3.66256046295166,0.8665655799848371],[3.662898302078247,0.8661357603337126],[3.663487195968628,0.8657056145675265],[3.6662962436676025,0.8652751423149906],[3.6677186489105225,0.8656036446469249],[3.6679680347442627,0.8651728066843904],[3.673306465148926,0.8647416413373861],[3.6737027168273926,0.8643101482326111],[3.676260232925415,0.8638783269961976],[3.678439140319824,0.8634461772537086],[3.679854393005371,0.8630136986301369],[3.6809206008911133,0.862580890749905],[3.681161403656006,0.8621477532368621],[3.681687355041504,0.8617142857142857],[3.682109832763672,0.861280487804878],[3.6823108196258545,0.8608463591307662],[3.6827900409698486,0.8604118993135011],[3.6837666034698486,0.8599771079740557],[3.6847927570343018,0.8595419847328245],[3.685070514678955,0.8591065292096219],[3.6858487129211426,0.8586707410236821],[3.689607620239258,0.8582346197936568],[3.6901981830596924,0.8577981651376145],[3.6920559406280518,0.8573613766730402],[3.692105531692505,0.8569242540168325],[3.69380784034729,0.8564867967853041],[3.6947226524353027,0.8560490045941807],[3.6961021423339844,0.8556108770585982],[3.696554660797119,0.8551724137931034],[3.697082996368408,0.854733614411652],[3.698526382446289,0.8542944785276073],[3.7006051540374756,0.85385500575374],[3.70123553276062,0.8534151957022256],[3.7021431922912598,0.852975047984645],[3.7024528980255127,0.8525345622119817],[3.7036936283111572,0.8520937379946215],[3.704066038131714,0.8516525749423521],[3.705181121826172,0.8512110726643599],[3.7060651779174805,0.8507692307692307],[3.7078967094421387,0.8503270488649481],[3.7080612182617188,0.8498845265588915],[3.7081568241119385,0.849441663457836],[3.7086589336395264,0.8489984591679507],[3.7094016075134277,0.8485549132947976],[3.7132251262664795,0.8481110254433307],[3.714216947555542,0.8476667952178943],[3.71498966217041,0.8479938271604938],[3.7155070304870605,0.8475492087996913],[3.7162880897521973,0.847104247104247],[3.7165489196777344,0.8466589416763229],[3.7174324989318848,0.8462132921174651],[3.7179317474365234,0.8465403942790877],[3.7188658714294434,0.8460943542150039],[3.7196030616760254,0.8456479690522244],[3.720200777053833,0.8452012383900928],[3.7208542823791504,0.8447541618273327],[3.7212157249450684,0.8443067389620449],[3.7217304706573486,0.8438589693917087],[3.722475051879883,0.8434108527131783],[3.723079204559326,0.8429623885226832],[3.7234907150268555,0.8425135764158261],[3.723921298980713,0.8420644159875825],[3.7262187004089355,0.8416149068322981],[3.7263805866241455,0.8411650485436893],[3.7265079021453857,0.8407148407148407],[3.7268338203430176,0.8402642829382044],[3.7285447120666504,0.8398133748055988],[3.728731155395508,0.839362115908207],[3.7306039333343506,0.8389105058365758],[3.7322821617126465,0.838458544180615],[3.7337331771850586,0.8380062305295951],[3.7345614433288574,0.8375535644721465],[3.735639810562134,0.8371005455962588],[3.736818790435791,0.8366471734892788],[3.739875078201294,0.8361934477379094],[3.740074872970581,0.8357393679282091],[3.74019718170166,0.8352849336455894],[3.741548776626587,0.8348301444748146],[3.744716167449951,0.8343750000000001],[3.7451131343841553,0.8339194998046111],[3.7453997135162354,0.8334636434714622],[3.7463901042938232,0.8330074305827142],[3.75046968460083,0.8325508607198749],[3.7506728172302246,0.8320939334637965],[3.753159523010254,0.831636648394675],[3.753260612487793,0.8319623971797885],[3.753959894180298,0.8315047021943573],[3.7558350563049316,0.8318306546452372],[3.758230209350586,0.8313725490196079],[3.758427619934082,0.830914083954492],[3.760317325592041,0.8304552590266875],[3.761017322540283,0.8299960738123282],[3.7611923217773438,0.8295365278868815],[3.762115001678467,0.8290766208251474],[3.7627243995666504,0.8286163522012578],[3.763256549835205,0.8281557215886748],[3.763453960418701,0.8276947285601888],[3.7642788887023926,0.8272333726879182],[3.7644243240356445,0.8267716535433071],[3.7645339965820312,0.8263095706971247],[3.764888048171997,0.8258471237194641],[3.766315460205078,0.8253843121797398],[3.7672500610351562,0.8249211356466878],[3.767643451690674,0.8244575936883629],[3.7677154541015625,0.823993685872139],[3.768495559692383,0.8235294117647058],[3.7686305046081543,0.8230647709320695],[3.7690067291259766,0.8225997629395497],[3.769293785095215,0.8221343873517787],[3.7695913314819336,0.8216686437327005],[3.769918918609619,0.8212025316455694],[3.770831823348999,0.8207360506529482],[3.771432399749756,0.8202692003167061],[3.77272891998291,0.8198019801980196],[3.773571014404297,0.8193343898573693],[3.7740588188171387,0.8188664288545382],[3.774472713470459,0.8183980967486123],[3.774491786956787,0.8179293930979771],[3.774660587310791,0.8174603174603176],[3.7756645679473877,0.816990869392616],[3.7760987281799316,0.8165210484511517],[3.7763442993164062,0.8160508541914978],[3.777437925338745,0.8155802861685215],[3.778501033782959,0.8151093439363817],[3.7798314094543457,0.8154335719968179],[3.7803897857666016,0.8149621965777955],[3.781327724456787,0.8144904458598725],[3.781860113143921,0.8140183193946635],[3.7825021743774414,0.8135458167330678],[3.7825968265533447,0.8130729374252691],[3.7828078269958496,0.8125996810207335],[3.782958507537842,0.8121260470682089],[3.783449649810791,0.8116520351157223],[3.783808469772339,0.8111776447105788],[3.7848217487335205,0.810702875399361],[3.7864885330200195,0.8102277267279265],[3.786494255065918,0.809752198241407],[3.7865490913391113,0.8092762894842063],[3.7872262001037598,0.8088000000000001],[3.787364959716797,0.8083233293317327],[3.7886734008789062,0.8078462770216174],[3.7887444496154785,0.8073688426111334],[3.7920002937316895,0.8068910256410255],[3.792020797729492,0.8064128256513027],[3.7931857109069824,0.8059342421812349],[3.794757843017578,0.806257521058965],[3.796144962310791,0.8057784911717496],[3.7962937355041504,0.8052990766760336],[3.796440601348877,0.8048192771084336],[3.796586036682129,0.8043390920048212],[3.7976129055023193,0.8038585209003215],[3.799750566482544,0.8033775633293124],[3.8006017208099365,0.8028962188254224],[3.8009016513824463,0.8024144869215293],[3.8010849952697754,0.8019323671497585],[3.8023812770843506,0.8014498590414821],[3.8027591705322266,0.8009669621273167],[3.803516387939453,0.8004836759371222],[3.8044233322143555,0.8],[3.8070836067199707,0.7995159338442921],[3.8080220222473145,0.7990314769975787],[3.811842918395996,0.7985466289866774],[3.8118605613708496,0.7980613893376414],[3.8120365142822266,0.7975757575757577],[3.81229305267334,0.7970897332255457],[3.8168327808380127,0.7966033158107562],[3.817239284515381,0.7961165048543689],[3.817455768585205,0.7956292998785918],[3.8187828063964844,0.7951417004048583],[3.822068691253662,0.7946537059538274],[3.8252100944519043,0.7941653160453808],[3.825951099395752,0.7936765301986217],[3.827664375305176,0.7931873479318734],[3.829289436340332,0.7926977687626775],[3.8303751945495605,0.7922077922077921],[3.83074688911438,0.7917174177831912],[3.8319215774536133,0.7912266450040618],[3.832000732421875,0.790735473384803],[3.8325886726379395,0.7902439024390244],[3.8326334953308105,0.7897519316795445],[3.833495616912842,0.7892595606183889],[3.8336129188537598,0.7887667887667889],[3.8336243629455566,0.7882736156351792],[3.8339147567749023,0.7877800407331976],[3.8353657722473145,0.7872860635696821],[3.835801601409912,0.7867916836526702],[3.836113452911377,0.7862969004893965],[3.8361659049987793,0.7858017135862914],[3.8368337154388428,0.7853061224489796],[3.840488910675049,0.7848101265822784],[3.842031240463257,0.784313725490196],[3.8420796394348145,0.7838169186759296],[3.8431026935577393,0.7833197056418643],[3.8441734313964844,0.7828220858895705],[3.846036911010742,0.7823240589198036],[3.8466172218322754,0.781825624232501],[3.8488004207611084,0.7813267813267813],[3.8503060340881348,0.7808275297009423],[3.8524205684661865,0.780327868852459],[3.852698802947998,0.7798277982779828],[3.854153633117676,0.7793273174733387],[3.8543219566345215,0.779647107098892],[3.8553714752197266,0.7791461412151067],[3.8562233448028564,0.7786447638603696],[3.856698513031006,0.7781429745275267],[3.8603649139404297,0.7776407727085902],[3.861300230026245,0.7771381578947367],[3.864459991455078,0.7766351295763061],[3.86458420753479,0.7761316872427984],[3.8650593757629395,0.7756278303828736],[3.865563154220581,0.7751235584843493],[3.868619918823242,0.7746188710341986],[3.8701751232147217,0.7741137675185491],[3.8715035915374756,0.7736082474226805],[3.872593402862549,0.773102310231023],[3.8728954792022705,0.7725959554271564],[3.8747546672821045,0.7720891824938069],[3.875603675842285,0.7715819909128461],[3.876067876815796,0.7710743801652893],[3.8761801719665527,0.7705663497312939],[3.876455783843994,0.7700578990901571],[3.877000331878662,0.7695490277203145],[3.878945827484131,0.7690397350993378],[3.8850059509277344,0.7685300207039337],[3.8869800567626953,0.768019884009942],[3.89011812210083,0.7675093244923332],[3.890878677368164,0.7669983416252073],[3.8915696144104004,0.7664869348817918],[3.8932173252105713,0.7659751037344399],[3.8945021629333496,0.7654628476546285],[3.894652843475342,0.7649501661129567],[3.8954343795776367,0.7644370585791441],[3.897165298461914,0.7639235245220284],[3.8991637229919434,0.7634095634095635],[3.9016318321228027,0.7628951747088187],[3.9028971195220947,0.7623803578859759],[3.905518054962158,0.761865112406328],[3.906613826751709,0.7613494377342774],[3.908656597137451,0.7608333333333333],[3.9124321937561035,0.7603167986661108],[3.9140281677246094,0.7597998331943285],[3.9143147468566895,0.7592824363788069],[3.916904926300049,0.7587646076794657],[3.9188525676727295,0.7582463465553236],[3.931286096572876,0.7577276524644946],[3.933225631713867,0.7572085248641872],[3.937617301940918,0.7566889632107023],[3.9386444091796875,0.7561689669594313],[3.939270496368408,0.7556485355648537],[3.952486991882324,0.7551276684805358],[3.9601058959960938,0.7546063651591289],[3.9651856422424316,0.754084625052367],[3.968700408935547,0.7535624476110646],[3.9708566665649414,0.7530398322851152],[3.9738316535949707,0.7525167785234899],[3.97833251953125,0.7519932857742342],[3.994406223297119,0.751469353484467],[4.011455059051514,0.7509449811003779],[4.0130109786987305,0.750420168067227],[4.017207145690918,0.7498949138293401],[4.020015239715576,0.7493692178301093],[4.03176212310791,0.74884307951199],[4.033619403839111,0.7483164983164983],[4.03398323059082,0.7477894736842104],[4.041675567626953,0.7472620050547598],[4.0466837882995605,0.7467340918668351],[4.0572404861450195,0.7462057335581787],[4.059924602508545,0.7456769295655842],[4.076155185699463,0.7451476793248946],[4.076690673828125,0.7446179822710003],[4.080657482147217,0.7440878378378379],[4.091114521026611,0.7435572454583862],[4.091197967529297,0.7430262045646661],[4.091980934143066,0.7433403805496829],[4.100416660308838,0.742808798646362],[4.111260414123535,0.7422767668218365],[4.122447490692139,0.7417442845046572],[4.132313251495361,0.7412113511224058],[4.133720397949219,0.7406779661016949],[4.134189128875732,0.7401441288681644],[4.146824836730957,0.73960983884648],[4.149438381195068,0.739075095460331],[4.1497344970703125,0.7385398981324278],[4.149888515472412,0.738004246284501],[4.152503967285156,0.7374681393372982],[4.1721367835998535,0.7369315767105822],[4.176628589630127,0.7363945578231293],[4.180092811584473,0.7358570820927265],[4.189122200012207,0.7353191489361702],[4.190274238586426,0.7347807577692635],[4.195148944854736,0.7342419080068143],[4.210500717163086,0.7337025990626332],[4.214054584503174,0.7331628303495311],[4.219615936279297,0.7326226012793177],[4.22271728515625,0.7329351535836176],[4.223113536834717,0.732394366197183],[4.232754230499268,0.7318531169940222],[4.239857196807861,0.7313114053823152],[4.245290279388428,0.7307692307692308],[4.249102592468262,0.7302265925609235],[4.256171703338623,0.7296834901625321],[4.257569313049316,0.7291399229781771],[4.270205020904541,0.728595890410959],[4.272670745849609,0.7289079229122056],[4.2802276611328125,0.7283633247643531],[4.28800106048584,0.7278182597513931],[4.289220809936523,0.7272727272727273],[4.289586067199707,0.7267267267267268],[4.294535160064697,0.7261802575107296],[4.300835609436035,0.725633319021039],[4.330641746520996,0.7250859106529209],[4.331167221069336,0.7245380318006015],[4.332852363586426,0.7239896818572658],[4.339148998260498,0.7234408602150537],[4.347001075744629,0.7228915662650602],[4.348587512969971,0.7223417993973311],[4.351041793823242,0.7217915590008614],[4.357687950134277,0.7212408444635933],[4.3652472496032715,0.7206896551724139],[4.370171546936035,0.7201379905131522],[4.370888710021973,0.719585849870578],[4.3766913414001465,0.7190332326283988],[4.384733200073242,0.7184801381692574],[4.388615608215332,0.7179265658747299],[4.397777557373047,0.7173725151253241],[4.398710250854492,0.7168179853004756],[4.421938896179199,0.7162629757785467],[4.433229446411133,0.715707485936824],[4.441150188446045,0.7151515151515152],[4.447625160217285,0.7145950627977479],[4.4681715965271,0.7140381282495666],[4.499127388000488,0.7134807108799306],[4.502748012542725,0.7129228100607112],[4.513116359710693,0.7123644251626898],[4.519296169281006,0.7118055555555556],[4.521034240722656,0.7112462006079026],[4.521878719329834,0.7106863596872285],[4.530057907104492,0.7101260321599304],[4.5551438331604,0.7095652173913043],[4.55764102935791,0.7090039147455414],[4.558052062988281,0.7084421235857268],[4.562338829040527,0.7078798432738354],[4.565474987030029,0.7073170731707318],[4.57100248336792,0.7067538126361655],[4.575340270996094,0.7061900610287706],[4.606259822845459,0.7056258177060618],[4.607389450073242,0.7050610820244329],[4.60753059387207,0.7044958533391532],[4.609645843505859,0.7039301310043667],[4.610141754150391,0.7033639143730887],[4.610479354858398,0.7027972027972028],[4.615204811096191,0.7022299956274596],[4.616631507873535,0.7016622922134734],[4.630326271057129,0.70109409190372],[4.631434440612793,0.700525394045534],[4.635534763336182,0.6999561979851073],[4.641157627105713,0.6993865030674846],[4.646075248718262,0.698816308636563],[4.656062126159668,0.6982456140350877],[4.662729740142822,0.6976744186046512],[4.678901672363281,0.6971027216856892],[4.680095672607422,0.6965305226174792],[4.687417984008789,0.6959578207381371],[4.688933372497559,0.6953846153846154],[4.6909027099609375,0.6948109058927],[4.691161155700684,0.6942366915970084],[4.69697904586792,0.693661971830986],[4.706230640411377,0.6930867459269044],[4.710453510284424,0.692511013215859],[4.715275764465332,0.6919347730277655],[4.717306613922119,0.6913580246913581],[4.720369338989258,0.690780767534186],[4.722867012023926,0.6902030008826125],[4.737827301025391,0.6896247240618101],[4.748136520385742,0.6890459363957595],[4.748981475830078,0.6884666372072471],[4.7628278732299805,0.6878868258178604],[4.7756218910217285,0.6873065015479877],[4.783833026885986,0.6867256637168141],[4.785770416259766,0.6861443116423196],[4.78656005859375,0.6855624446412755],[4.798031806945801,0.6849800620292424],[4.825568675994873,0.6843971631205674],[4.829324722290039,0.6838137472283814],[4.831666946411133,0.6832298136645963],[4.835297584533691,0.6826453617399024],[4.836594581604004,0.6820603907637655],[4.842987060546875,0.6814749000444246],[4.84343957901001,0.6808888888888889],[4.84373140335083,0.6803023566029346],[4.846911430358887,0.6797153024911032],[4.849024772644043,0.6800178015131286],[4.850586891174316,0.6794300979519144],[4.85302209854126,0.6788418708240533],[4.853682041168213,0.6782531194295899],[4.863955497741699,0.6776638430673204],[4.864100456237793,0.6770740410347904],[4.8695454597473145,0.6764837126282909],[4.884057998657227,0.6758928571428572],[4.885433673858643,0.6753014738722642],[4.8859405517578125,0.674709562109026],[4.889523506164551,0.6741171211443898],[4.889687538146973,0.6735241502683363],[4.889939308166504,0.6729306487695749],[4.894972801208496,0.6723366159355416],[4.903923511505127,0.6717420510523958],[4.905004501342773,0.671146953405018],[4.90613317489624,0.6705513222770059],[4.907480239868164,0.6699551569506725],[4.907823085784912,0.6693584567070434],[4.922300338745117,0.6687612208258528],[4.922839641571045,0.668163448585541],[4.925227165222168,0.6675651392632524],[4.9255290031433105,0.6669662921348315],[4.93112325668335,0.6663669064748201],[4.934317588806152,0.6657669815564553],[4.939540863037109,0.6651665166516652],[4.940515041351318,0.6645655110310671],[4.940558433532715,0.663963963963964],[4.941460609436035,0.6633618747183416],[4.942283630371094,0.6627592425608656],[4.942904472351074,0.6621560667568787],[4.944109916687012,0.6615523465703971],[4.944915771484375,0.6609480812641084],[4.9457106590271,0.6603432700993677],[4.94816780090332,0.6597379123361952],[4.952385425567627,0.659132007233273],[4.964950084686279,0.6585255540479421],[4.9650163650512695,0.6579185520361991],[4.966763496398926,0.6573110004526935],[4.968249320983887,0.6567028985507247],[4.969255447387695,0.6560942455822384],[4.973440170288086,0.6554850407978242],[4.973994731903076,0.654875283446712],[4.987888336181641,0.6542649727767695],[4.98848819732666,0.6536541080344984],[4.989139080047607,0.6530426884650318],[4.995589733123779,0.6524307133121308],[4.997094631195068,0.6518181818181819],[4.998268127441406,0.6512050932241927],[4.9993062019348145,0.6505914467697909],[4.999663352966309,0.6499772416932181],[5.0028228759765625,0.6493624772313298],[5.004924297332764,0.64874715261959],[5.0078816413879395,0.6481312670920693],[5.010379314422607,0.6475148198814409],[5.010712146759033,0.6468978102189782],[5.0128912925720215,0.6462802373345505],[5.01546049118042,0.645662100456621],[5.015984535217285,0.645043398812243],[5.016448020935059,0.6444241316270567],[5.021473407745361,0.6438042981252857],[5.022171497344971,0.6431838975297347],[5.023194313049316,0.6425629290617848],[5.023311138153076,0.6419413919413919],[5.0254225730896,0.6413192853870819],[5.026845455169678,0.6406966086159487],[5.026954650878906,0.6400733608436497],[5.0328474044799805,0.6394495412844037],[5.032870292663574,0.6388251491509866],[5.034512519836426,0.6391184573002755],[5.035418510437012,0.6384933394579697],[5.037164211273193,0.6378676470588235],[5.0371880531311035,0.6372413793103449],[5.037324905395508,0.6366145354185833],[5.038429260253906,0.6359871145881271],[5.038661003112793,0.6353591160220995],[5.0390625,0.6347305389221557],[5.041404724121094,0.6341013824884792],[5.04925537109375,0.6334716459197787],[5.053902626037598,0.6328413284132842],[5.055022239685059,0.6322104291647439],[5.055134296417236,0.6315789473684209],[5.056167125701904,0.63094688221709],[5.058854103088379,0.6303142329020333],[5.0592193603515625,0.6296809986130375],[5.059223651885986,0.6290471785383903],[5.05955696105957,0.6284127718648773],[5.060013771057129,0.6277777777777778],[5.062582969665527,0.6271421954608616],[5.066922664642334,0.6265060240963856],[5.0680060386657715,0.6258692628650905],[5.069206237792969,0.6252319109461967],[5.0707526206970215,0.6245939675174014],[5.0726637840271,0.6239554317548747],[5.077104091644287,0.623316302833256],[5.077697277069092,0.6226765799256505],[5.078605651855469,0.6220362622036263],[5.0788373947143555,0.6213953488372094],[5.081977367401123,0.6207538389948812],[5.0824713706970215,0.6201117318435755],[5.084061145782471,0.6194690265486725],[5.0849809646606445,0.6188257222739981],[5.085374355316162,0.6181818181818182],[5.085484027862549,0.6175373134328358],[5.086874008178711,0.6168922071861875],[5.089232921600342,0.6162464985994397],[5.092015743255615,0.6156001868285848],[5.09868860244751,0.6149532710280374],[5.099114418029785,0.6143057503506312],[5.1008453369140625,0.6136576239476146],[5.101712226867676,0.6130088909686476],[5.101965427398682,0.6123595505617978],[5.101980686187744,0.6117096018735363],[5.101997375488281,0.6110590440487348],[5.102856159210205,0.6104078762306611],[5.104342937469482,0.6097560975609757],[5.10582160949707,0.6091037071797278],[5.106050491333008,0.6084507042253521],[5.106235980987549,0.6077970878346641],[5.106342792510986,0.6071428571428571],[5.109316825866699,0.6064880112834978],[5.111052989959717,0.605832549388523],[5.112462997436523,0.6061176470588235],[5.11290168762207,0.6054613935969869],[5.1133270263671875,0.6048045219029676],[5.117648601531982,0.6041470311027333],[5.118165016174316,0.6034889203206035],[5.119170188903809,0.6028301886792452],[5.121283531188965,0.6021708352996696],[5.123860836029053,0.6015108593012276],[5.124725818634033,0.600850259801606],[5.126072406768799,0.6001890359168243],[5.127540588378906,0.5995271867612293],[5.128905296325684,0.5988647114474929],[5.129656791687012,0.5982016090866068],[5.134328842163086,0.5975378787878787],[5.138133525848389,0.5968735196589294],[5.140664100646973,0.5962085308056873],[5.145584583282471,0.595542911332385],[5.145895004272461,0.594876660341556],[5.145974636077881,0.5942097769340294],[5.146145343780518,0.5935422602089269],[5.146241664886475,0.5928741092636579],[5.146853923797607,0.5922053231939164],[5.14827823638916,0.5915359010936757],[5.148504734039307,0.5908658420551856],[5.150400161743164,0.5901951451689672],[5.151001930236816,0.5895238095238096],[5.156478404998779,0.5888518342067651],[5.161632061004639,0.5881792183031459],[5.162754535675049,0.5875059608965189],[5.166755199432373,0.5868320610687022],[5.16688346862793,0.5861575178997613],[5.167933940887451,0.5854823304680038],[5.168830871582031,0.5848064978499761],[5.170987606048584,0.5841300191204589],[5.171444892883301,0.583452893352463],[5.171646595001221,0.5827751196172248],[5.173025608062744,0.582096696984203],[5.1733503341674805,0.5814176245210728],[5.174821853637695,0.580737901293723],[5.175157070159912,0.5800575263662512],[5.1781907081604,0.5793764988009592],[5.1803059577941895,0.5786948176583493],[5.183150768280029,0.5780124819971194],[5.18368673324585,0.5773294908741595],[5.183770179748535,0.5766458433445459],[5.184937000274658,0.5759615384615384],[5.185052394866943,0.5752765752765753],[5.186534881591797,0.5755534167468721],[5.189682483673096,0.574867597496389],[5.19342565536499,0.5741811175337187],[5.196922302246094,0.5734939759036145],[5.198024272918701,0.5728061716489875],[5.2012457847595215,0.5721177038109021],[5.205982685089111,0.5714285714285714],[5.20632791519165,0.570738773539353],[5.208418846130371,0.5700483091787439],[5.212089538574219,0.5693571773803769],[5.212096214294434,0.5686653771760155],[5.213590621948242,0.5679729075955492],[5.2155046463012695,0.5672797676669894],[5.218204021453857,0.5665859564164649],[5.218808174133301,0.5658914728682172],[5.221278667449951,0.5651963160445952],[5.226101875305176,0.5645004849660523],[5.228265762329102,0.5638039786511403],[5.229948043823242,0.5631067961165048],[5.230400085449219,0.562408936376882],[5.231381416320801,0.5617103984450923],[5.231627464294434,0.5610111813320369],[5.232369899749756,0.5603112840466926],[5.233705997467041,0.559610705596107],[5.234391212463379,0.5589094449853944],[5.238495349884033,0.5582075012177301],[5.239093780517578,0.5575048732943471],[5.240507125854492,0.5568015602145294],[5.2434306144714355,0.5560975609756098],[5.244173526763916,0.5553928745729625],[5.244654178619385,0.5546875000000001],[5.2465386390686035,0.5539814362481681],[5.247930526733398,0.5532746823069404],[5.248025894165039,0.5525672371638142],[5.248494625091553,0.5518590998043054],[5.248610019683838,0.5511502692119432],[5.249064922332764,0.5504407443682664],[5.249187469482422,0.5497305242528172],[5.249571323394775,0.5490196078431372],[5.250124931335449,0.548307994114762],[5.250189781188965,0.5475956820412169],[5.253465175628662,0.5468826705940109],[5.2540974617004395,0.5461689587426326],[5.254208087921143,0.5454545454545454],[5.256136417388916,0.5447394296951819],[5.256561279296875,0.544023610427939],[5.256911754608154,0.5433070866141733],[5.257091045379639,0.5425898572131954],[5.2594499588012695,0.5418719211822661],[5.263340473175049,0.5411532774765895],[5.266887664794922,0.5404339250493096],[5.267736911773682,0.5397138628515047],[5.26856803894043,0.5389930898321816],[5.27239990234375,0.5382716049382716],[5.272716999053955,0.5375494071146245],[5.272866249084473,0.536826495304004],[5.27451229095459,0.5361028684470821],[5.276108741760254,0.5353785254824344],[5.276177406311035,0.5346534653465347],[5.277881145477295,0.5339276869737494],[5.279025554656982,0.5332011892963331],[5.280585765838623,0.5324739712444224],[5.281564712524414,0.5317460317460317],[5.2830305099487305,0.5310173697270473],[5.283993721008301,0.5302879841112215],[5.285031795501709,0.529557873820169],[5.287383079528809,0.5288270377733598],[5.288417339324951,0.5280954748881153],[5.288768291473389,0.527363184079602],[5.290430068969727,0.5266301642608262],[5.290585041046143,0.5258964143426296],[5.296854019165039,0.5251619332336821],[5.297765254974365,0.5244267198404785],[5.298296928405762,0.5236907730673317],[5.299871444702148,0.5229540918163673],[5.300100803375244,0.5222166749875188],[5.300483703613281,0.5214785214785215],[5.300515174865723,0.5207396301849077],[5.302009582519531,0.52],[5.302594184875488,0.5192596298149074],[5.302637100219727,0.5185185185185186],[5.3056559562683105,0.5177766649974962],[5.30736780166626,0.5170340681362726],[5.307917594909668,0.5162907268170426],[5.3080034255981445,0.5155466399197592],[5.309727668762207,0.5148018063221275],[5.310009956359863,0.5140562248995983],[5.311122417449951,0.5133098945253641],[5.311176300048828,0.5125628140703518],[5.311375617980957,0.5118149824032177],[5.3122382164001465,0.5110663983903421],[5.312317848205566,0.5103170608958227],[5.3131103515625,0.5095669687814703],[5.313255786895752,0.508816120906801],[5.313291072845459,0.5080645161290323],[5.313647747039795,0.5073121533030762],[5.314915657043457,0.5065590312815338],[5.316786766052246,0.5058051489146895],[5.317202091217041,0.505050505050505],[5.317458629608154,0.5042950985346134],[5.318927764892578,0.5035389282103134],[5.319887638092041,0.5027819929185634],[5.319935321807861,0.5020242914979758],[5.320107936859131,0.50126582278481],[5.322154998779297,0.5005065856129686],[5.324019908905029,0.4997465788139888],[5.324826717376709,0.4989858012170385],[5.324832916259766,0.49822425164890916],[5.325720310211182,0.49746192893401014],[5.3265767097473145,0.4966988318943626],[5.326823711395264,0.4959349593495934],[5.327644348144531,0.4951703101169293],[5.327904224395752,0.4944048830111903],[5.329375267028809,0.49465648854961836],[5.331072807312012,0.4938900203665988],[5.331470489501953,0.4931227712684666],[5.332176208496094,0.4923547400611621],[5.333704948425293,0.49158592554818975],[5.333967208862305,0.49081632653061225],[5.3362016677856445,0.4900459418070444],[5.3363938331604,0.4892747701736466],[5.337085723876953,0.4885028104241185],[5.337459087371826,0.48773006134969327],[5.337523460388184,0.4869565217391304],[5.337794303894043,0.4861821903787103],[5.337954521179199,0.4854070660522274],[5.339442729949951,0.48463114754098363],[5.339787483215332,0.4838544336237828],[5.340407371520996,0.483076923076923],[5.340811729431152,0.48229861467419194],[5.341876983642578,0.48151950718685826],[5.343638896942139,0.48073959938366717],[5.343648910522461,0.4799588900308325],[5.3437113761901855,0.47917737789203085],[5.344133377075195,0.47839506172839513],[5.344438552856445,0.4776119402985075],[5.344876289367676,0.47682801235839334],[5.345210075378418,0.4760432766615147],[5.345365047454834,0.47525773195876286],[5.346278190612793,0.4744713769984528],[5.347362041473389,0.4736842105263158],[5.350083351135254,0.472896231285493],[5.3508405685424805,0.472107438016529],[5.351219654083252,0.4713178294573644],[5.353487014770508,0.47052740434332985],[5.35407018661499,0.4697361614071391],[5.354445457458496,0.468944099378882],[5.355337142944336,0.46815121698601764],[5.356724739074707,0.46735751295336775],[5.358401298522949,0.46656298600311047],[5.358954906463623,0.4657676348547718],[5.361059188842773,0.4649714582252206],[5.361207008361816,0.46417445482866043],[5.361993312835693,0.46337662337662333],[5.362785816192627,0.4625779625779626],[5.366015434265137,0.46177847113884557],[5.366212844848633,0.46097814776274715],[5.3672075271606445,0.46017699115044247],[5.367696762084961,0.4593749999999999],[5.367812156677246,0.45857217300677433],[5.368983745574951,0.4577685088633994],[5.369260787963867,0.456964006259781],[5.370726108551025,0.4561586638830898],[5.374172210693359,0.4553524804177546],[5.374926567077637,0.45454545454545453],[5.375324249267578,0.4537375849451123],[5.375343322753906,0.45292887029288703],[5.3757758140563965,0.45211930926216637],[5.3758544921875,0.45130890052356026],[5.376593112945557,0.4504976427448927],[5.37681245803833,0.449685534591195],[5.3769097328186035,0.44887257472469855],[5.377424716949463,0.4480587618048269],[5.378458499908447,0.44724409448818897],[5.379737854003906,0.44642857142857145],[5.380102634429932,0.4456121912769311],[5.381851673126221,0.444794952681388],[5.381872653961182,0.44397685428721717],[5.3827996253967285,0.44315789473684214],[5.383522987365723,0.4423380726698262],[5.3844146728515625,0.4415173867228662],[5.384751796722412,0.44069583552978386],[5.384824275970459,0.439873417721519],[5.384857177734375,0.4390501319261213],[5.385678291320801,0.43822597676874336],[5.386279582977295,0.4374009508716324],[5.386345386505127,0.4365750528541226],[5.386546611785889,0.4357482813326281],[5.386584281921387,0.43492063492063493],[5.386887073516846,0.43409211222869243],[5.387365341186523,0.43326271186440685],[5.387444496154785,0.4324324324324324],[5.388312816619873,0.43160127253446445],[5.3890557289123535,0.43076923076923085],[5.389242649078369,0.42993630573248404],[5.389466762542725,0.4291024960169942],[5.391116619110107,0.4282678002125399],[5.391737461090088,0.42743221690590116],[5.391951560974121,0.42659574468085104],[5.392874240875244,0.425758382118148],[5.394021034240723,0.4249201277955272],[5.394716739654541,0.4240809802876932],[5.396419048309326,0.42324093816631125],[5.396462917327881,0.4224],[5.39666748046875,0.4215581643543222],[5.39695405960083,0.42071542979177795],[5.397987365722656,0.4198717948717948],[5.398633003234863,0.41902725815072156],[5.3989787101745605,0.4181818181818182],[5.398979187011719,0.41733547351524874],[5.399196624755859,0.41648822269807273],[5.399570941925049,0.4156400642742367],[5.399780750274658,0.414790996784566],[5.400345325469971,0.413941018766756],[5.400369167327881,0.4130901287553648],[5.400936603546143,0.4122383252818036],[5.401504993438721,0.4113856068743286],[5.401519775390625,0.4105319720580334],[5.401637554168701,0.4096774193548387],[5.401803016662598,0.4088219472834858],[5.402770042419434,0.4079655543595263],[5.403768062591553,0.407108239095315],[5.403892517089844,0.40625],[5.404465675354004,0.40539083557951483],[5.404555797576904,0.40453074433656955],[5.404937744140625,0.40366972477064217],[5.405567169189453,0.40280777537796975],[5.405570983886719,0.4019448946515397],[5.405817985534668,0.40108108108108104],[5.405930995941162,0.40021633315305577],[5.406239986419678,0.3993506493506493],[5.4064412117004395,0.3984840281537628],[5.406582832336426,0.39761646803900325],[5.407127857208252,0.3967479674796748],[5.408033847808838,0.39587852494577],[5.409275531768799,0.3950081389039609],[5.410104274749756,0.3941368078175896],[5.410665035247803,0.3932645301466594],[5.411484718322754,0.39239130434782615],[5.41157341003418,0.3915171288743883],[5.412185192108154,0.39064200217627854],[5.412548065185547,0.38976592270005445],[5.412642478942871,0.38888888888888884],[5.412646770477295,0.3880108991825613],[5.413416385650635,0.38713195201744816],[5.413931369781494,0.38625204582651396],[5.4141106605529785,0.3853711790393013],[5.414187431335449,0.3844893500819225],[5.414618968963623,0.3836065573770492],[5.415111541748047,0.3827227993439038],[5.415460109710693,0.3818380743982494],[5.416204929351807,0.3809523809523809],[5.416219234466553,0.380065717415115],[5.4168219566345215,0.37917808219178084],[5.417513370513916,0.3782894736842105],[5.418393611907959,0.3773998902907295],[5.419101238250732,0.37650933040614715],[5.419134616851807,0.37561779242174625],[5.420840740203857,0.3747252747252747],[5.422110557556152,0.37383177570093457],[5.422365188598633,0.37403740374037403],[5.423217296600342,0.3731425426527243],[5.423377990722656,0.3722466960352423],[5.42360782623291,0.37134986225895317],[5.424294471740723,0.37045203969129],[5.424661159515381,0.36955322669608387],[5.424699783325195,0.3686534216335541],[5.424723148345947,0.3677526228602982],[5.424818992614746,0.36685082872928176],[5.4253010749816895,0.36594803758982863],[5.426306247711182,0.3650442477876107],[5.42694091796875,0.3641394576646375],[5.427311897277832,0.3632336655592469],[5.4278459548950195,0.3623268698060942],[5.427969455718994,0.36141906873614194],[5.428133487701416,0.36051026067665],[5.429043769836426,0.35960044395116536],[5.429117202758789,0.35868961687951134],[5.4297308921813965,0.35777777777777775],[5.430171966552734,0.3568649249583102],[5.430509567260742,0.3559510567296996],[5.430812358856201,0.3550361713967724],[5.430995941162109,0.35412026726057905],[5.431283473968506,0.35320334261838443],[5.432058334350586,0.35228539576365664],[5.432207107543945,0.35136642498605686],[5.432796001434326,0.3504464285714285],[5.432986736297607,0.34952540480178673],[5.4331746101379395,0.3486033519553073],[5.433388710021973,0.3476802683063164],[5.433483123779297,0.34675615212527966],[5.433681488037109,0.3458310016787913],[5.433844566345215,0.34490481522956323],[5.434754848480225,0.34397759103641457],[5.435314178466797,0.34304932735426014],[5.435328006744385,0.34212002243409984],[5.43605375289917,0.34118967452300786],[5.436802387237549,0.3402582818641213],[5.437054634094238,0.33932584269662924],[5.437163352966309,0.33839235525576167],[5.43734073638916,0.3374578177727784],[5.437666416168213,0.3365222284749578],[5.437751293182373,0.3355855855855856],[5.437924861907959,0.3346478873239437],[5.438046455383301,0.3337091319052988],[5.438174247741699,0.3327693175408912],[5.438254356384277,0.33182844243792325],[5.439542770385742,0.33088650479954834],[5.439602375030518,0.32994350282485874],[5.439678192138672,0.32899943470887505],[5.440756320953369,0.32805429864253394],[5.4412126541137695,0.32616081540203856],[5.441850662231445,0.32521246458923514],[5.442657947540283,0.3242630385487528],[5.443838119506836,0.32331253545093586],[5.4438886642456055,0.322360953461975],[5.444047451019287,0.32140829074389554],[5.444112300872803,0.3204545454545455],[5.4441423416137695,0.31949971574758385],[5.444212436676025,0.31854379977246866],[5.444650173187256,0.3175867956744451],[5.445503234863281,0.316628701594533],[5.445688724517822,0.3156695156695156],[5.445789813995361,0.314709236031927],[5.446625232696533,0.3137478608100399],[5.447299003601074,0.31278538812785384],[5.447534561157227,0.3118218161050828],[5.447646141052246,0.3108571428571429],[5.448878765106201,0.3098913664951401],[5.449191093444824,0.3089244851258582],[5.44924259185791,0.30795649685174586],[5.450527667999268,0.3069873997709049],[5.4507317543029785,0.3060171919770774],[5.450873851776123,0.305045871559633],[5.450875282287598,0.30407343660355707],[5.45093297958374,0.3030998851894374],[5.450953006744385,0.30212521539345205],[5.450981140136719,0.3011494252873563],[5.450992107391357,0.3001725129384704],[5.451024532318115,0.2991944764096663],[5.45103120803833,0.2982153137593552],[5.451715469360352,0.2972350230414747],[5.451725959777832,0.2962536023054754],[5.452066421508789,0.29527104959630907],[5.45284366607666,0.2942873629544143],[5.4528913497924805,0.29330254041570436],[5.453354835510254,0.29231658001155403],[5.454234600067139,0.29132947976878615],[5.454595565795898,0.29034123770965875],[5.455030918121338,0.28935185185185186],[5.456283092498779,0.288361320208454],[5.456953525543213,0.2873696407879491],[5.4570698738098145,0.2863768115942029],[5.457098960876465,0.2853828306264501],[5.4575090408325195,0.2843876958792803],[5.457779884338379,0.28339140534262486],[5.458083152770996,0.2823939570017432],[5.45852518081665,0.2813953488372093],[5.458826541900635,0.2803955788248982],[5.459427356719971,0.27939464493597205],[5.459429740905762,0.2783925451368667],[5.459983825683594,0.2773892773892773],[5.460076808929443,0.27638483965014576],[5.460348129272461,0.27537922987164526],[5.460695266723633,0.27437244600116756],[5.460920810699463,0.2733644859813084],[5.4609503746032715,0.27235534774985387],[5.460981845855713,0.2713450292397661],[5.462215423583984,0.2703335283791691],[5.462395668029785,0.2693208430913349],[5.462399959564209,0.268306971294669],[5.463396072387695,0.2672919109026964],[5.46360445022583,0.2662756598240469],[5.463891983032227,0.26525821596244126],[5.463930130004883,0.2642395772166765],[5.464385032653809,0.2621987066431511],[5.464662075042725,0.2611764705882353],[5.465183258056641,0.2601530311948205],[5.465186595916748,0.2591283863368669],[5.465556621551514,0.25810253388332355],[5.466118335723877,0.25707547169811323],[5.466707706451416,0.25604719764011796],[5.466928005218506,0.2550177095631641],[5.467002868652344,0.25398700531600715],[5.467691421508789,0.2529550827423168],[5.467764854431152,0.25192193968066234],[5.467899799346924,0.250887573964497],[5.468293190002441,0.24985198342214326],[5.468551158905029,0.2488151658767772],[5.468980312347412,0.2477771191464138],[5.4692840576171875,0.24673784104389085],[5.471034526824951,0.2456973293768546],[5.4710845947265625,0.24465558194774342],[5.4714860916137695,0.24361259655377301],[5.471813201904297,0.24256837098692033],[5.473374366760254,0.24152290303390841],[5.473401069641113,0.24047619047619048],[5.473512172698975,0.23942823108993452],[5.473579406738281,0.23837902264600713],[5.473965644836426,0.23732856290995827],[5.474264144897461,0.23627684964200477],[5.474727153778076,0.23522388059701496],[5.474970817565918,0.23416965352449223],[5.475193977355957,0.23311416616855946],[5.4752397537231445,0.23205741626794257],[5.475550174713135,0.2309994015559545],[5.476508140563965,0.22994011976047907],[5.477025985717773,0.22887956860395448],[5.477056503295898,0.22781774580335734],[5.4772796630859375,0.22675464907018594],[5.477540016174316,0.22569027611044415],[5.477658748626709,0.22462462462462462],[5.478178024291992,0.22355769230769232],[5.478548526763916,0.22248947684906797],[5.47908353805542,0.2214199759326113],[5.4791436195373535,0.22034918723660443],[5.479236602783203,0.21927710843373496],[5.4797468185424805,0.218203737191079],[5.480152130126953,0.21712907117008445],[5.480316162109375,0.216053108026554],[5.481484889984131,0.214975845410628],[5.481960296630859,0.2138972809667674],[5.482814311981201,0.2128174123337364],[5.483131408691406,0.21173623714458562],[5.483461380004883,0.21065375302663433],[5.4839863777160645,0.20956995760145367],[5.485162258148193,0.2084848484848485],[5.485272407531738,0.20739842328684052],[5.4855756759643555,0.2063106796116505],[5.4856462478637695,0.2052216150576806],[5.485658168792725,0.20413122721749694],[5.485939979553223,0.20303951367781153],[5.486815452575684,0.20194647201946475],[5.4868693351745605,0.20085209981740715],[5.487109184265137,0.1997563946406821],[5.487266540527344,0.1986593540524071],[5.487471580505371,0.1975609756097561],[5.487951755523682,0.19646125686394145],[5.4879961013793945,0.19536019536019536],[5.488997936248779,0.19425778863775198],[5.490118503570557,0.19315403422982885],[5.490787506103516,0.19204892966360856],[5.49094295501709,0.1909424724602203],[5.491738319396973,0.1898346601347214],[5.491753101348877,0.1887254901960784],[5.49190092086792,0.18761496014714898],[5.492162704467773,0.1865030674846626],[5.4925055503845215,0.185389809699202],[5.492796897888184,0.18427518427518427],[5.493583679199219,0.18315918869084205],[5.494071006774902,0.1820418204182042],[5.494251251220703,0.1809230769230769],[5.495283126831055,0.17980295566502466],[5.4957122802734375,0.1786814540973506],[5.496224403381348,0.1775585696670777],[5.496428489685059,0.17643429981492906],[5.497269630432129,0.17530864197530865],[5.497628211975098,0.17418159357628168],[5.4985270500183105,0.17305315203955499],[5.500370025634766,0.1719233147804576],[5.5005083084106445,0.1707920792079208],[5.5015645027160645,0.1696594427244582],[5.5018391609191895,0.1685254027261462],[5.5022053718566895,0.16738995660260386],[5.502677917480469,0.16625310173697266],[5.5030107498168945,0.16511483550589695],[5.503175735473633,0.16397515527950313],[5.503434181213379,0.1628340584213797],[5.50386905670166,0.16169154228855723],[5.503878116607666,0.16054760423148726],[5.503910541534424,0.1594022415940224],[5.504055023193359,0.15825545171339564],[5.5054121017456055,0.1571072319201995],[5.506379127502441,0.15595757953836556],[5.506448268890381,0.15480649188514356],[5.506549835205078,0.15365396627108055],[5.5065789222717285,0.1525],[5.507222652435303,0.15134459036898062],[5.507547855377197,0.15018773466833538],[5.508030891418457,0.14902943018159048],[5.509675979614258,0.14786967418546368],[5.510188102722168,0.14670846394984324],[5.510259628295898,0.14554579673776663],[5.511025905609131,0.14438166980539863],[5.511415481567383,0.14321608040201003],[5.511470317840576,0.142049025769956],[5.512455463409424,0.14088050314465408],[5.513064861297607,0.13971050975456262],[5.513265132904053,0.1385390428211587],[5.513535022735596,0.1373660995589162],[5.513622283935547,0.13619167717528372],[5.513887882232666,0.13501577287066246],[5.514081001281738,0.1338383838383838],[5.514106750488281,0.13265950726468728],[5.515140533447266,0.13147914032869787],[5.515749931335449,0.13029728020240355],[5.515854358673096,0.1291139240506329],[5.5162787437438965,0.1279290690310323],[5.516559600830078,0.12674271229404308],[5.517024993896484,0.12555485098287886],[5.517270088195801,0.12436548223350255],[5.517797470092773,0.12317460317460316],[5.518641948699951,0.12198221092757307],[5.518749713897705,0.12078830260648443],[5.518943786621094,0.11959287531806616],[5.519103527069092,0.11839592616168046],[5.519873142242432,0.11847133757961785],[5.52036190032959,0.11727214786488208],[5.523470401763916,0.11607142857142856],[5.524409770965576,0.1148691767708998],[5.52647066116333,0.11366538952745849],[5.527515888214111,0.11246006389776357],[5.5277252197265625,0.11125319693094629],[5.528584957122803,0.11004478566858605],[5.52861213684082,0.1088348271446863],[5.529273986816406,0.10762331838565023],[5.529603481292725,0.10641025641025642],[5.529646396636963,0.10519563822963438],[5.5299506187438965,0.10397946084724004],[5.53071403503418,0.10276172125883108],[5.532960414886475,0.10154241645244216],[5.534492492675781,0.10032154340836012],[5.534606456756592,0.0990990990990991],[5.534728050231934,0.0978750804893754],[5.53472900390625,0.09664948453608248],[5.535111904144287,0.09542230818826564],[5.5358781814575195,0.09419354838709679],[5.536415100097656,0.09296320206584893],[5.53729248046875,0.09173126614987079],[5.537821292877197,0.09049773755656107],[5.538136005401611,0.08926261319534282],[5.5381388664245605,0.08802588996763754],[5.53870153427124,0.08678756476683938],[5.538969993591309,0.08554763447828906],[5.539653778076172,0.08430609597924774],[5.540896892547607,0.08306294613887087],[5.54340934753418,0.08181818181818182],[5.543581962585449,0.08057179987004548],[5.544709205627441,0.07932379713914174],[5.545493125915527,0.07807417046193883],[5.54595947265625,0.07682291666666667],[5.5469512939453125,0.0755700325732899],[5.547216415405273,0.07431551499348109],[5.5491108894348145,0.07305936073059362],[5.549431800842285,0.07180156657963448],[5.5505170822143555,0.07054212932723711],[5.551426410675049,0.06928104575163398],[5.5516037940979,0.06801831262262917],[5.551705360412598,0.06675392670157068],[5.5517425537109375,0.06548788474132285],[5.551863670349121,0.06422018348623854],[5.552540302276611,0.06295081967213115],[5.553042411804199,0.06167979002624672],[5.553325653076172,0.06040709126723572],[5.553946495056152,0.059132720105124846],[5.554219722747803,0.05785667324128863],[5.55423641204834,0.05657894736842105],[5.554789066314697,0.05529953917050691],[5.5570902824401855,0.054018445322793145],[5.557783603668213,0.05273566249176005],[5.558842658996582,0.051451187335092345],[5.559474468231201,0.050165016501650166],[5.561708927154541,0.0488771466314399],[5.562946796417236,0.04758757435558494],[5.563033580780029,0.046296296296296294],[5.564709663391113,0.045003309066843154],[5.5654730796813965,0.043708609271523174],[5.5659589767456055,0.04241219350563286],[5.566808223724365,0.04111405835543767],[5.567758560180664,0.039814200398142],[5.570086479187012,0.03851261620185923],[5.570338249206543,0.0372093023255814],[5.57199764251709,0.03590425531914894],[5.572871685028076,0.03459747172322023],[5.573123455047607,0.033288948069241014],[5.573521614074707,0.031978680879413725],[5.576064109802246,0.030666666666666665],[5.577417850494385,0.02935290193462308],[5.577928066253662,0.02803738317757009],[5.578514099121094,0.026720106880427523],[5.582254409790039,0.02540106951871658],[5.585228443145752,0.02408026755852843],[5.5860795974731445,0.02275769745649264],[5.586142063140869,0.021433355659745478],[5.593440532684326,0.020107238605898123],[5.594103813171387,0.018779342723004695],[5.595059394836426,0.0174496644295302],[5.596238136291504,0.016118200134318333],[5.5963616371154785,0.014784946236559139],[5.599128723144531,0.013449899125756557],[5.600484848022461,0.012113055181695828],[5.604204177856445,0.010774410774410775],[5.604269504547119,0.009433962264150945],[5.604974746704102,0.008091706001348618],[5.606573581695557,0.006747638326585696],[5.612203121185303,0.005401755570560432],[5.617467403411865,0.004054054054054053],[5.640913009643555,0.002704530087897228],[5.645580291748047,0.0013531799729364004],[null,0.0]],\"hovertemplate\":\"Threshold: %{customdata[0]:.4f} <br>Precision: %{y:.4f} <br>Recall: %{x:.4f}  <br>F1 score: %{customdata[1]:.4f} <extra></extra>\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"PR Curve (AUC=0.99)\",\"showlegend\":true,\"x\":[1.0,0.98645903859174,0.985781990521327,0.9851049424509141,0.984427894380501,0.984427894380501,0.983750846310088,0.983073798239675,0.982396750169262,0.9817197020988491,0.981042654028436,0.980365605958023,0.97968855788761,0.979011509817197,0.9783344617467841,0.977657413676371,0.976980365605958,0.976303317535545,0.975626269465132,0.9749492213947191,0.974272173324306,0.974272173324306,0.973595125253893,0.97291807718348,0.972241029113067,0.9715639810426541,0.970886932972241,0.970209884901828,0.969532836831415,0.968855788761002,0.9681787406905891,0.967501692620176,0.966824644549763,0.96614759647935,0.965470548408937,0.9647935003385241,0.964116452268111,0.963439404197698,0.962762356127285,0.9620853080568721,0.9614082599864591,0.960731211916046,0.960054163845633,0.95937711577522,0.9587000677048071,0.9580230196343941,0.957345971563981,0.956668923493568,0.955991875423155,0.955991875423155,0.9553148273527421,0.9546377792823291,0.953960731211916,0.953283683141503,0.95260663507109,0.9519295870006771,0.9512525389302641,0.9512525389302641,0.950575490859851,0.949898442789438,0.949221394719025,0.9485443466486121,0.9478672985781991,0.947190250507786,0.946513202437373,0.94583615436696,0.9451591062965471,0.9444820582261341,0.943805010155721,0.943127962085308,0.942450914014895,0.9417738659444821,0.9410968178740691,0.940419769803656,0.939742721733243,0.9390656736628301,0.9383886255924171,0.9383886255924171,0.9383886255924171,0.9377115775220041,0.937034529451591,0.936357481381178,0.9356804333107651,0.9350033852403521,0.9343263371699391,0.933649289099526,0.932972241029113,0.9322951929587001,0.9316181448882871,0.9316181448882871,0.9309410968178741,0.930264048747461,0.929587000677048,0.9289099526066351,0.9282329045362221,0.9275558564658091,0.926878808395396,0.926878808395396,0.926201760324983,0.9255247122545701,0.9248476641841571,0.9241706161137441,0.923493568043331,0.922816519972918,0.9221394719025051,0.9214624238320921,0.9207853757616791,0.920108327691266,0.919431279620853,0.9187542315504401,0.9180771834800271,0.9174001354096141,0.916723087339201,0.9160460392687881,0.9153689911983751,0.9146919431279621,0.9140148950575491,0.913337846987136,0.913337846987136,0.9126607989167231,0.9119837508463101,0.9113067027758971,0.9106296547054841,0.909952606635071,0.9092755585646581,0.9085985104942451,0.9079214624238321,0.9072444143534191,0.906567366283006,0.9058903182125931,0.9058903182125931,0.9052132701421801,0.9045362220717671,0.9038591740013541,0.903182125930941,0.9025050778605281,0.9018280297901151,0.9011509817197021,0.9004739336492891,0.9004739336492891,0.899796885578876,0.8991198375084631,0.8991198375084631,0.8984427894380501,0.8977657413676371,0.8970886932972241,0.896411645226811,0.8957345971563981,0.8950575490859851,0.8943805010155721,0.8937034529451591,0.8930264048747462,0.8923493568043331,0.8923493568043331,0.8916723087339201,0.8909952606635071,0.8903182125930941,0.8896411645226812,0.8889641164522681,0.8882870683818551,0.8876100203114421,0.8869329722410291,0.8862559241706162,0.8855788761002031,0.8849018280297901,0.8842247799593771,0.8835477318889641,0.8828706838185512,0.8821936357481381,0.8815165876777251,0.8808395396073121,0.8801624915368991,0.8794854434664862,0.8794854434664862,0.8788083953960731,0.8781313473256601,0.8774542992552471,0.8767772511848341,0.8761002031144212,0.8754231550440081,0.8747461069735951,0.8740690589031821,0.8733920108327691,0.8727149627623562,0.8720379146919431,0.8713608666215301,0.8706838185511171,0.8700067704807042,0.8693297224102912,0.8686526743398781,0.8679756262694651,0.8672985781990521,0.8666215301286392,0.8659444820582262,0.8652674339878131,0.8645903859174001,0.8639133378469871,0.8632362897765742,0.8625592417061612,0.8618821936357481,0.8612051455653351,0.8605280974949221,0.8598510494245092,0.8591740013540962,0.8584969532836831,0.8578199052132701,0.8571428571428571,0.8564658090724442,0.8557887610020312,0.8551117129316181,0.8551117129316181,0.8544346648612051,0.8537576167907921,0.8530805687203792,0.8524035206499662,0.8517264725795531,0.8510494245091401,0.8503723764387271,0.8496953283683142,0.8490182802979012,0.8483412322274881,0.8476641841570751,0.8469871360866622,0.8463100880162492,0.8456330399458362,0.8449559918754231,0.8442789438050101,0.8436018957345972,0.8436018957345972,0.8429248476641842,0.8422477995937712,0.8415707515233581,0.8408937034529451,0.8402166553825322,0.8395396073121192,0.8388625592417062,0.8381855111712931,0.8375084631008801,0.8375084631008801,0.8375084631008801,0.8368314150304672,0.8361543669600542,0.8354773188896412,0.8354773188896412,0.8348002708192281,0.8341232227488151,0.8334461746784022,0.8327691266079892,0.8320920785375762,0.8314150304671631,0.8307379823967501,0.8300609343263372,0.8293838862559242,0.8287068381855112,0.8280297901150981,0.8273527420446851,0.8266756939742722,0.8259986459038592,0.8253215978334462,0.8253215978334462,0.8246445497630331,0.8239675016926202,0.8232904536222072,0.8232904536222072,0.8226134055517942,0.8219363574813812,0.8212593094109681,0.8205822613405552,0.8199052132701422,0.8192281651997292,0.8185511171293162,0.8178740690589031,0.8178740690589031,0.8171970209884902,0.8171970209884902,0.8165199729180772,0.8165199729180772,0.8158429248476642,0.8151658767772512,0.8144888287068381,0.8138117806364252,0.8131347325660122,0.8124576844955992,0.8117806364251862,0.8111035883547731,0.8104265402843602,0.8104265402843602,0.8104265402843602,0.8104265402843602,0.8097494922139472,0.8090724441435342,0.8083953960731212,0.8077183480027081,0.8077183480027081,0.8070412999322952,0.8063642518618822,0.8056872037914692,0.8050101557210562,0.8043331076506431,0.8036560595802302,0.8029790115098172,0.8029790115098172,0.8023019634394042,0.8016249153689912,0.8009478672985783,0.8009478672985783,0.8002708192281652,0.7995937711577522,0.7989167230873392,0.7982396750169262,0.7982396750169262,0.7975626269465133,0.7968855788761002,0.7962085308056872,0.7955314827352742,0.7948544346648612,0.7941773865944483,0.7935003385240352,0.7928232904536222,0.7921462423832092,0.7914691943127962,0.7907921462423833,0.7901150981719702,0.7894380501015572,0.7887610020311442,0.7880839539607312,0.7874069058903183,0.7867298578199052,0.7860528097494922,0.7860528097494922,0.7853757616790792,0.7846987136086662,0.7840216655382533,0.7833446174678402,0.7826675693974272,0.7819905213270142,0.7813134732566012,0.7806364251861883,0.7799593771157752,0.7792823290453622,0.7786052809749492,0.7786052809749492,0.7786052809749492,0.7779282329045363,0.7772511848341233,0.7765741367637102,0.7758970886932972,0.7752200406228842,0.7745429925524713,0.7745429925524713,0.7738659444820583,0.7731888964116452,0.7725118483412322,0.7718348002708192,0.7718348002708192,0.7711577522004063,0.7704807041299933,0.7698036560595802,0.7691266079891672,0.7684495599187542,0.7677725118483413,0.7670954637779283,0.7664184157075152,0.7657413676371022,0.7650643195666892,0.7643872714962763,0.7637102234258633,0.7630331753554502,0.7623561272850372,0.7616790792146242,0.7610020311442113,0.7603249830737983,0.7596479350033852,0.7589708869329722,0.7582938388625592,0.7576167907921463,0.7569397427217333,0.7562626946513202,0.7555856465809072,0.7549085985104943,0.7542315504400813,0.7535545023696683,0.7528774542992552,0.7522004062288422,0.7515233581584293,0.7508463100880163,0.7501692620176033,0.7494922139471902,0.7488151658767772,0.7481381178063643,0.7474610697359513,0.7467840216655383,0.7461069735951252,0.7454299255247122,0.7447528774542993,0.7440758293838863,0.7440758293838863,0.7433987813134733,0.7427217332430602,0.7420446851726472,0.7413676371022343,0.7413676371022343,0.7406905890318213,0.7400135409614083,0.7393364928909952,0.7386594448205822,0.7379823967501693,0.7373053486797563,0.7366283006093433,0.7359512525389302,0.7352742044685172,0.7345971563981043,0.7339201083276913,0.7332430602572783,0.7325660121868652,0.7318889641164523,0.7312119160460393,0.7305348679756263,0.7298578199052133,0.7291807718348002,0.7285037237643873,0.7278266756939743,0.7271496276235613,0.7264725795531483,0.7257955314827352,0.7251184834123223,0.7244414353419093,0.7237643872714963,0.7230873392010833,0.7224102911306702,0.7217332430602573,0.7210561949898443,0.7203791469194313,0.7197020988490183,0.7190250507786052,0.7190250507786052,0.7183480027081923,0.7183480027081923,0.7176709546377793,0.7169939065673663,0.7163168584969533,0.7156398104265402,0.7149627623561273,0.7142857142857143,0.7136086662153013,0.7129316181448883,0.7122545700744752,0.7115775220040623,0.7109004739336493,0.7102234258632363,0.7095463777928233,0.7088693297224103,0.7081922816519973,0.7075152335815843,0.7068381855111713,0.7061611374407583,0.7054840893703453,0.7048070412999323,0.7041299932295193,0.7034529451591063,0.7027758970886933,0.7020988490182803,0.7014218009478673,0.7007447528774543,0.7000677048070413,0.6993906567366283,0.6987136086662153,0.6980365605958023,0.6973595125253893,0.6966824644549763,0.6960054163845633,0.6953283683141503,0.6946513202437373,0.6939742721733243,0.6939742721733243,0.6932972241029113,0.6926201760324983,0.6919431279620853,0.6912660798916723,0.6905890318212593,0.6899119837508463,0.6892349356804333,0.6885578876100203,0.6878808395396073,0.6872037914691943,0.6865267433987813,0.6858496953283684,0.6851726472579553,0.6844955991875423,0.6838185511171293,0.6831415030467163,0.6824644549763034,0.6817874069058903,0.6811103588354773,0.6804333107650643,0.6804333107650643,0.6797562626946513,0.6790792146242384,0.6784021665538253,0.6777251184834123,0.6770480704129993,0.6763710223425863,0.6756939742721734,0.6750169262017603,0.6743398781313473,0.6736628300609343,0.6729857819905213,0.6723087339201084,0.6716316858496953,0.6709546377792823,0.6702775897088693,0.6696005416384563,0.6689234935680434,0.6682464454976303,0.6675693974272173,0.6668923493568043,0.6662153012863913,0.6655382532159784,0.6648612051455653,0.6641841570751523,0.6635071090047393,0.6628300609343263,0.6621530128639134,0.6614759647935003,0.6607989167230873,0.6601218686526743,0.6594448205822614,0.6587677725118484,0.6580907244414353,0.6574136763710223,0.6567366283006093,0.6560595802301964,0.6553825321597834,0.6547054840893703,0.6540284360189573,0.6533513879485443,0.6526743398781314,0.6519972918077184,0.6513202437373053,0.6506431956668923,0.6499661475964793,0.6492890995260664,0.6486120514556534,0.6479350033852403,0.6472579553148273,0.6465809072444143,0.6459038591740014,0.6452268111035884,0.6445497630331753,0.6438727149627623,0.6431956668923493,0.6431956668923493,0.6425186188219364,0.6418415707515234,0.6411645226811103,0.6404874746106973,0.6398104265402843,0.6391333784698714,0.6384563303994584,0.6377792823290453,0.6371022342586323,0.6364251861882194,0.6357481381178064,0.6350710900473934,0.6343940419769803,0.6337169939065673,0.6330399458361544,0.6323628977657414,0.6316858496953284,0.6310088016249153,0.6303317535545023,0.6296547054840894,0.6289776574136764,0.6283006093432634,0.6276235612728503,0.6269465132024373,0.6262694651320244,0.6255924170616114,0.6249153689911984,0.6242383209207854,0.6235612728503723,0.6228842247799594,0.6222071767095464,0.6215301286391334,0.6208530805687204,0.6201760324983073,0.6194989844278944,0.6188219363574814,0.6181448882870684,0.6174678402166554,0.6167907921462423,0.6161137440758294,0.6154366960054164,0.6147596479350034,0.6140825998645904,0.6134055517941774,0.6127285037237644,0.6120514556533514,0.6113744075829384,0.6106973595125254,0.6100203114421124,0.6093432633716994,0.6086662153012864,0.6079891672308734,0.6073121191604604,0.6066350710900474,0.6059580230196344,0.6052809749492214,0.6046039268788084,0.6039268788083954,0.6032498307379824,0.6025727826675694,0.6018957345971564,0.6012186865267434,0.6005416384563304,0.5998645903859174,0.5991875423155044,0.5985104942450914,0.5978334461746784,0.5971563981042654,0.5964793500338524,0.5958023019634394,0.5951252538930264,0.5951252538930264,0.5944482058226134,0.5937711577522004,0.5930941096817874,0.5924170616113744,0.5917400135409614,0.5910629654705484,0.5903859174001355,0.5897088693297224,0.5890318212593094,0.5883547731888964,0.5876777251184834,0.5870006770480705,0.5863236289776574,0.5856465809072444,0.5849695328368314,0.5842924847664184,0.5836154366960055,0.5829383886255924,0.5822613405551794,0.5815842924847664,0.5815842924847664,0.5809072444143534,0.5802301963439405,0.5795531482735274,0.5788761002031144,0.5781990521327014,0.5775220040622884,0.5768449559918755,0.5761679079214624,0.5761679079214624,0.5754908598510494,0.5748138117806364,0.5741367637102234,0.5734597156398105,0.5727826675693974,0.5721056194989844,0.5714285714285714,0.5707515233581584,0.5700744752877455,0.5693974272173324,0.5687203791469194,0.5680433310765064,0.5673662830060935,0.5666892349356805,0.5660121868652674,0.5653351387948544,0.5646580907244414,0.5639810426540285,0.5633039945836155,0.5626269465132024,0.5619498984427894,0.5612728503723764,0.5605958023019635,0.5599187542315505,0.5592417061611374,0.5585646580907244,0.5578876100203114,0.5572105619498985,0.5565335138794855,0.5558564658090724,0.5551794177386594,0.5545023696682464,0.5538253215978335,0.5531482735274205,0.5524712254570074,0.5517941773865944,0.5511171293161814,0.5504400812457685,0.5497630331753555,0.5490859851049424,0.5484089370345294,0.5477318889641164,0.5470548408937035,0.5463777928232905,0.5457007447528774,0.5450236966824644,0.5443466486120515,0.5436696005416385,0.5429925524712255,0.5423155044008124,0.5416384563303994,0.5409614082599865,0.5402843601895735,0.5396073121191605,0.5389302640487474,0.5382532159783344,0.5375761679079215,0.5368991198375085,0.5362220717670955,0.5355450236966824,0.5348679756262694,0.5341909275558565,0.5335138794854435,0.5328368314150305,0.5321597833446174,0.5314827352742044,0.5308056872037915,0.5301286391333785,0.5294515910629655,0.5287745429925524,0.5280974949221394,0.5274204468517265,0.5267433987813135,0.5260663507109005,0.5253893026404874,0.5247122545700744,0.5240352064996615,0.5233581584292485,0.5226811103588355,0.5220040622884224,0.5213270142180095,0.5206499661475965,0.5199729180771835,0.5192958700067705,0.5186188219363574,0.5179417738659445,0.5172647257955315,0.5172647257955315,0.5165876777251185,0.5159106296547055,0.5152335815842924,0.5145565335138795,0.5138794854434665,0.5132024373730535,0.5125253893026405,0.5118483412322274,0.5111712931618145,0.5104942450914015,0.5098171970209885,0.5091401489505755,0.5084631008801624,0.5077860528097495,0.5071090047393365,0.5064319566689235,0.5057549085985105,0.5050778605280974,0.5044008124576845,0.5037237643872715,0.5030467163168585,0.5023696682464455,0.5016926201760324,0.5010155721056195,0.5003385240352065,0.4996614759647935,0.4989844278943805,0.4983073798239675,0.4976303317535545,0.4969532836831415,0.4962762356127285,0.4955991875423155,0.4949221394719025,0.4942450914014895,0.4935680433310765,0.4928909952606635,0.4922139471902505,0.4915368991198375,0.49085985104942453,0.4901828029790115,0.4895057549085985,0.4888287068381855,0.4881516587677725,0.48747461069735953,0.4867975626269465,0.4861205145565335,0.4854434664861205,0.4847664184157075,0.48408937034529453,0.4834123222748815,0.4827352742044685,0.4820582261340555,0.4813811780636425,0.48070412999322953,0.4800270819228165,0.47935003385240355,0.4786729857819905,0.4779959377115775,0.47731888964116453,0.4766418415707515,0.47596479350033855,0.4752877454299255,0.4746106973595125,0.47393364928909953,0.4732566012186865,0.47257955314827355,0.4719025050778605,0.4712254570074475,0.4712254570074475,0.47054840893703453,0.4698713608666215,0.46919431279620855,0.4685172647257955,0.46784021665538256,0.46716316858496953,0.4664861205145565,0.46580907244414355,0.4651320243737305,0.46445497630331756,0.46377792823290453,0.4631008801624915,0.46242383209207855,0.4617467840216655,0.46106973595125256,0.46039268788083954,0.4597156398104265,0.45903859174001355,0.4583615436696005,0.45768449559918756,0.45700744752877454,0.45633039945836157,0.45565335138794855,0.4549763033175355,0.45429925524712256,0.45362220717670954,0.45294515910629657,0.45226811103588355,0.4515910629654705,0.45091401489505756,0.45023696682464454,0.44955991875423157,0.44888287068381855,0.4482058226134055,0.44752877454299256,0.44685172647257954,0.44617467840216657,0.44549763033175355,0.4448205822613406,0.44414353419092756,0.44346648612051454,0.44278943805010157,0.44211238997968855,0.4414353419092756,0.44075829383886256,0.44008124576844954,0.43940419769803657,0.43872714962762355,0.4380501015572106,0.43737305348679756,0.43669600541638454,0.43601895734597157,0.43601895734597157,0.43534190927555855,0.4346648612051456,0.43398781313473256,0.4333107650643196,0.43263371699390657,0.43195666892349355,0.4312796208530806,0.43060257278266756,0.4299255247122546,0.42924847664184157,0.42857142857142855,0.4278943805010156,0.42721733243060256,0.4265402843601896,0.42586323628977657,0.42518618821936355,0.4245091401489506,0.42383209207853756,0.4231550440081246,0.42247799593771157,0.4218009478672986,0.4211238997968856,0.42044685172647256,0.4197698036560596,0.41909275558564657,0.4184157075152336,0.4177386594448206,0.41706161137440756,0.4163845633039946,0.41570751523358157,0.4150304671631686,0.4143534190927556,0.41367637102234256,0.4129993229519296,0.41232227488151657,0.4116452268111036,0.4109681787406906,0.4102911306702776,0.4096140825998646,0.40893703452945157,0.4082599864590386,0.4075829383886256,0.4069058903182126,0.4062288422477996,0.40555179417738657,0.4048747461069736,0.4048747461069736,0.4041976980365606,0.4035206499661476,0.4028436018957346,0.40216655382532157,0.4014895057549086,0.4008124576844956,0.4001354096140826,0.3994583615436696,0.3987813134732566,0.3981042654028436,0.3974272173324306,0.3967501692620176,0.3960731211916046,0.3953960731211916,0.3947190250507786,0.3940419769803656,0.3933649289099526,0.3926878808395396,0.3920108327691266,0.3913337846987136,0.3906567366283006,0.3899796885578876,0.3893026404874746,0.3886255924170616,0.3879485443466486,0.38727149627623564,0.3865944482058226,0.3859174001354096,0.3852403520649966,0.3845633039945836,0.38388625592417064,0.3832092078537576,0.3825321597833446,0.3818551117129316,0.3811780636425186,0.38050101557210564,0.3798239675016926,0.3791469194312796,0.3784698713608666,0.3777928232904536,0.37711577522004064,0.3764387271496276,0.37576167907921465,0.37508463100880163,0.3744075829383886,0.37373053486797564,0.3730534867975626,0.37237643872714965,0.37169939065673663,0.3710223425863236,0.37034529451591064,0.3696682464454976,0.36899119837508465,0.36831415030467163,0.3676371022342586,0.36696005416384564,0.3662830060934326,0.36560595802301965,0.36492890995260663,0.36425186188219366,0.36357481381178064,0.3628977657413676,0.36222071767095465,0.36154366960054163,0.36086662153012866,0.36018957345971564,0.3595125253893026,0.35883547731888965,0.35815842924847663,0.35748138117806366,0.35680433310765064,0.3561272850372376,0.35545023696682465,0.35477318889641163,0.35409614082599866,0.35341909275558564,0.3527420446851727,0.35206499661475965,0.35138794854434663,0.35071090047393366,0.35003385240352064,0.3493568043331077,0.34867975626269465,0.34800270819228163,0.34732566012186866,0.34664861205145564,0.3459715639810427,0.34529451591062965,0.34461746784021663,0.34394041976980366,0.34326337169939064,0.3425863236289777,0.34190927555856465,0.3412322274881517,0.34055517941773866,0.33987813134732564,0.3392010832769127,0.33852403520649965,0.3378469871360867,0.33716993906567366,0.33649289099526064,0.3358158429248477,0.33513879485443465,0.3344617467840217,0.33378469871360866,0.33310765064319564,0.3324306025727827,0.33175355450236965,0.3310765064319567,0.33039945836154366,0.3297224102911307,0.3290453622207177,0.3290453622207177,0.32836831415030465,0.3276912660798917,0.32701421800947866,0.3263371699390657,0.3256601218686527,0.32498307379823965,0.3243060257278267,0.32362897765741366,0.3229519295870007,0.3222748815165877,0.32159783344617465,0.3209207853757617,0.32024373730534866,0.3195666892349357,0.3188896411645227,0.3182125930941097,0.3175355450236967,0.31685849695328366,0.3161814488828707,0.3155044008124577,0.3148273527420447,0.3141503046716317,0.31347325660121866,0.3127962085308057,0.3121191604603927,0.3114421123899797,0.3107650643195667,0.31008801624915366,0.3094109681787407,0.3087339201083277,0.3080568720379147,0.3073798239675017,0.3067027758970887,0.3060257278266757,0.3053486797562627,0.3046716316858497,0.3039945836154367,0.3033175355450237,0.3026404874746107,0.3019634394041977,0.3012863913337847,0.3006093432633717,0.2999322951929587,0.2992552471225457,0.2985781990521327,0.2979011509817197,0.2972241029113067,0.2965470548408937,0.2958700067704807,0.29519295870006773,0.2945159106296547,0.2938388625592417,0.2931618144888287,0.2924847664184157,0.29180771834800273,0.2911306702775897,0.2904536222071767,0.2897765741367637,0.2890995260663507,0.28842247799593773,0.2877454299255247,0.2870683818551117,0.2863913337846987,0.2857142857142857,0.28503723764387273,0.2843601895734597,0.28368314150304674,0.2830060934326337,0.2823290453622207,0.28165199729180773,0.2809749492213947,0.28029790115098174,0.2796208530805687,0.2789438050101557,0.27826675693974273,0.2775897088693297,0.27691266079891674,0.2762356127285037,0.2755585646580907,0.27488151658767773,0.2742044685172647,0.27352742044685174,0.2728503723764387,0.27217332430602575,0.27149627623561273,0.2708192281651997,0.27014218009478674,0.2694651320243737,0.26878808395396075,0.26811103588354773,0.2674339878131347,0.26675693974272174,0.2660798916723087,0.26540284360189575,0.26472579553148273,0.2640487474610697,0.26337169939065674,0.2626946513202437,0.26201760324983076,0.26134055517941773,0.26066350710900477,0.25998645903859174,0.2593094109681787,0.25863236289776576,0.25795531482735273,0.25727826675693977,0.25660121868652674,0.2559241706161137,0.25524712254570076,0.25457007447528773,0.25389302640487477,0.25321597833446174,0.2525389302640487,0.25186188219363576,0.25118483412322273,0.25050778605280977,0.24983073798239674,0.24915368991198375,0.24847664184157076,0.24779959377115776,0.24712254570074474,0.24644549763033174,0.24576844955991875,0.24509140148950576,0.24441435341909276,0.24373730534867977,0.24306025727826674,0.24238320920785375,0.24170616113744076,0.24102911306702776,0.24035206499661477,0.23967501692620177,0.23899796885578875,0.23832092078537576,0.23764387271496276,0.23696682464454977,0.23628977657413677,0.23561272850372375,0.23493568043331076,0.23425863236289776,0.23358158429248477,0.23290453622207177,0.23222748815165878,0.23155044008124576,0.23087339201083276,0.23019634394041977,0.23019634394041977,0.22951929587000677,0.22884224779959378,0.22816519972918078,0.22748815165876776,0.22681110358835477,0.22613405551794177,0.22545700744752878,0.22477995937711578,0.22410291130670276,0.22342586323628977,0.22274881516587677,0.22207176709546378,0.22139471902505078,0.2207176709546378,0.22004062288422477,0.21936357481381177,0.21868652674339878,0.21800947867298578,0.2173324306025728,0.2166553825321598,0.21597833446174677,0.21530128639133378,0.21462423832092078,0.2139471902505078,0.2132701421800948,0.21259309410968177,0.21191604603926878,0.21123899796885579,0.2105619498984428,0.2098849018280298,0.2092078537576168,0.20853080568720378,0.20785375761679079,0.2071767095463778,0.2064996614759648,0.2058226134055518,0.2051455653351388,0.20446851726472579,0.2037914691943128,0.2031144211238998,0.2024373730534868,0.2017603249830738,0.20108327691266079,0.2004062288422478,0.1997291807718348,0.1990521327014218,0.1983750846310088,0.1976980365605958,0.1970209884901828,0.1963439404197698,0.1949898442789438,0.1943127962085308,0.19363574813811782,0.1929587000677048,0.1922816519972918,0.1916046039268788,0.1909275558564658,0.19025050778605282,0.1895734597156398,0.1888964116452268,0.1882193635748138,0.18754231550440081,0.18686526743398782,0.18618821936357483,0.1855111712931618,0.1848341232227488,0.18415707515233581,0.18348002708192282,0.18280297901150983,0.18212593094109683,0.1814488828706838,0.18077183480027081,0.18009478672985782,0.17941773865944483,0.17874069058903183,0.1780636425186188,0.17738659444820581,0.17670954637779282,0.17603249830737983,0.17535545023696683,0.17467840216655384,0.17400135409614081,0.17332430602572782,0.17264725795531483,0.17197020988490183,0.17129316181448884,0.17061611374407584,0.16993906567366282,0.16926201760324983,0.16858496953283683,0.16790792146242384,0.16723087339201084,0.16655382532159782,0.16587677725118483,0.16519972918077183,0.16452268111035884,0.16384563303994584,0.16316858496953285,0.16249153689911983,0.16181448882870683,0.16113744075829384,0.16046039268788084,0.15978334461746785,0.15910629654705485,0.15842924847664183,0.15775220040622884,0.15707515233581584,0.15639810426540285,0.15572105619498985,0.15504400812457683,0.15436696005416384,0.15368991198375084,0.15301286391333785,0.15233581584292485,0.15098171970209884,0.15030467163168584,0.14962762356127285,0.14895057549085985,0.14827352742044686,0.14759647935003387,0.14691943127962084,0.14624238320920785,0.14556533513879485,0.14488828706838186,0.14421123899796887,0.14353419092755584,0.14285714285714285,0.14218009478672985,0.14150304671631686,0.14082599864590387,0.14014895057549087,0.13947190250507785,0.13879485443466485,0.13811780636425186,0.13744075829383887,0.13676371022342587,0.13608666215301288,0.13540961408259986,0.13473256601218686,0.13405551794177387,0.13337846987136087,0.13270142180094788,0.13202437373053486,0.13134732566012186,0.13067027758970887,0.12999322951929587,0.12931618144888288,0.12863913337846988,0.12796208530805686,0.12728503723764387,0.12660798916723087,0.12593094109681788,0.12525389302640488,0.12457684495599188,0.12389979688557888,0.12322274881516587,0.12254570074475288,0.12186865267433988,0.12119160460392688,0.12051455653351388,0.11983750846310089,0.11916046039268788,0.11848341232227488,0.11780636425186188,0.11712931618144888,0.11645226811103589,0.11577522004062288,0.11509817197020988,0.11442112389979689,0.11374407582938388,0.11306702775897089,0.11238997968855789,0.11171293161814488,0.11103588354773189,0.1103588354773189,0.10968178740690589,0.10900473933649289,0.1083276912660799,0.10765064319566689,0.1069735951252539,0.10629654705484089,0.10561949898442789,0.1049424509140149,0.10426540284360189,0.1035883547731889,0.1029113067027759,0.10223425863236289,0.1015572105619499,0.1008801624915369,0.1002031144211239,0.0995260663507109,0.0988490182802979,0.0981719702098849,0.0974949221394719,0.09681787406905891,0.0961408259986459,0.0954637779282329,0.0947867298578199,0.0941096817874069,0.09343263371699391,0.0927555856465809,0.09207853757616791,0.09140148950575491,0.0907244414353419,0.09004739336492891,0.08937034529451592,0.08869329722410291,0.08801624915368991,0.08733920108327692,0.08666215301286391,0.08598510494245092,0.08530805687203792,0.08463100880162491,0.08395396073121192,0.08327691266079891,0.08259986459038592,0.08192281651997292,0.08124576844955991,0.08056872037914692,0.07989167230873392,0.07921462423832092,0.07853757616790792,0.07786052809749493,0.07718348002708192,0.07650643195666892,0.07582938388625593,0.07515233581584292,0.07447528774542993,0.07379823967501693,0.07312119160460392,0.07244414353419093,0.07176709546377792,0.07109004739336493,0.07041299932295193,0.06973595125253892,0.06905890318212593,0.06838185511171294,0.06770480704129993,0.06702775897088693,0.06635071090047394,0.06567366283006093,0.06499661475964794,0.06431956668923494,0.06364251861882193,0.06296547054840894,0.06296547054840894,0.06228842247799594,0.061611374407582936,0.06093432633716994,0.06025727826675694,0.05958023019634394,0.05890318212593094,0.05822613405551794,0.05754908598510494,0.05687203791469194,0.056194989844278946,0.055517941773865945,0.05484089370345294,0.05416384563303995,0.05348679756262695,0.052809749492213946,0.052132701421800945,0.05145565335138795,0.05077860528097495,0.05010155721056195,0.04942450914014895,0.04874746106973595,0.04807041299932295,0.04739336492890995,0.046716316858496955,0.046039268788083954,0.04536222071767095,0.04468517264725796,0.044008124576844956,0.043331076506431955,0.04265402843601896,0.04197698036560596,0.04129993229519296,0.040622884224779957,0.03994583615436696,0.03926878808395396,0.03859174001354096,0.037914691943127965,0.037237643872714964,0.03656059580230196,0.03588354773188896,0.035206499661475966,0.034529451591062965,0.033852403520649964,0.03317535545023697,0.03249830737982397,0.03182125930941097,0.03114421123899797,0.03046716316858497,0.02979011509817197,0.02911306702775897,0.02843601895734597,0.027758970886932972,0.027081922816519974,0.026404874746106973,0.025727826675693975,0.025050778605280974,0.024373730534867976,0.023696682464454975,0.023019634394041977,0.02234258632362898,0.021665538253215978,0.02098849018280298,0.020311442112389978,0.01963439404197698,0.018957345971563982,0.01828029790115098,0.017603249830737983,0.016926201760324982,0.016249153689911984,0.015572105619498984,0.014895057549085985,0.014218009478672985,0.013540961408259987,0.012863913337846988,0.012186865267433988,0.011509817197020988,0.010832769126607989,0.010155721056194989,0.009478672985781991,0.008801624915368992,0.008124576844955992,0.007447528774542992,0.006770480704129994,0.006093432633716994,0.005416384563303994,0.004739336492890996,0.004062288422477996,0.003385240352064997,0.002708192281651997,0.002031144211238998,0.0013540961408259986,0.0006770480704129993,0.0],\"xaxis\":\"x\",\"y\":[0.9615885416666666,0.9649006622516556,0.9648774022531478,0.9648541114058355,0.9648307896483079,0.9654714475431607,0.9654485049833887,0.9654255319148937,0.9654025282767797,0.9653794940079894,0.9653564290473018,0.9653333333333334,0.9653102068045364,0.965287049399199,0.9652638610554443,0.9652406417112299,0.9652173913043478,0.965194109772423,0.9651707970529136,0.9651474530831099,0.9651240778001341,0.9657718120805369,0.9657488247145736,0.9657258064516129,0.9657027572293208,0.9656796769851952,0.9656565656565657,0.965633423180593,0.9656102494942683,0.9655870445344129,0.9655638082376773,0.9655405405405405,0.9655172413793104,0.9654939106901218,0.965470548408937,0.9654471544715447,0.9654237288135593,0.9654002713704206,0.9653767820773931,0.9653532608695652,0.9653297076818491,0.9653061224489796,0.9652825051055139,0.965258855585831,0.9652351738241309,0.9652114597544338,0.9651877133105802,0.9651639344262295,0.9651401230348599,0.9658002735978112,0.9657768651608487,0.9657534246575342,0.9657299520219328,0.9657064471879286,0.9656829100892245,0.9656593406593407,0.9656357388316151,0.9662998624484181,0.9662766689607708,0.9662534435261708,0.9662301860785665,0.9662068965517241,0.966183574879227,0.9661602209944752,0.9661368348306841,0.9661134163208852,0.9660899653979239,0.9660664819944599,0.966042966042966,0.9660194174757282,0.9659958362248439,0.9659722222222222,0.965948575399583,0.9659248956884562,0.9659011830201809,0.9658774373259053,0.9658536585365853,0.9665271966527197,0.9672016748080949,0.9671787709497207,0.9671558350803634,0.9671328671328672,0.967109867039888,0.9670868347338936,0.9670637701471618,0.9670406732117812,0.9670175438596491,0.9669943820224719,0.9669711876317639,0.9676511954992968,0.9676284306826178,0.967605633802817,0.9675828047921071,0.9675599435825106,0.9675370501058574,0.9675141242937854,0.9674911660777386,0.9681753889674681,0.9681528662420382,0.9681303116147308,0.9681077250177179,0.9680851063829787,0.9680624556422995,0.9680397727272727,0.9680170575692963,0.9679943100995733,0.9679715302491103,0.967948717948718,0.9679258731290092,0.9679029957203994,0.9678800856531049,0.9678571428571429,0.9678341672623302,0.9678111587982833,0.9677881173944166,0.9677650429799427,0.967741935483871,0.9677187948350072,0.968413496051687,0.9683908045977011,0.9683680805176133,0.9683453237410072,0.9683225341972642,0.968299711815562,0.9682768565248738,0.9682539682539683,0.9682310469314079,0.9682080924855492,0.9681851048445409,0.9681620839363242,0.9688631426502534,0.9688405797101449,0.9688179840464104,0.9687953555878084,0.9687726942628904,0.96875,0.9687272727272728,0.9687045123726347,0.9686817188638019,0.9693877551020408,0.9693654266958425,0.9693430656934306,0.9700511322132944,0.9700292397660819,0.9700073152889539,0.9699853587115667,0.96996336996337,0.9699413489736071,0.9699192956713133,0.9698972099853157,0.9698750918442322,0.9698529411764706,0.9698307579102281,0.9705449189985272,0.9705232129697863,0.9705014749262537,0.9704797047970479,0.9704579025110783,0.9704360679970436,0.9704142011834319,0.9703923019985197,0.9703703703703703,0.9703484062268347,0.9703264094955489,0.9703043801039347,0.9702823179791976,0.9702602230483272,0.9702380952380952,0.9702159344750558,0.970193740685544,0.9701715137956749,0.9701492537313433,0.9701269604182226,0.9708520179372198,0.9708302169035153,0.9708083832335329,0.9707865168539326,0.9707646176911544,0.9707426856714179,0.9707207207207207,0.9706987227648385,0.9706766917293234,0.9706546275395034,0.9706325301204819,0.9706103993971364,0.9705882352941176,0.970566037735849,0.9705438066465257,0.9705215419501134,0.970499243570348,0.9704769114307343,0.9704545454545455,0.9704321455648218,0.9704097116843703,0.9703872437357631,0.9703647416413373,0.9703422053231939,0.9703196347031964,0.9702970297029703,0.9702743902439024,0.9702517162471396,0.9702290076335878,0.9702062643239114,0.9701834862385321,0.9701606732976281,0.9701378254211332,0.9701149425287356,0.9700920245398773,0.9700690713737529,0.9700460829493087,0.9707916986933128,0.9707692307692307,0.970746728252502,0.9707241910631741,0.9707016191210486,0.970679012345679,0.9706563706563707,0.9706336939721792,0.9706109822119103,0.9705882352941176,0.9705654531371031,0.9705426356589147,0.9705197827773467,0.9704968944099379,0.9704739704739704,0.9704510108864697,0.9704280155642023,0.9704049844236761,0.9711613406079501,0.9711388455538221,0.9711163153786104,0.97109375,0.9710711493354183,0.9710485133020345,0.971025841816758,0.9710031347962382,0.9709803921568627,0.9709576138147566,0.9717203456402199,0.9724842767295597,0.9724626278520849,0.9724409448818898,0.9724192277383766,0.973186119873817,0.9731649565903709,0.9731437598736177,0.9731225296442688,0.9731012658227848,0.9730799683293745,0.9730586370839936,0.9730372720063442,0.973015873015873,0.9729944400317713,0.972972972972973,0.9729514717581543,0.9729299363057324,0.9729083665338646,0.9728867623604466,0.9728651237031125,0.9736421725239617,0.973621103117506,0.9736,0.9735788630904724,0.9743589743589743,0.9743384121892542,0.9743178170144462,0.97429718875502,0.9742765273311897,0.9742558326629123,0.9742351046698873,0.9742143432715552,0.9741935483870968,0.9749798224374495,0.9749596122778675,0.9757477768795473,0.9757281553398058,0.9765182186234818,0.9764991896272285,0.9764801297648013,0.976461038961039,0.9764419171405362,0.9764227642276423,0.9764035801464606,0.9763843648208469,0.9763651181744091,0.9763458401305057,0.9771428571428571,0.9779411764705882,0.9787408013082584,0.9787234042553191,0.9787059787059788,0.978688524590164,0.9786710418375718,0.9794745484400657,0.9794576828266228,0.9794407894736842,0.9794238683127572,0.9794069192751236,0.9793899422918384,0.9793729372937293,0.9793559042113955,0.9801652892561984,0.9801488833746899,0.9801324503311258,0.980115990057995,0.9809286898839138,0.9809128630705394,0.9808970099667774,0.9808811305070657,0.980865224625624,0.9816819317235637,0.9816666666666667,0.981651376146789,0.9816360601001669,0.9816207184628237,0.9816053511705686,0.9815899581589959,0.981574539363484,0.9815590947191953,0.9815436241610739,0.9815281276238456,0.9815126050420168,0.9814970563498738,0.9814814814814815,0.9814658803706824,0.9814502529510961,0.9814345991561182,0.981418918918919,0.981403212172443,0.9822335025380711,0.9822184589331076,0.9822033898305085,0.9821882951653944,0.9821731748726655,0.9821580288870009,0.9821428571428571,0.9821276595744681,0.9821124361158433,0.9820971867007673,0.9820819112627986,0.982066609735269,0.9829059829059829,0.9837467921300257,0.9837328767123288,0.9837189374464439,0.983704974271012,0.9836909871244636,0.9836769759450171,0.9836629406706793,0.9845094664371773,0.9844961240310077,0.9844827586206897,0.9844693701466781,0.9844559585492227,0.9853068280034573,0.9852941176470589,0.9852813852813853,0.9852686308492201,0.9852558542931483,0.9852430555555556,0.9852302345786272,0.9852173913043478,0.9852045256744996,0.985191637630662,0.985178727114211,0.9851657940663177,0.9851528384279477,0.9851398601398601,0.9851268591426072,0.9851138353765324,0.9851007887817704,0.9850877192982456,0.9850746268656716,0.9850615114235501,0.9850483729111698,0.9850352112676056,0.9850220264317181,0.9850088183421517,0.9849955869373345,0.984982332155477,0.9849690539345711,0.9849557522123894,0.9849424269264836,0.9849290780141844,0.9849157054125999,0.9849023090586145,0.9848888888888889,0.9848754448398577,0.9848619768477292,0.9848484848484849,0.9848349687778769,0.9848214285714286,0.9848078641644326,0.9847942754919499,0.9847806624888094,0.9847670250896058,0.9856502242152466,0.9856373429084381,0.9856244384546271,0.9856115107913669,0.9855985598559855,0.9864864864864865,0.9864743011722272,0.9864620938628159,0.986449864498645,0.9864376130198915,0.9864253393665159,0.9864130434782609,0.986400725294651,0.9863883847549909,0.9863760217983651,0.9863636363636363,0.986351228389445,0.9863387978142076,0.9863263445761167,0.9863138686131386,0.9863013698630136,0.9862888482632541,0.9862763037511436,0.9862637362637363,0.9862511457378552,0.9862385321100917,0.9862258953168044,0.9862132352941176,0.9862005519779209,0.9861878453038674,0.9861751152073732,0.9861623616236163,0.9861495844875346,0.9861367837338263,0.9861239592969473,0.9861111111111112,0.9860982391102873,0.9860853432282004,0.9860724233983287,0.9869888475836431,0.9869767441860465,0.9878957169459963,0.9878844361602982,0.9878731343283582,0.9878618113912232,0.9878504672897196,0.9878391019644528,0.9878277153558053,0.9878163074039362,0.9878048780487805,0.9877934272300469,0.9877819548872181,0.9877704609595485,0.987758945386064,0.9877474081055608,0.9877358490566037,0.987724268177526,0.9877126654064272,0.9877010406811731,0.9876893939393939,0.9876777251184834,0.9876660341555977,0.9876543209876543,0.9876425855513308,0.9876308277830638,0.9876190476190476,0.9876072449952336,0.9875954198473282,0.9875835721107927,0.9875717017208413,0.9875598086124402,0.9875478927203065,0.987535953978907,0.9875239923224568,0.9875120076849183,0.9875,0.987487969201155,0.98747591522158,0.9884281581485053,0.9884169884169884,0.9884057971014493,0.988394584139265,0.9883833494675702,0.9883720930232558,0.988360814742968,0.9883495145631068,0.9883381924198251,0.9883268482490273,0.9883154819863681,0.9883040935672515,0.9882926829268293,0.98828125,0.9882697947214076,0.9882583170254403,0.9882468168462292,0.9882352941176471,0.9882237487733072,0.9882121807465619,0.9882005899705014,0.9891732283464567,0.9891625615763546,0.9891518737672583,0.9891411648568608,0.9891304347826086,0.9891196834817013,0.9891089108910891,0.9890981169474727,0.9890873015873016,0.9890764647467726,0.989065606361829,0.9890547263681592,0.9890438247011952,0.9890329012961117,0.9890219560878244,0.989010989010989,0.989,0.988988988988989,0.9889779559118237,0.9889669007021064,0.9889558232931727,0.9889447236180905,0.9889336016096579,0.9889224572004028,0.9889112903225806,0.9889001009081736,0.9888888888888889,0.9888776541961577,0.9888663967611336,0.9888551165146909,0.9888438133874239,0.9888324873096447,0.9888211382113821,0.9888097660223805,0.9887983706720977,0.9887869520897044,0.9887755102040816,0.9887640449438202,0.9887525562372188,0.9887410440122825,0.9887295081967213,0.9887179487179487,0.9887063655030801,0.9886947584789312,0.9886831275720165,0.9886714727085479,0.988659793814433,0.9886480908152735,0.9886363636363636,0.9886246122026887,0.9886128364389234,0.9886010362694301,0.9885892116182573,0.9885773624091381,0.9885654885654885,0.9885535900104059,0.9895833333333334,0.9895724713242962,0.9895615866388309,0.9895506792058516,0.9895397489539749,0.9895287958115183,0.989517819706499,0.9895068205666316,0.9894957983193278,0.9894847528916929,0.9894736842105263,0.9894625922023182,0.989451476793249,0.989440337909187,0.9894291754756871,0.9894179894179894,0.989406779661017,0.9893955461293743,0.9893842887473461,0.9893730074388948,0.9893617021276596,0.9893503727369543,0.9893390191897654,0.9893276414087513,0.9893162393162394,0.9893048128342246,0.9892933618843683,0.9892818863879957,0.9892703862660944,0.9892588614393125,0.989247311827957,0.9892357373519914,0.9892241379310345,0.9892125134843581,0.9892008639308856,0.9891891891891892,0.9891774891774892,0.9891657638136512,0.9891540130151844,0.98914223669924,0.9891304347826086,0.9891186071817193,0.9891067538126361,0.9890948745910578,0.9890829694323144,0.9890710382513661,0.9890590809628009,0.9890470974808324,0.9890350877192983,0.9890230515916575,0.989010989010989,0.988998899889989,0.9889867841409692,0.9889746416758545,0.9889624724061811,0.988950276243094,0.9889380530973452,0.9889258028792912,0.9889135254988913,0.9889012208657048,0.9888888888888889,0.9888765294771968,0.9888641425389755,0.9888517279821628,0.9888392857142857,0.9888268156424581,0.9888143176733781,0.9888017917133258,0.9887892376681614,0.9887766554433222,0.9887640449438202,0.9887514060742407,0.9898648648648649,0.9898534385569335,0.989841986455982,0.9898305084745763,0.9898190045248869,0.9898074745186863,0.9897959183673469,0.9897843359818388,0.9897727272727272,0.9897610921501706,0.989749430523918,0.9897377423033067,0.9897260273972602,0.9897142857142858,0.9897025171624714,0.9896907216494846,0.9896788990825688,0.9896670493685419,0.9896551724137931,0.9896432681242808,0.9896313364055299,0.9907727797001153,0.9907621247113164,0.9907514450867052,0.9907407407407407,0.9907300115874855,0.9907192575406032,0.9907084785133565,0.9906976744186047,0.9906868451688009,0.9918414918414918,0.9918319719953326,0.991822429906542,0.991812865497076,0.9918032786885246,0.9917936694021102,0.9917840375586855,0.9917743830787309,0.991764705882353,0.9917550058892816,0.9917452830188679,0.9917355371900827,0.991725768321513,0.991715976331361,0.9917061611374408,0.9916963226571768,0.9916864608076009,0.9916765755053508,0.9916666666666667,0.9916567342073898,0.9916467780429594,0.991636798088411,0.9916267942583732,0.9916167664670659,0.9916067146282974,0.9915966386554622,0.9915865384615384,0.9915764139590855,0.9915662650602409,0.991556091676719,0.9915458937198067,0.9915356711003628,0.9915254237288136,0.9915151515151515,0.991504854368932,0.991494532199271,0.9914841849148418,0.9914738124238733,0.9914634146341463,0.9914529914529915,0.991442542787286,0.9914320685434517,0.991421568627451,0.9914110429447853,0.9914004914004914,0.991389913899139,0.9913793103448276,0.9913686806411838,0.991358024691358,0.9913473423980222,0.9913366336633663,0.9913258983890955,0.9913151364764268,0.991304347826087,0.9912935323383084,0.9912826899128269,0.9912718204488778,0.9912609238451935,0.99125,0.9912390488110138,0.9912280701754386,0.9912170639899623,0.9912060301507538,0.9911949685534591,0.9911838790931989,0.9911727616645649,0.9911616161616161,0.9911504424778761,0.9911392405063291,0.991128010139417,0.9911167512690355,0.9911054637865311,0.9910941475826972,0.9910828025477707,0.9910714285714286,0.9910600255427842,0.9910485933503836,0.9910371318822023,0.9910256410256411,0.9910141206675225,0.9910025706940874,0.990990990990991,0.990979381443299,0.9909677419354839,0.9909560723514211,0.9909443725743855,0.9909326424870466,0.9909208819714657,0.9922077922077922,0.9921976592977894,0.9921875,0.9921773142112125,0.9921671018276762,0.9921568627450981,0.9921465968586387,0.9921363040629095,0.9921259842519685,0.9921156373193167,0.9921052631578947,0.9920948616600791,0.9920844327176781,0.9920739762219286,0.9920634920634921,0.9920529801324504,0.9920424403183024,0.9920318725099602,0.9920212765957447,0.9920106524633822,0.992,0.9919893190921228,0.9919786096256684,0.9919678714859438,0.9919571045576407,0.9919463087248322,0.9919354838709677,0.9919246298788694,0.9919137466307277,0.9919028340080972,0.9918918918918919,0.9918809201623816,0.991869918699187,0.9918588873812755,0.9918478260869565,0.9918367346938776,0.9918256130790191,0.9918144611186903,0.9918032786885246,0.9917920656634747,0.9917808219178083,0.9917695473251029,0.9917582417582418,0.9917469050894085,0.9917355371900827,0.9917241379310345,0.9917127071823204,0.991701244813278,0.9916897506925207,0.9916782246879334,0.9916666666666667,0.9916550764951322,0.9916434540389972,0.9916317991631799,0.9916201117318436,0.9916083916083916,0.9915966386554622,0.9915848527349228,0.9915730337078652,0.9915611814345991,0.9915492957746479,0.9915373765867419,0.9915254237288136,0.9915134370579916,0.9915014164305949,0.9914893617021276,0.9914772727272727,0.9914651493598862,0.9914529914529915,0.992867332382311,0.9928571428571429,0.9928469241773963,0.9928366762177651,0.9928263988522238,0.992816091954023,0.9928057553956835,0.9927953890489913,0.9927849927849928,0.9927745664739884,0.9927641099855282,0.9927536231884058,0.9927431059506531,0.9927325581395349,0.992721979621543,0.9927113702623906,0.9927007299270073,0.9926900584795322,0.9926793557833089,0.9926686217008798,0.9926578560939795,0.9926470588235294,0.9926362297496318,0.9926253687315634,0.9926144756277696,0.992603550295858,0.9925925925925926,0.9925816023738873,0.9925705794947994,0.9925595238095238,0.992548435171386,0.9925373134328358,0.992526158445441,0.9925149700598802,0.992503748125937,0.9924924924924925,0.9924812030075187,0.9924698795180723,0.9924585218702866,0.9924471299093656,0.9924357034795764,0.9924242424242424,0.992412746585736,0.9924012158054711,0.9923896499238964,0.9923780487804879,0.9923664122137404,0.9923547400611621,0.9923430321592649,0.9923312883435583,0.9923195084485407,0.9923076923076923,0.9922958397534669,0.9938271604938271,0.9938176197836167,0.9938080495356038,0.993798449612403,0.9937888198757764,0.9937791601866252,0.9937694704049844,0.9937597503900156,0.99375,0.9937402190923318,0.9937304075235109,0.9937205651491365,0.9937106918238994,0.9937007874015747,0.9936908517350158,0.9936808846761453,0.9936708860759493,0.993660855784469,0.9936507936507937,0.9936406995230525,0.9936305732484076,0.9936204146730463,0.9936102236421726,0.9936,0.9935897435897436,0.9935794542536116,0.9935691318327974,0.9935587761674718,0.9935483870967742,0.9935379644588045,0.9935275080906149,0.993517017828201,0.9935064935064936,0.9934959349593496,0.993485342019544,0.9934747145187602,0.9934640522875817,0.9934533551554828,0.9934426229508196,0.993431855500821,0.993421052631579,0.9934102141680395,0.9933993399339934,0.9933884297520661,0.9933774834437086,0.9933665008291874,0.9933554817275747,0.9950083194675541,0.995,0.994991652754591,0.9949832775919732,0.9949748743718593,0.9949664429530202,0.9949579831932773,0.9949494949494949,0.9949409780775716,0.9949324324324325,0.9949238578680203,0.9949152542372881,0.9949066213921901,0.9948979591836735,0.9948892674616695,0.9948805460750854,0.9948717948717949,0.9948630136986302,0.9948542024013722,0.9948453608247423,0.9948364888123924,0.9948275862068966,0.9948186528497409,0.9948096885813149,0.9948006932409013,0.9947916666666666,0.9947826086956522,0.9947735191637631,0.9947643979057592,0.9947552447552448,0.9947460595446584,0.9947368421052631,0.9947275922671354,0.9947183098591549,0.9947089947089947,0.9946996466431095,0.9946902654867257,0.9946808510638298,0.9946714031971581,0.994661921708185,0.9946524064171123,0.9946428571428572,0.9946332737030411,0.9946236559139785,0.9946140035906643,0.9946043165467626,0.9945945945945946,0.9945848375451264,0.9945750452079566,0.9945652173913043,0.9945553539019963,0.9945454545454545,0.994535519125683,0.9945255474452555,0.9945155393053017,0.9945054945054945,0.9944954128440368,0.9944852941176471,0.994475138121547,0.9944649446494465,0.9944547134935305,0.9944444444444445,0.9944341372912802,0.9944237918215614,0.994413407821229,0.9944029850746269,0.994392523364486,0.9943820224719101,0.9943714821763602,0.9943609022556391,0.9943502824858758,0.9943396226415094,0.994328922495274,0.9943181818181818,0.9943074003795066,0.9942965779467681,0.9942857142857143,0.9942748091603053,0.994263862332696,0.9942528735632183,0.9942418426103646,0.9942307692307693,0.9942196531791907,0.9942084942084942,0.9941972920696325,0.9941860465116279,0.9941747572815534,0.9941634241245136,0.9941520467836257,0.994140625,0.9941291585127201,0.9941176470588236,0.9941060903732809,0.9940944881889764,0.9940828402366864,0.9940711462450593,0.994059405940594,0.9940476190476191,0.9940357852882704,0.9940239043824701,0.9940119760479041,0.994,0.9939879759519038,0.9939759036144579,0.993963782696177,0.9939516129032258,0.9939393939393939,0.9939271255060729,0.9939148073022313,0.9939024390243902,0.9938900203665988,0.9938775510204082,0.9938650306748467,0.9959016393442623,0.9958932238193019,0.9958847736625515,0.9958762886597938,0.9958677685950413,0.9958592132505176,0.995850622406639,0.9958419958419958,0.9958333333333333,0.9958246346555324,0.99581589958159,0.9958071278825996,0.9957983193277311,0.9957894736842106,0.9957805907172996,0.9957716701902748,0.9957627118644068,0.9957537154989384,0.9957446808510638,0.9957356076759062,0.9957264957264957,0.9957173447537473,0.9957081545064378,0.9956989247311828,0.9956896551724138,0.9956803455723542,0.9956709956709957,0.9956616052060737,0.9956521739130435,0.9956427015250545,0.9956331877729258,0.9956236323851203,0.9956140350877193,0.9956043956043956,0.9955947136563876,0.9955849889624724,0.995575221238938,0.9955654101995566,0.9955555555555555,0.9955456570155902,0.9955357142857143,0.9955257270693513,0.9955156950672646,0.9955056179775281,0.9954954954954955,0.9954853273137697,0.995475113122172,0.9954648526077098,0.9954545454545455,0.9954441913439636,0.9954337899543378,0.9954233409610984,0.9954128440366973,0.9954022988505747,0.9953917050691244,0.9953810623556582,0.9953703703703703,0.9953596287703016,0.9953488372093023,0.9953379953379954,0.9953271028037384,0.9953161592505855,0.9953051643192489,0.9952941176470588,0.9952830188679245,0.9952718676122931,0.995260663507109,0.995249406175772,0.9952380952380953,0.9952267303102625,0.9952153110047847,0.9952038369304557,0.9951923076923077,0.9951807228915662,0.9951690821256038,0.9951573849878934,0.9951456310679612,0.9951338199513382,0.9951219512195122,0.9951100244498777,0.9950980392156863,0.995085995085995,0.9950738916256158,0.9950617283950617,0.995049504950495,0.9950372208436724,0.9950248756218906,0.9950124688279302,0.995,0.9949874686716792,0.9949748743718593,0.9949622166246851,0.9949494949494949,0.9949367088607595,0.9949238578680203,0.9949109414758269,0.9948979591836735,0.9948849104859335,0.9948717948717949,0.9948586118251928,0.9948453608247423,0.9948320413436692,0.9948186528497409,0.9948051948051948,0.9947916666666666,0.9947780678851175,0.9947643979057592,0.994750656167979,0.9947368421052631,0.9947229551451188,0.9947089947089947,0.9946949602122016,0.9946808510638298,0.9946666666666667,0.9946524064171123,0.9946380697050938,0.9946236559139785,0.9946091644204852,0.9945945945945946,0.994579945799458,0.9945652173913043,0.9945504087193461,0.994535519125683,0.9945205479452055,0.9945054945054945,0.9944903581267218,0.994475138121547,0.9944598337950139,0.9944444444444445,0.9944289693593314,0.994413407821229,0.9943977591036415,0.9943820224719101,0.9943661971830986,0.9943502824858758,0.9943342776203966,0.9943181818181818,0.9943019943019943,0.9942857142857143,0.994269340974212,0.9942528735632183,0.9942363112391931,0.9942196531791907,0.9942028985507246,0.9941860465116279,0.9941690962099126,0.9941520467836257,0.9970674486803519,0.9970588235294118,0.9970501474926253,0.9970414201183432,0.9970326409495549,0.9970238095238095,0.9970149253731343,0.9970059880239521,0.996996996996997,0.9969879518072289,0.9969788519637462,0.996969696969697,0.9969604863221885,0.9969512195121951,0.9969418960244648,0.9969325153374233,0.9969230769230769,0.9969135802469136,0.9969040247678018,0.9968944099378882,0.9968847352024922,0.996875,0.9968652037617555,0.9968553459119497,0.9968454258675079,0.9968354430379747,0.9968253968253968,0.9968152866242038,0.9968051118210862,0.9967948717948718,0.9967845659163987,0.9967741935483871,0.9967637540453075,0.9967532467532467,0.996742671009772,0.9967320261437909,0.9967213114754099,0.9967105263157895,0.9966996699669967,0.9966887417218543,0.9966777408637874,0.9966666666666667,0.9966555183946488,0.9966442953020134,0.9966329966329966,0.9966216216216216,0.9966101694915255,0.9965986394557823,0.9965870307167235,0.9965753424657534,0.9965635738831615,0.9965397923875432,0.9965277777777778,0.9965156794425087,0.9965034965034965,0.9964912280701754,0.9964788732394366,0.9964664310954063,0.9964539007092199,0.99644128113879,0.9964285714285714,0.996415770609319,0.9964028776978417,0.9963898916967509,0.9963768115942029,0.9963636363636363,0.9963503649635036,0.9963369963369964,0.9963235294117647,0.996309963099631,0.9962962962962963,0.9962825278810409,0.996268656716418,0.9962546816479401,0.9962406015037594,0.9962264150943396,0.9962121212121212,0.9961977186311787,0.9961832061068703,0.9961685823754789,0.9961538461538462,0.9961389961389961,0.9961240310077519,0.9961089494163424,0.99609375,0.996078431372549,0.9960629921259843,0.9960474308300395,0.996031746031746,0.9960159362549801,0.996,0.9959839357429718,0.9959677419354839,0.9959514170040485,0.9959349593495935,0.9959183673469387,0.9959016393442623,0.9958847736625515,0.9958677685950413,0.995850622406639,0.9958333333333333,0.99581589958159,0.9957983193277311,0.9957805907172996,0.9957627118644068,0.9957446808510638,0.9957264957264957,0.9957081545064378,0.9956896551724138,0.9956709956709957,0.9956521739130435,0.9956331877729258,0.9956140350877193,0.9955947136563876,0.995575221238938,0.9955357142857143,0.9955156950672646,0.9954954954954955,0.995475113122172,0.9954545454545455,0.9954337899543378,0.9954128440366973,0.9953917050691244,0.9953703703703703,0.9953488372093023,0.9953271028037384,0.9953051643192489,0.9952830188679245,0.995260663507109,0.9952380952380953,0.9952153110047847,0.9951923076923077,0.9951690821256038,0.9951456310679612,0.9951219512195122,0.9950980392156863,0.9950738916256158,0.995049504950495,0.9950248756218906,0.995,0.9949748743718593,0.9949494949494949,0.9949238578680203,0.9948979591836735,0.9948717948717949,0.9948453608247423,0.9948186528497409,0.9947916666666666,0.9947643979057592,0.9947368421052631,0.9947089947089947,0.9946808510638298,0.9946524064171123,0.9946236559139785,0.9945945945945946,0.9945652173913043,0.994535519125683,0.9945054945054945,0.994475138121547,0.9944444444444445,0.994413407821229,0.9943820224719101,0.9943502824858758,0.9943181818181818,0.9942857142857143,0.9942528735632183,0.9942196531791907,0.9941860465116279,0.9941520467836257,0.9941176470588236,0.9940828402366864,0.9940476190476191,0.9940119760479041,0.9939759036144579,0.9939393939393939,0.9939024390243902,0.9938650306748467,0.9938271604938271,0.9937888198757764,0.99375,0.9937106918238994,0.9936708860759493,0.9936305732484076,0.9935897435897436,0.9935483870967742,0.9935064935064936,0.9934640522875817,0.993421052631579,0.9933774834437086,0.9933333333333333,0.9932885906040269,0.9932432432432432,0.9931972789115646,0.9931506849315068,0.993103448275862,0.9930555555555556,0.993006993006993,0.9929577464788732,0.9929078014184397,0.9928571428571429,0.9928057553956835,0.9927536231884058,0.9927007299270073,0.9926470588235294,0.9925925925925926,0.9925373134328358,0.9924812030075187,0.9924242424242424,0.9923664122137404,0.9923076923076923,0.9922480620155039,0.9921875,0.9921259842519685,0.9920634920634921,0.992,0.9919354838709677,0.991869918699187,0.9918032786885246,0.9917355371900827,0.9916666666666667,0.9915966386554622,0.9915254237288136,0.9914529914529915,0.9913793103448276,0.991304347826087,0.9912280701754386,0.9911504424778761,0.9910714285714286,0.990990990990991,0.990909090909091,0.9908256880733946,0.9907407407407407,0.9906542056074766,0.9905660377358491,0.9904761904761905,0.9903846153846154,0.9902912621359223,0.9901960784313726,0.9900990099009901,0.99,0.98989898989899,0.9897959183673469,0.9896907216494846,0.9895833333333334,0.9894736842105263,0.9893617021276596,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],\"yaxis\":\"y\",\"type\":\"scattergl\",\"textposition\":\"top center\"},{\"hovertemplate\":[],\"legendgroup\":\"iso_curves\",\"line\":{\"color\":\"#4C78A8\",\"dash\":\"dot\",\"width\":0.8},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"ISO-f1 Curves\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.11102040816326529,0.13122448979591836,0.15142857142857144,0.1716326530612245,0.19183673469387755,0.2120408163265306,0.23224489795918368,0.2524489795918367,0.2726530612244898,0.29285714285714287,0.3130612244897959,0.333265306122449,0.35346938775510206,0.3736734693877551,0.39387755102040817,0.4140816326530612,0.4342857142857143,0.45448979591836736,0.4746938775510204,0.49489795918367346,0.5151020408163265,0.5353061224489796,0.5555102040816327,0.5757142857142857,0.5959183673469388,0.6161224489795918,0.6363265306122449,0.656530612244898,0.676734693877551,0.6969387755102041,0.7171428571428571,0.7373469387755102,0.7575510204081632,0.7777551020408163,0.7979591836734694,0.8181632653061224,0.8383673469387755,0.8585714285714285,0.8787755102040816,0.8989795918367347,0.9191836734693878,0.9393877551020408,0.9595918367346938,0.9797959183673469,1.0],\"xaxis\":\"x\",\"y\":[1.007407407407409,0.4202614379084969,0.29444444444444445,0.23960113960113963,0.20888888888888893,0.18925318761384338,0.1756172839506173,0.16559571619812585,0.157919621749409,0.15185185185185188,0.14693486590038315,0.14286964129483817,0.1394524959742351,0.1365398956002983,0.1340277777777778,0.1318388564002599,0.1299145299145299,0.12820955670696604,0.1266884531590414,0.12532299741602068,0.12409046214355948,0.12297233942803563,0.12195340501792114,0.12102102102102102,0.12016460905349795,0.11937524713325426,0.1186453576864536,0.11796846351301797,0.11733899504600141,0.11675213675213675,0.11620370370370371,0.11569004162664105,0.11520794537554314,0.11475459199036435,0.11432748538011697,0.11392441034384769,0.11354339414040907,0.11318267419962334,0.11284067085953879,0.11251596424010218,0.11220727453911311,0.11191344517383904,0.11163342830009498,0.11136627232660637,0.11111111111111112],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":[],\"legendgroup\":\"iso_curves\",\"line\":{\"color\":\"#4C78A8\",\"dash\":\"dot\",\"width\":0.8},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"ISO-f1 Curves\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[0.2120408163265306,0.23224489795918368,0.2524489795918367,0.2726530612244898,0.29285714285714287,0.3130612244897959,0.333265306122449,0.35346938775510206,0.3736734693877551,0.39387755102040817,0.4140816326530612,0.4342857142857143,0.45448979591836736,0.4746938775510204,0.49489795918367346,0.5151020408163265,0.5353061224489796,0.5555102040816327,0.5757142857142857,0.5959183673469388,0.6161224489795918,0.6363265306122449,0.656530612244898,0.676734693877551,0.6969387755102041,0.7171428571428571,0.7373469387755102,0.7575510204081632,0.7777551020408163,0.7979591836734694,0.8181632653061224,0.8383673469387755,0.8585714285714285,0.8787755102040816,0.8989795918367347,0.9191836734693878,0.9393877551020408,0.9595918367346938,0.9797959183673469,1.0],\"xaxis\":\"x\",\"y\":[3.522033898305091,1.4405063291139244,0.9626459143968878,0.7505617977528092,0.6307692307692309,0.5537906137184117,0.5001531393568148,0.46063829787234045,0.43031727379553475,0.40631578947368424,0.3868446139180172,0.3707317073170732,0.357177225340818,0.3456166419019317,0.33564013840830453,0.32694300518134717,0.3192939744370055,0.31251435132032146,0.30646387832699623,0.30103092783505153,0.2961255517410496,0.2916744621141254,0.2876173446580242,0.2839041095890411,0.2804928131416838,0.2773480662983426,0.27443980250664646,0.27174231332357246,0.2692334864005652,0.26689419795221847,0.2647078243644767,0.2626598465473146,0.26073752711496745,0.2589296452194829,0.2572262773722628,0.2556186152099887,0.2540988131382832,0.25265986029016657,0.2512954723894269,0.25],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":[],\"legendgroup\":\"iso_curves\",\"line\":{\"color\":\"#4C78A8\",\"dash\":\"dot\",\"width\":0.8},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"ISO-f1 Curves\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[0.3130612244897959,0.333265306122449,0.35346938775510206,0.3736734693877551,0.39387755102040817,0.4140816326530612,0.4342857142857143,0.45448979591836736,0.4746938775510204,0.49489795918367346,0.5151020408163265,0.5353061224489796,0.5555102040816327,0.5757142857142857,0.5959183673469388,0.6161224489795918,0.6363265306122449,0.656530612244898,0.676734693877551,0.6969387755102041,0.7171428571428571,0.7373469387755102,0.7575510204081632,0.7777551020408163,0.7979591836734694,0.8181632653061224,0.8383673469387755,0.8585714285714285,0.8787755102040816,0.8989795918367347,0.9191836734693878,0.9393877551020408,0.9595918367346938,0.9797959183673469,1.0],\"xaxis\":\"x\",\"y\":[7.190625000000037,3.0055214723926422,1.9832061068702302,1.5216066481994475,1.2586956521739137,1.0889087656529526,0.9702127659574474,0.8825627476882435,0.8151869158878509,0.7617801047120423,0.7184060721062622,0.6824804856895059,0.6522364217252398,0.6264248704663213,0.6041379310344829,0.5846998063266626,0.567597087378641,0.5524327418431598,0.5388949079089925,0.5267352185089975,0.5157534246575344,0.5057862809146059,0.496699375557538,0.4883810337462624,0.4807377049180329,0.4736904293028753,0.4671721000758151,0.4611253196930948,0.45550070521861785,0.45025553662691664,0.44535266974291376,0.440759655282477,0.4364480198019803,0.43239267487241084,0.42857142857142866],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":[],\"legendgroup\":\"iso_curves\",\"line\":{\"color\":\"#4C78A8\",\"dash\":\"dot\",\"width\":0.8},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"ISO-f1 Curves\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[0.4140816326530612,0.4342857142857143,0.45448979591836736,0.4746938775510204,0.49489795918367346,0.5151020408163265,0.5353061224489796,0.5555102040816327,0.5757142857142857,0.5959183673469388,0.6161224489795918,0.6363265306122449,0.656530612244898,0.676734693877551,0.6969387755102041,0.7171428571428571,0.7373469387755102,0.7575510204081632,0.7777551020408163,0.7979591836734694,0.8181632653061224,0.8383673469387755,0.8585714285714285,0.8787755102040816,0.8989795918367347,0.9191836734693878,0.9393877551020408,0.9595918367346938,0.9797959183673469,1.0],\"xaxis\":\"x\",\"y\":[11.762318840579754,5.066666666666672,3.3363295880149826,2.542076502732242,2.086021505376345,1.7900709219858164,1.5825037707390655,1.4288713910761157,1.3105691056910571,1.2166666666666668,1.1403210576015113,1.077029360967185,1.0237072394590296,0.9781710914454278,0.9388316151202749,0.9045045045045048,0.874289171203872,0.847488584474886,0.8235548352242031,0.8020512820512822,0.7826256710590533,0.7649906890130355,0.7489096573208723,0.7341858482523446,0.7206543967280165,0.7081761006289309,0.6966326144532728,0.6859226841721372,0.6759591693065823,0.6666666666666667],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"line\":{\"color\":\"#20313e\",\"dash\":\"dash\"},\"mode\":\"lines\",\"name\":\"Baseline\",\"x\":[-1,2],\"y\":[0.9615885416666666,0.9615885416666666],\"type\":\"scatter\",\"showlegend\":true}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Recall\"},\"range\":[0.0,1.03]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Precision\"},\"range\":[0.0,1.03]},\"legend\":{\"tracegroupgap\":0,\"font\":{\"size\":9},\"yanchor\":\"top\",\"y\":0.18,\"xanchor\":\"left\",\"x\":0.03},\"title\":{\"text\":\"<b>AUPRC - Test</b>\"},\"annotations\":[{\"showarrow\":false,\"text\":\"f1=0.2\",\"x\":0.9,\"y\":0.1222072745391131,\"yshift\":10},{\"showarrow\":false,\"text\":\"f1=0.4\",\"x\":0.9,\"y\":0.2656186152099887,\"yshift\":10},{\"showarrow\":false,\"text\":\"f1=0.6\",\"x\":0.9,\"y\":0.4553526697429138,\"yshift\":10},{\"showarrow\":false,\"text\":\"f1=0.8\",\"x\":0.9,\"y\":0.7181761006289309,\"yshift\":10}],\"width\":550,\"height\":550,\"margin\":{\"l\":40,\"r\":40,\"t\":40,\"b\":40}},                        {\"displayModeBar\": true, \"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('41b9f11f-aca1-4c00-98f0-b8c4bf74e66a');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, f1_score, recall_score, precision_score, precision_recall_curve, confusion_matrix, matthews_corrcoef\n",
        "preds2 = [1 if i >= 0.5 else 0 for i in preds]\n",
        "mcc = matthews_corrcoef(target, preds2)\n",
        "precision = precision_score(target, preds2)\n",
        "recall = recall_score(target, preds2)\n",
        "f1 = f1_score(target, preds2, average='weighted')\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"Matthews Corr Coef:\", mcc)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"f-1 score:\", f1)\n",
        "print(\"\\n\")\n",
        "print(classification_report(target, preds2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VT83h4xfY7IF",
        "outputId": "5b7d6178-2e88-4220-a7a8-85f5f0fae5eb"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Matthews Corr Coef: 0.13392962307934062\n",
            "Precision: 0.9654025282767797\n",
            "Recall: 0.982396750169262\n",
            "f-1 score: 0.9422646675299097\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.21      0.12      0.15        59\n",
            "         1.0       0.97      0.98      0.97      1477\n",
            "\n",
            "    accuracy                           0.95      1536\n",
            "   macro avg       0.59      0.55      0.56      1536\n",
            "weighted avg       0.94      0.95      0.94      1536\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "def show_conf_matrix(target, preds, set1 = \"\", model=\"\", run=None):\n",
        "    confmat_DNN = confusion_matrix(target, preds)\n",
        "    print(\"CM - \" +set1 +  \" Set\")\n",
        "    print(\"-----------\")\n",
        "    print(confmat_DNN)\n",
        "    plt.figure(figsize=(4,4))\n",
        "    fig = sns.heatmap(confmat_DNN, annot=True,  linewidths=.5, square = True, cmap = 'Blues')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.title(\"CM - \" +set1 +  \" Set\" , size = 15)\n",
        "\n",
        "    if run:\n",
        "        run[\"confusion-matrix\"] = fig"
      ],
      "metadata": {
        "id": "r6IZu6ULb_TV"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_conf_matrix(target, preds2, set1 = \"Test\", model=\"\", run=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "pIWBXbcxcAGT",
        "outputId": "63d79153-416f-4695-faa3-b0e4a7a7353e"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CM - Test Set\n",
            "-----------\n",
            "[[   7   52]\n",
            " [  26 1451]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "780e02f01b3ae00d5e97f14df45fcdece40e9a09f09f224add9952588133a4cb"
      }
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "uUZPmd-OcEVB"
      ],
      "toc_visible": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}