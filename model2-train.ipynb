{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"780e02f01b3ae00d5e97f14df45fcdece40e9a09f09f224add9952588133a4cb"}},"colab":{"provenance":[],"toc_visible":true,"collapsed_sections":["uUZPmd-OcEVB"]},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"4246a68b512b471cab2f45debf969e23":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c35b504322eb428fa76994177a23262b","IPY_MODEL_afe8f80681a944bd8aff35a74ed24916","IPY_MODEL_cb9f96537e6049dfb796a8b311b3b318"],"layout":"IPY_MODEL_bc544100a8204b7a83569a4c875b76e0"}},"c35b504322eb428fa76994177a23262b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a89c89bc44a4052bf4dc94da4a59e4a","placeholder":"​","style":"IPY_MODEL_b11abacbbd6347dc9f137c9dfba39c1b","value":"Downloading: 100%"}},"afe8f80681a944bd8aff35a74ed24916":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7a8665042ef44865aee292361b1b3c70","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fd8bf205a56f4dcc97b18c335a41433e","value":231508}},"cb9f96537e6049dfb796a8b311b3b318":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_28fb8a4360414048a5924f0b0e4c226f","placeholder":"​","style":"IPY_MODEL_671e6d9f89ba4eda9e163102ba582ad5","value":" 232k/232k [00:00&lt;00:00, 622kB/s]"}},"bc544100a8204b7a83569a4c875b76e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a89c89bc44a4052bf4dc94da4a59e4a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b11abacbbd6347dc9f137c9dfba39c1b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7a8665042ef44865aee292361b1b3c70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd8bf205a56f4dcc97b18c335a41433e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"28fb8a4360414048a5924f0b0e4c226f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"671e6d9f89ba4eda9e163102ba582ad5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f9762cafd61649b985746d1c584b1524":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c1ec951787bb4948ba711f8249fd2c66","IPY_MODEL_6dc501456e5747dba906957cb9559270","IPY_MODEL_63bb5e6bfeba4b3bb72ba09c940656c1"],"layout":"IPY_MODEL_ba32f233d6ef46719f27b8c29e453ef7"}},"c1ec951787bb4948ba711f8249fd2c66":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_556fdceed894496cb2409b69d3b7233f","placeholder":"​","style":"IPY_MODEL_24fa80c9acb749a8a84b994c5f33f6cd","value":"Downloading: 100%"}},"6dc501456e5747dba906957cb9559270":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e20717d65e449cc90a7c328fbb4e874","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bdce1b6508dd4d7da9f09ae13ad1047b","value":28}},"63bb5e6bfeba4b3bb72ba09c940656c1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_79368710f7c44f2d8a35fac50ba3a751","placeholder":"​","style":"IPY_MODEL_29b9c76e6d8a4fbc81190beeabf54d0a","value":" 28.0/28.0 [00:00&lt;00:00, 1.02kB/s]"}},"ba32f233d6ef46719f27b8c29e453ef7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"556fdceed894496cb2409b69d3b7233f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"24fa80c9acb749a8a84b994c5f33f6cd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1e20717d65e449cc90a7c328fbb4e874":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bdce1b6508dd4d7da9f09ae13ad1047b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"79368710f7c44f2d8a35fac50ba3a751":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29b9c76e6d8a4fbc81190beeabf54d0a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4ea74383abfa4c929a473f7a191c9b31":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f18ea6dcb4774215ba9290a377e6f711","IPY_MODEL_06cd9e46559d4e3ab55a165c79e01275","IPY_MODEL_10883f587ef547adac24de092460d387"],"layout":"IPY_MODEL_f467a4aed68247ea882a547ab1aee155"}},"f18ea6dcb4774215ba9290a377e6f711":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8f2a5040edc4cb1981cf03e3e17caad","placeholder":"​","style":"IPY_MODEL_e16d2ed298404ee0b127a7ede726e437","value":"Downloading: 100%"}},"06cd9e46559d4e3ab55a165c79e01275":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5590e7a35fa743a38692afdd9dbc3f41","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e2c9fec5ff2a4cc5b2dbbdbbd11853b7","value":570}},"10883f587ef547adac24de092460d387":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c1021f2eb9674d3d84ef77544db9046d","placeholder":"​","style":"IPY_MODEL_3920cff77bc04533ae1f3078c4c4b502","value":" 570/570 [00:00&lt;00:00, 20.8kB/s]"}},"f467a4aed68247ea882a547ab1aee155":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8f2a5040edc4cb1981cf03e3e17caad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e16d2ed298404ee0b127a7ede726e437":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5590e7a35fa743a38692afdd9dbc3f41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2c9fec5ff2a4cc5b2dbbdbbd11853b7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c1021f2eb9674d3d84ef77544db9046d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3920cff77bc04533ae1f3078c4c4b502":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3a7fb52a5e234b669ddcc9728cb6e9e5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1b461a7071304c4195d8ee70f0a575bf","IPY_MODEL_863ee13b969948f284148cf17eb536cc","IPY_MODEL_018796e0ad424954af6eb45d29192478"],"layout":"IPY_MODEL_cd7fc90e670942adb881dfe304b4d772"}},"1b461a7071304c4195d8ee70f0a575bf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e3a46a296e4431c93b8ea8ff01ad51a","placeholder":"​","style":"IPY_MODEL_fdd372c15b7d47e68919d7310ae41203","value":"Epoch: :   0%"}},"863ee13b969948f284148cf17eb536cc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_40e89d977e244ef399e726c146d864d8","max":5,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5aaf4c415d9945c781b8194b01c8f757","value":0}},"018796e0ad424954af6eb45d29192478":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_20cf793e554e4969bec0b1a9d4740cc5","placeholder":"​","style":"IPY_MODEL_c2bb602182af495e9e6c55c4cff9eda9","value":" 0/5 [03:08&lt;?, ?it/s, Epoch=0, Training loss=0.693, Training Acc=0.966, Step=1, from=15]"}},"cd7fc90e670942adb881dfe304b4d772":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e3a46a296e4431c93b8ea8ff01ad51a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fdd372c15b7d47e68919d7310ae41203":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"40e89d977e244ef399e726c146d864d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5aaf4c415d9945c781b8194b01c8f757":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"20cf793e554e4969bec0b1a9d4740cc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2bb602182af495e9e6c55c4cff9eda9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# #install python 3.9\n# !sudo apt-get update -y\n# !sudo apt-get install python3.9\n\n# #change alternatives\n# !sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1\n# !sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.9.13\n\n# #check python version\n# !python --version\n# #3.9.16\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3HKxV1g6d2Co","outputId":"354d8d5e-e479-4f5a-85ab-5026e55d01c9","execution":{"iopub.status.busy":"2022-12-15T13:36:51.891400Z","iopub.execute_input":"2022-12-15T13:36:51.891773Z","iopub.status.idle":"2022-12-15T13:36:51.896886Z","shell.execute_reply.started":"2022-12-15T13:36:51.891742Z","shell.execute_reply":"2022-12-15T13:36:51.895756Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import sys\nprint(sys.version)","metadata":{"execution":{"iopub.status.busy":"2022-12-15T13:36:51.902605Z","iopub.execute_input":"2022-12-15T13:36:51.902892Z","iopub.status.idle":"2022-12-15T13:36:51.907743Z","shell.execute_reply.started":"2022-12-15T13:36:51.902867Z","shell.execute_reply":"2022-12-15T13:36:51.906514Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) \n[GCC 9.4.0]\n","output_type":"stream"}]},{"cell_type":"code","source":"CUDA_LAUNCH_BLOCKING=1","metadata":{"id":"nXTkNDCVbpjA","execution":{"iopub.status.busy":"2022-12-15T13:36:51.912877Z","iopub.execute_input":"2022-12-15T13:36:51.913162Z","iopub.status.idle":"2022-12-15T13:36:51.918771Z","shell.execute_reply.started":"2022-12-15T13:36:51.913137Z","shell.execute_reply":"2022-12-15T13:36:51.917545Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"! pip install transformers","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LCMpCNKVccFg","outputId":"95462926-8746-4917-95ad-064bbb2eb1c6","execution":{"iopub.status.busy":"2022-12-15T13:36:51.934995Z","iopub.execute_input":"2022-12-15T13:36:51.935255Z","iopub.status.idle":"2022-12-15T13:37:01.775450Z","shell.execute_reply.started":"2022-12-15T13:36:51.935230Z","shell.execute_reply":"2022-12-15T13:37:01.774080Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.20.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.7.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.1)\nRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.13.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.8.0)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.3)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.12)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.9.24)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"# !conda install pytorch torchvision -c pytorch","metadata":{"execution":{"iopub.status.busy":"2022-12-15T13:37:01.778538Z","iopub.execute_input":"2022-12-15T13:37:01.779267Z","iopub.status.idle":"2022-12-15T13:37:01.784258Z","shell.execute_reply.started":"2022-12-15T13:37:01.779224Z","shell.execute_reply":"2022-12-15T13:37:01.783266Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport typing\nimport transformers\nfrom transformers import TFAutoModel, AutoTokenizer, BertTokenizer, AutoConfig, BertModel\n#%load_ext blackcellmagic","metadata":{"id":"R5EIgqmDcEUi","execution":{"iopub.status.busy":"2022-12-15T13:37:01.786379Z","iopub.execute_input":"2022-12-15T13:37:01.787835Z","iopub.status.idle":"2022-12-15T13:37:01.795656Z","shell.execute_reply.started":"2022-12-15T13:37:01.787796Z","shell.execute_reply":"2022-12-15T13:37:01.794379Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive')\n# %cd /content/drive/My Drive/FintechDS\nimport os\nos.listdir('/kaggle/input/')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tsj3kKyIc-6a","outputId":"87a4ee32-cefd-42c0-e620-8cddc561b4b4","execution":{"iopub.status.busy":"2022-12-15T13:37:01.799189Z","iopub.execute_input":"2022-12-15T13:37:01.799999Z","iopub.status.idle":"2022-12-15T13:37:01.808524Z","shell.execute_reply.started":"2022-12-15T13:37:01.799961Z","shell.execute_reply":"2022-12-15T13:37:01.807368Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"['amazon-fake-reviews-scrapped']"},"metadata":{}}]},{"cell_type":"code","source":"df = pd.read_csv(\n    \"../input/amazon-fake-reviews-scrapped/df.csv\",\n    dtype={\n        \"product_title\": str,\n        \"review_title\": str,\n        \"review_text\": str,\n        \"product_id\": str,\n    },\n)\nreviews_scraped = pd.read_csv(\n    \"../input/amazon-fake-reviews-scrapped/reviews_scraped.csv\",\n    dtype={\"review_title\": str, \"review_text\": str, \"product_id\": str},\n)\nprint(df.shape)\nprint(reviews_scraped.shape)\n\n\n#df = df[0:10000]\n\n#reviews_scraped = reviews_scraped[0:20000]\nreviews_scraped.fillna(0,inplace= True)\ndf.fillna(0,inplace=True)\n","metadata":{"id":"g2DpCBqccEUn","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e2e80aa2-c548-419a-884f-21df22b7247a","execution":{"iopub.status.busy":"2022-12-15T13:37:01.810118Z","iopub.execute_input":"2022-12-15T13:37:01.810789Z","iopub.status.idle":"2022-12-15T13:37:04.128698Z","shell.execute_reply.started":"2022-12-15T13:37:01.810754Z","shell.execute_reply":"2022-12-15T13:37:04.127700Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"(18107, 48)\n(99889, 16)\n","output_type":"stream"}]},{"cell_type":"code","source":"df.columns","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oJS9orGf8khl","outputId":"ab4e1f5b-3251-4018-8e66-6c049c387240","execution":{"iopub.status.busy":"2022-12-15T13:37:04.130094Z","iopub.execute_input":"2022-12-15T13:37:04.131934Z","iopub.status.idle":"2022-12-15T13:37:04.139077Z","shell.execute_reply.started":"2022-12-15T13:37:04.131895Z","shell.execute_reply":"2022-12-15T13:37:04.137988Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"Index(['Unnamed: 0', 'rating', 'verified', 'PRODUCT_CATEGORY', 'product_id',\n       'review_title', 'review_text', 'cat_0', 'cat_1', 'cat_2', 'cat_3',\n       'cat_4', 'cat_5', 'cat_6', 'cat_7', 'cat_8', 'cat_9', 'cat_10',\n       'cat_11', 'cat_12', 'cat_13', 'cat_14', 'cat_15', 'cat_16', 'cat_17',\n       'cat_18', 'cat_19', 'cat_20', 'cat_21', 'cat_22', 'cat_23', 'cat_24',\n       'cat_25', 'cat_26', 'cat_27', 'cat_28', 'cat_29', 'label',\n       'text_sentiment', 'text_subjectivity', 'rating_count', 'rating_avg',\n       'rating1', 'rating2', 'rating3', 'rating4', 'rating5', 'product_title'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"reviews_scraped.columns ","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eR_UJsd-8mre","outputId":"914e564d-4364-4747-ac36-456ae02c30ce","execution":{"iopub.status.busy":"2022-12-15T13:37:04.140272Z","iopub.execute_input":"2022-12-15T13:37:04.141974Z","iopub.status.idle":"2022-12-15T13:37:04.152758Z","shell.execute_reply.started":"2022-12-15T13:37:04.141928Z","shell.execute_reply":"2022-12-15T13:37:04.151684Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"Index(['Unnamed: 0', 'product_id', 'review_title', 'rating_count',\n       'rating_avg', 'rating1', 'rating2', 'rating3', 'rating4', 'rating5',\n       'helpful', 'verified', 'review_text', 'rating', 'text_sentiment',\n       'text_subjectivity'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"markdown","source":"### Constants","metadata":{"id":"CAGcO0hbcEUu"}},{"cell_type":"code","source":"BERT_TOKENIZER_LENGTH: int = 256\nBERT_EMBEDDING_SIZE : int = 768\nDEVICE :torch.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nBERT_TOKENIZER = BertTokenizer.from_pretrained(\"bert-base-uncased\")\nBERT_CONFIG, _ = AutoConfig.from_pretrained('bert-base-uncased', output_attention=True, return_unused_kwargs=True)\nSCRAPED_REVIEW_LIMIT = 10\nBATCH_SIZE=256","metadata":{"id":"1nSr7Y6-cEUw","colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["4246a68b512b471cab2f45debf969e23","c35b504322eb428fa76994177a23262b","afe8f80681a944bd8aff35a74ed24916","cb9f96537e6049dfb796a8b311b3b318","bc544100a8204b7a83569a4c875b76e0","2a89c89bc44a4052bf4dc94da4a59e4a","b11abacbbd6347dc9f137c9dfba39c1b","7a8665042ef44865aee292361b1b3c70","fd8bf205a56f4dcc97b18c335a41433e","28fb8a4360414048a5924f0b0e4c226f","671e6d9f89ba4eda9e163102ba582ad5","f9762cafd61649b985746d1c584b1524","c1ec951787bb4948ba711f8249fd2c66","6dc501456e5747dba906957cb9559270","63bb5e6bfeba4b3bb72ba09c940656c1","ba32f233d6ef46719f27b8c29e453ef7","556fdceed894496cb2409b69d3b7233f","24fa80c9acb749a8a84b994c5f33f6cd","1e20717d65e449cc90a7c328fbb4e874","bdce1b6508dd4d7da9f09ae13ad1047b","79368710f7c44f2d8a35fac50ba3a751","29b9c76e6d8a4fbc81190beeabf54d0a","4ea74383abfa4c929a473f7a191c9b31","f18ea6dcb4774215ba9290a377e6f711","06cd9e46559d4e3ab55a165c79e01275","10883f587ef547adac24de092460d387","f467a4aed68247ea882a547ab1aee155","b8f2a5040edc4cb1981cf03e3e17caad","e16d2ed298404ee0b127a7ede726e437","5590e7a35fa743a38692afdd9dbc3f41","e2c9fec5ff2a4cc5b2dbbdbbd11853b7","c1021f2eb9674d3d84ef77544db9046d","3920cff77bc04533ae1f3078c4c4b502"]},"outputId":"705052f3-0563-4dff-d2e1-feb7b411b8c2","execution":{"iopub.status.busy":"2022-12-15T13:37:04.154389Z","iopub.execute_input":"2022-12-15T13:37:04.154822Z","iopub.status.idle":"2022-12-15T13:37:14.268487Z","shell.execute_reply.started":"2022-12-15T13:37:04.154788Z","shell.execute_reply":"2022-12-15T13:37:14.267525Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cccc123218294ae8a518e9b1fa013463"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1dc9513e07e3405eb2f3c063750ae5b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00278d8c9a3e4574a1915efbab64f12f"}},"metadata":{}}]},{"cell_type":"markdown","source":"### Dataset\n","metadata":{"id":"vJPsdMIqcEUx"}},{"cell_type":"code","source":"if sys.version_info >= (3, 8):\n    from typing import TypedDict\nelse:\n    from typing_extensions import TypedDict\nfrom torch.utils.data import Dataset, DataLoader\nfrom dataclasses import dataclass\n\n\nclass BertInput(TypedDict):\n    attention_mask: torch.Tensor\n    \"\"\"shape: (1,MAX_SEQUENCE_LENGTH_BERT_TOKENIZER)\"\"\"\n    input_ids: torch.Tensor\n    \"\"\"shape: (1,MAX_SEQUENCE_LENGTH_BERT_TOKENIZER)\"\"\"\n\n\nclass BertInputBatch:\n    def __init__(self, attention_mask: torch.Tensor, input_ids: torch.Tensor) -> None:\n        self.attention_mask = attention_mask\n        self.input_ids = input_ids\n\n    @staticmethod\n    def from_batch_encoding(\n        batch_encoding: transformers.tokenization_utils_base.BatchEncoding,\n    ):\n        return BertInputBatch(\n            torch.tensor(batch_encoding[\"attention_mask\"]).to(DEVICE),\n            torch.tensor(batch_encoding[\"input_ids\"]).to(DEVICE),\n        )\n\n    attention_mask: torch.Tensor\n    input_ids: torch.Tensor\n\n    @property\n    def shape(self) -> torch.Size:\n        return self.input_ids.shape\n\n    def __getitem__(self, i: int) -> BertInput:\n        return {\n            \"attention_mask\": self.attention_mask[i : i + 1, :],\n            \"input_ids\": self.input_ids[i : i + 1, :],\n        }\n\n\n# class ReviewDataSetItemInput(TypedDict):\n#     \"\"\"one fake/real review with X context reviews from the same product\"\"\"\n\n#     product_title_bert_input: BertInput\n#     review_title_bert_input: BertInput\n#     review_text_bert_input: BertInput\n\n#     review_features: torch.Tensor\n#     \"\"\"shape: (4)    Rating [1-5; 1] + Verified Purchase [0-1; 1] + SA Valence + Subjectivity [0.0-1.0; 2]\"\"\"\n\n#     product_features: torch.Tensor\n#     \"\"\"shape: (37)    Ratings (1-5) Ratio [0.0-1.0]; 5] + Rating Avg [f64; 1] + Rating Count [u64; 1] + Category [u64; 30]\"\"\"\n\n#     scraped_review_features: torch.Tensor\n#     \"\"\"shape: (X, 4)    Rating [1-5; 1] + Verified Purchase [0-1; 1] + SA Valence + Subjectivity [0.0-1.0; 2]\"\"\"\n\n#     scraped_helpful: torch.Tensor\n#     \"\"\"shape: (X, 1)    Helpfulness [u64; 1]\"\"\"\n\n#     scraped_review_texts: BertInputBatch\n\n#     scraped_review_titles: BertInputBatch\n\nPACKED_DATASET_ROW_SIZE = 37 + 4 + 6 * BERT_TOKENIZER_LENGTH + SCRAPED_REVIEW_LIMIT * (1 + 4 + 4 * BERT_TOKENIZER_LENGTH)\n\nclass ReviewsDataSet(Dataset):\n    \"\"\"\n    Args:\n        df: pd.DataFrame of size M with columns:\n            - rating (1-5)\n            - verified (0-1)\n            - product_id (str)\n            - review_title (str)\n            - review_text (str)\n            - cat_0 - cat_29 (0-1)\n            - label (0-1)\n            - text_sentiment (0.0-1.0)\n            - text_subjectivity (0.0-1.0)\n            - rating_count (u64)\n            - rating_avg (1.0-5.0)\n            - rating1 - rating5  (0.0-1.0)\n            - product_title (str)\n\n        reviews_scraped:  pd.DataFrame of size N with columns:\n            - product_id (str)\n            - review_title (str)\n            - review_text (str)\n            - helpful (u64)\n            - verified (0-1)\n            - rating (1-5)\n            - text_sentiment (0.0-1.0)\n            - text_subjectivity (0.0-1.0)\n    \"\"\"\n\n    df: pd.DataFrame\n    reviews_scraped: pd.DataFrame\n\n    df_product_title_encoded: BertInputBatch\n    \"\"\"shape: (N, MAX_SEQUENCE_LENGTH_BERT_TOKENIZER)\"\"\"\n\n    df_review_title_encoded: BertInputBatch\n    \"\"\"shape: (N, MAX_SEQUENCE_LENGTH_BERT_TOKENIZER)\"\"\"\n\n    df_review_text_encoded: BertInputBatch\n    \"\"\"shape: (N, MAX_SEQUENCE_LENGTH_BERT_TOKENIZER)\"\"\"\n\n    review_feature_vector: torch.Tensor\n    \"\"\"shape: (N, 4)    Rating [1-5; 1] + Verified Purchase [0-1; 1] + SA Valence + Subjectivity [0.0-1.0; 2]\"\"\"\n\n    product_feature_vector: torch.Tensor\n    \"\"\"shape: (N, 37)    Ratings (1-5) Ratio [0.0-1.0]; 5] + Rating Avg [f64; 1] + Rating Count [u64; 1] + Category [u64; 30]\"\"\"\n\n    label_vector: torch.Tensor\n    \"\"\"shape: (N, 1) \"\"\"\n\n    scraped_review_feature_vector: torch.Tensor\n    \"\"\"shape: (M, 4)    Rating [1-5; 1] + Verified Purchase [0-1; 1] + SA Valence + Subjectivity [0.0-1.0; 2]\"\"\"\n\n    scraped_review_helpful: torch.Tensor\n    \"\"\"shape: (M, 1)    Helpfulness [u64; 1]\"\"\"\n\n    scraped_review_title_encoded: BertInputBatch\n    \"\"\"shape: (M, MAX_SEQUENCE_LENGTH_BERT_TOKENIZER)\"\"\"\n\n    scraped_review_text_encoded: BertInputBatch\n    \"\"\"shape: (M, MAX_SEQUENCE_LENGTH_BERT_TOKENIZER)\"\"\"\n\n    # product_id_indexes_map: dict[str, list[int]]\n    # \"\"\"For each product, maps the product id to the int indices for all scraped context reviews for this product\"\"\"\n\n    def __init__(self, df, reviews_scraped):\n\n        self.df = df\n        self.reviews_scraped = reviews_scraped\n        M = reviews_scraped.__len__()\n        N = df.__len__()\n\n        # use bert tokenizer to tokenize all strings of the\n        print(\n            f\"creating ReviewsDataSet (real/fake reviews: N={len(df)}, context reviews: M={len(reviews_scraped)}\"\n        )\n        print(f\"    bert tokeinzer working...\")\n\n        def bert_input_batch_tokenize(\n            #list_of_strings: list[str],\n            list_of_strings: list,\n        ) -> BertInputBatch:\n            list_of_strings = [str(e) for e in list_of_strings]\n            return BertInputBatch.from_batch_encoding(\n                BERT_TOKENIZER.batch_encode_plus(\n                    list_of_strings,\n                    max_length=BERT_TOKENIZER_LENGTH,\n                    pad_to_max_length=True,\n                    truncation=True,\n                    return_token_type_ids=False,\n                )\n            )\n\n        print(f\"    creating df_product_title_encoded...\")\n        self.df_product_title_encoded = bert_input_batch_tokenize(\n            df[\"product_title\"].tolist()\n        )\n\n        print(f\"    creating df_review_title_encoded...\")\n        self.df_review_title_encoded = bert_input_batch_tokenize(\n            df[\"review_title\"].tolist()\n        )\n\n        print(f\"    creating df_review_text_encoded...\")\n        self.df_review_text_encoded = bert_input_batch_tokenize(\n            df[\"review_text\"].tolist()\n        )\n\n        print(f\"    creating scraped_review_title_encoded...\")\n        self.scraped_review_title_encoded = bert_input_batch_tokenize(\n            reviews_scraped[\"review_title\"].tolist()\n        )\n\n        print(f\"    creating scraped_review_text_encoded...\")\n        self.scraped_review_text_encoded = bert_input_batch_tokenize(\n            reviews_scraped[\"review_text\"].tolist()\n        )\n\n        review_feature_cols = [\n            \"rating\",\n            \"verified\",\n            \"text_sentiment\",\n            \"text_subjectivity\",\n        ]\n        self.review_feature_vector = torch.tensor(df[review_feature_cols].to_numpy()).float().to(DEVICE)\n        self.label_vector = torch.tensor(df[[\"label\"]].to_numpy()).float().to(DEVICE)\n        self.scraped_review_feature_vector = torch.tensor(\n            reviews_scraped[review_feature_cols].to_numpy()\n        ).float().to(DEVICE)\n        self.scraped_review_helpful = torch.reshape(\n            torch.tensor(reviews_scraped[\"helpful\"].to_numpy()).float(), (M, 1)\n        ).to(DEVICE)\n\n        product_feature_cols = [\n            \"rating_count\",\n            \"rating_avg\",\n            \"rating1\",\n            \"rating2\",\n            \"rating3\",\n            \"rating4\",\n            \"rating5\",\n        ] + [f\"cat_{i}\" for i in range(0, 30)]\n        self.product_feature_vector = torch.tensor(df[product_feature_cols].to_numpy()).float().to(DEVICE)\n\n    #def __getitem__(self, index) -> tuple[torch.Tensor, torch.Tensor]:\n    def __getitem__(self, index):\n        product_id = self.df.loc[index, \"product_id\"]\n\n        # get indexes in scraped data where product id is the same\n        indices = torch.tensor(\n            reviews_scraped.index[\n                reviews_scraped[\"product_id\"] == product_id\n            ].to_numpy()\n        ).int().to(DEVICE)\n\n        def slice(tensor: torch.Tensor) -> torch.Tensor:\n            \"\"\"selects only the subset where index indicates product id is the same\"\"\"\n            return torch.index_select(tensor, 0, indices)\n\n        def zero_pad_ravel(tensor: torch.Tensor, X) -> torch.Tensor:\n            \"\"\"takes in a tensor of shape (N,D) appends zero elements or removes elements from the end to create an (X,D) shaped tensor and then reshapes that into a (X*D) shaped tensor\"\"\"\n            (N, D) = tensor.shape\n            return torch.reshape(\n                torch.nn.functional.pad(\n                    input=tensor[0:X, :],\n                    pad=(0, 0, 0, max(X - N, 0)),\n                    mode=\"constant\",\n                    value=0,\n                ),\n                (-1,),\n            )\n\n        # slice the tensors of relevant scraped reviews out of the total reviews:\n        scraped_helpful = slice(self.scraped_review_helpful)\n        _N = scraped_helpful.shape[0]  # is N\n        assert scraped_helpful.shape == (_N, 1)\n\n        scraped_review_features = slice(self.scraped_review_feature_vector)\n        assert scraped_review_features.shape == (_N, 4)\n\n        scraped_review_texts_att = slice(\n            self.scraped_review_text_encoded.attention_mask\n        )\n\n        assert scraped_review_texts_att.shape == (_N, BERT_TOKENIZER_LENGTH)\n\n        scraped_review_texts_ids = slice(self.scraped_review_text_encoded.input_ids)\n        assert scraped_review_texts_ids.shape == (_N, BERT_TOKENIZER_LENGTH)\n\n        scraped_review_titles_att = slice(\n            self.scraped_review_title_encoded.attention_mask\n        )\n        assert scraped_review_titles_att.shape == (_N, BERT_TOKENIZER_LENGTH)\n\n        scraped_review_titles_ids = slice(self.scraped_review_title_encoded.input_ids)\n        assert scraped_review_titles_ids.shape == (_N, BERT_TOKENIZER_LENGTH)\n\n        # combine all review data into a (X,) shaped tensor:\n        scraped_block = torch.cat(\n            (\n                scraped_helpful,\n                scraped_review_features,\n                scraped_review_texts_att,\n                scraped_review_texts_ids,\n                scraped_review_titles_att,\n                scraped_review_titles_ids,\n            ),\n            dim=1,\n        )\n        scraped_block_flat = zero_pad_ravel(scraped_block, SCRAPED_REVIEW_LIMIT)\n        assert scraped_block_flat.shape == (\n            SCRAPED_REVIEW_LIMIT * (1 + 4 + 4 * BERT_TOKENIZER_LENGTH),\n        )\n\n        product_title_bert_input_att = self.df_product_title_encoded[index][\n            \"attention_mask\"\n        ][0, :]\n        assert product_title_bert_input_att.shape == (BERT_TOKENIZER_LENGTH,)\n        product_title_bert_input_ids = self.df_product_title_encoded[index][\n            \"input_ids\"\n        ][0, :]\n        assert product_title_bert_input_ids.shape == (BERT_TOKENIZER_LENGTH,)\n        review_title_bert_input_att = self.df_review_title_encoded[index][\n            \"attention_mask\"\n        ][0, :]\n        assert review_title_bert_input_att.shape == (BERT_TOKENIZER_LENGTH,)\n        review_title_bert_input_ids = self.df_review_title_encoded[index][\"input_ids\"][\n            0, :\n        ]\n        assert review_title_bert_input_ids.shape == (BERT_TOKENIZER_LENGTH,)\n        review_text_bert_input_att = self.df_review_text_encoded[index][\n            \"attention_mask\"\n        ][0, :]\n        assert review_text_bert_input_att.shape == (BERT_TOKENIZER_LENGTH,)\n        review_text_bert_input_ids = self.df_review_text_encoded[index][\"input_ids\"][\n            0, :\n        ]\n        assert review_text_bert_input_ids.shape == (BERT_TOKENIZER_LENGTH,)\n\n        product_features = self.product_feature_vector[index]  # shape: (37)\n        assert product_features.shape == (37,)\n\n        review_features = self.review_feature_vector[index]  # shape: (4)\n        assert review_features.shape == (4,)\n\n        catted = torch.cat(\n            (\n                product_features,\n                review_features,\n                product_title_bert_input_att,\n                product_title_bert_input_ids,\n                review_title_bert_input_att,\n                review_title_bert_input_ids,\n                review_text_bert_input_att,\n                review_text_bert_input_ids,\n                scraped_block_flat,\n            ),\n            dim=0,\n        )\n        assert catted.shape == (PACKED_DATASET_ROW_SIZE,)\n        ##############################################################\n        ## Data layout in the catted tensor row, assuming BERT_TOKENIZER_LENGTH = 256 and SCRAPED_REVIEW_LIMIT = 10\n        ## | 37 | 4 | 256+256 | 256+256 | 256+256 | 10 * ( | 1 | 4 | 256+256 | 256+256 |)\n\n        label = self.label_vector[index]\n        return (catted, label)\n\n    def __len__(self) -> int:\n        return self.df.__len__()","metadata":{"id":"wIqU78JOcEUy","execution":{"iopub.status.busy":"2022-12-15T13:37:14.270111Z","iopub.execute_input":"2022-12-15T13:37:14.270690Z","iopub.status.idle":"2022-12-15T13:37:14.309007Z","shell.execute_reply.started":"2022-12-15T13:37:14.270649Z","shell.execute_reply":"2022-12-15T13:37:14.308078Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"#### unpacking functions","metadata":{"id":"HaN9_42rcEU3"}},{"cell_type":"code","source":"def unpack_dataset_items(packed_batch_tensor: torch.Tensor):\n    \"\"\"\n    expects packed_batch_tensor to be of shape\n    \"\"\"\n    assert packed_batch_tensor.shape[1] == PACKED_DATASET_ROW_SIZE\n    (B, T) = packed_batch_tensor.shape\n\n    c: int = 0\n\n    def next(n: int) -> torch.Tensor:\n        nonlocal c\n        slice = packed_batch_tensor[:, c : c + n]\n        c += n\n        return slice\n\n    product_features = next(37)\n    assert product_features.shape == (B, 37)\n\n    review_features = next(4)\n    assert review_features.shape == (B, 4)\n\n    product_title_bert_input_att = next(BERT_TOKENIZER_LENGTH)\n    product_title_bert_input_ids = next(BERT_TOKENIZER_LENGTH)\n    review_title_bert_input_att = next(BERT_TOKENIZER_LENGTH)\n    review_title_bert_input_ids = next(BERT_TOKENIZER_LENGTH)\n    review_text_bert_input_att = next(BERT_TOKENIZER_LENGTH)\n    review_text_bert_input_ids = next(BERT_TOKENIZER_LENGTH)\n    assert (\n        product_title_bert_input_att.shape\n        == product_title_bert_input_ids.shape\n        == review_title_bert_input_att.shape\n        == review_title_bert_input_ids.shape\n        == review_text_bert_input_att.shape\n        == review_text_bert_input_ids.shape\n        == (B, BERT_TOKENIZER_LENGTH)\n    )\n\n    _scraped_block_flat = next(\n        SCRAPED_REVIEW_LIMIT * (1 + 4 + 4 * BERT_TOKENIZER_LENGTH)\n    )\n    assert _scraped_block_flat.shape == (\n        B,\n        SCRAPED_REVIEW_LIMIT * (1 + 4 + 4 * BERT_TOKENIZER_LENGTH),\n    )\n\n    scraped_block = torch.reshape(\n        _scraped_block_flat,\n        (B, SCRAPED_REVIEW_LIMIT, (1 + 4 + 4 * BERT_TOKENIZER_LENGTH)),\n    )\n    assert scraped_block.shape == (\n        B,\n        SCRAPED_REVIEW_LIMIT,\n        (1 + 4 + 4 * BERT_TOKENIZER_LENGTH),\n    )\n\n    scraped_helpful = scraped_block[:, :, 0:1]\n    assert scraped_helpful.shape == (B, SCRAPED_REVIEW_LIMIT, 1)\n\n    scraped_review_features = scraped_block[:, :, 1:5]\n    assert scraped_review_features.shape == (B, SCRAPED_REVIEW_LIMIT, 4)\n\n    scraped_review_title_bert_input_att = scraped_block[\n        :, :, 5 : 5 + BERT_TOKENIZER_LENGTH\n    ]\n    scraped_review_title_bert_input_ids = scraped_block[\n        :, :, 5 + BERT_TOKENIZER_LENGTH : 5 + 2 * BERT_TOKENIZER_LENGTH\n    ]\n    scraped_review_text_bert_input_att = scraped_block[\n        :, :, 5 + 2 * BERT_TOKENIZER_LENGTH : 5 + 3 * BERT_TOKENIZER_LENGTH\n    ]\n    scraped_review_text_bert_input_ids = scraped_block[\n        :, :, 5 + 3 * BERT_TOKENIZER_LENGTH : 5 + 4 * BERT_TOKENIZER_LENGTH\n    ]\n\n    return (\n        product_features,\n        review_features,\n        product_title_bert_input_att,\n        product_title_bert_input_ids,\n        review_title_bert_input_att,\n        review_title_bert_input_ids,\n        review_text_bert_input_att,\n        review_text_bert_input_ids,\n        (\n            scraped_helpful,\n            scraped_review_features,\n            scraped_review_title_bert_input_att,\n            scraped_review_title_bert_input_ids,\n            scraped_review_text_bert_input_att,\n            scraped_review_text_bert_input_ids,\n        ),\n    )","metadata":{"id":"R7vexK9GcEU5","execution":{"iopub.status.busy":"2022-12-15T13:37:14.313244Z","iopub.execute_input":"2022-12-15T13:37:14.313522Z","iopub.status.idle":"2022-12-15T13:37:14.330577Z","shell.execute_reply.started":"2022-12-15T13:37:14.313497Z","shell.execute_reply":"2022-12-15T13:37:14.329691Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"### Model","metadata":{"id":"CuvMo8wicEU7"}},{"cell_type":"code","source":"from collections import OrderedDict\nimport torch.nn as nn\n#def create_mlp(layer_sizes: list[int]) -> nn.Sequential:\ndef create_mlp(layer_sizes: list):\n    \"\"\"\n    creates an MLP with the given layer_sizes. The first element is the input size, the last one the output size\n    args:\n        layer_sizes: [input_dim, h1_dim, h2_dim, ...., out_dim]\"\"\"\n    assert layer_sizes.__len__() >= 2\n        \n    layers = []\n    for i in range(1, layer_sizes.__len__()):\n        layers.append((f\"hidden_layer_{i}\",nn.Linear(layer_sizes[i-1], layer_sizes[i]) ))\n        layers.append((f\"activation_{i}\",  nn.ReLU()))\n    return nn.Sequential(OrderedDict(layers))","metadata":{"id":"FMnZowjDcEU8","execution":{"iopub.status.busy":"2022-12-15T13:37:14.331986Z","iopub.execute_input":"2022-12-15T13:37:14.332418Z","iopub.status.idle":"2022-12-15T13:37:14.342112Z","shell.execute_reply.started":"2022-12-15T13:37:14.332382Z","shell.execute_reply":"2022-12-15T13:37:14.341188Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"class ReviewEncodingModel(torch.nn.Module):\n\n    def __init__(self, freeze: bool = True, outdim=500) -> None:\n        super(ReviewEncodingModel, self).__init__()\n        self.bert = BertModel(BERT_CONFIG)\n        if freeze:\n            for param in self.bert.parameters():\n                param.requires_grad = False\n        self.out_mlp = create_mlp([BERT_EMBEDDING_SIZE*2+4, outdim])\n    \n    def forward(self, review_features: torch.Tensor, \n               review_title_bert_input_att: torch.Tensor,\n               review_title_bert_input_ids: torch.Tensor,\n               review_text_bert_input_att: torch.Tensor,\n               review_text_bert_input_ids: torch.Tensor, ) -> torch.Tensor:\n        \"\"\"\n        args:\n            review_features: shape: (BATCH_SIZE, 5)\n            review_title_bert_input_att: shape: (BATCH_SIZE, BERT_TOKENIZER_LENGTH)\n            review_title_bert_input_ids: shape: (BATCH_SIZE, BERT_TOKENIZER_LENGTH)\n            review_text_bert_input_att: shape: (BATCH_SIZE, BERT_TOKENIZER_LENGTH)\n            review_text_bert_input_ids: shape: (BATCH_SIZE, BERT_TOKENIZER_LENGTH)\n        returns:\n            torch.Tensor of shape (BATCH_SIZE, OUTDIM)\n        \"\"\"\n\n        # max over all tokens in every dimension of the 768 dimensional embedding\n      \n        bert_title_embedding = self.bert(attention_mask=review_title_bert_input_att.int(), input_ids=review_title_bert_input_ids.int()).last_hidden_state[:,0,:]\n        assert bert_title_embedding.shape == (BATCH_SIZE, BERT_EMBEDDING_SIZE)\n\n        # max over all tokens in every dimension of the 768 dimensional embedding\n        bert_text_embedding = self.bert(attention_mask=review_text_bert_input_att.int(), input_ids=review_text_bert_input_ids.int()).last_hidden_state[:,0,:]\n        assert bert_title_embedding.shape == (BATCH_SIZE, BERT_EMBEDDING_SIZE)\n\n        # concat all on top of each other:\n        catted = torch.cat([bert_title_embedding, bert_text_embedding, review_features], dim=1)\n\n        # apply linear layer and relu:\n        return self.out_mlp(catted)\n\n        \n    def freeze_bert(self, freezed: bool) -> None:\n        for param in self.bert.parameters():\n                param.requires_grad =  not freezed\n","metadata":{"id":"pbDVbiKEcEU-","execution":{"iopub.status.busy":"2022-12-15T13:37:14.343577Z","iopub.execute_input":"2022-12-15T13:37:14.343956Z","iopub.status.idle":"2022-12-15T13:37:14.354490Z","shell.execute_reply.started":"2022-12-15T13:37:14.343916Z","shell.execute_reply":"2022-12-15T13:37:14.353588Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"# Fake Detection Model","metadata":{"id":"qNhRK1ra-SSD"}},{"cell_type":"code","source":"REVIEW_ENCODING_MODEL_OUTDIM = 149\n# REVIEW_ENCODING_MODEL_OUTDIM + 1 has to be divisible by 3 for this to work, bc. we use 3 attention heads\n\nclass FakeDetectionModel(torch.nn.Module):\n    review_encoding_model: ReviewEncodingModel\n    scraped_reviews_transformer: torch.nn.TransformerEncoderLayer\n    outmlp: nn.Sequential\n\n    def __init__(self):\n        super(FakeDetectionModel, self).__init__()\n        self.review_encoding_model: ReviewEncodingModel = ReviewEncodingModel(\n            freeze=True, outdim=REVIEW_ENCODING_MODEL_OUTDIM\n        )\n        self.scraped_reviews_transformer = torch.nn.TransformerEncoderLayer(\n            d_model=REVIEW_ENCODING_MODEL_OUTDIM+1, nhead=15, batch_first=True\n        )\n\n        LAST_FEATURES_DIM = 37 + (REVIEW_ENCODING_MODEL_OUTDIM + 1) + REVIEW_ENCODING_MODEL_OUTDIM +  BERT_EMBEDDING_SIZE\n        # LAST_FEATURES_DIM: product features + transformer output dimension + review encoded + bert embedding from product title\n        self.outmlp = create_mlp([LAST_FEATURES_DIM, 30, 20, 1])\n\n    def forward(self, packed_dataset_rows: torch.Tensor)-> torch.Tensor :\n        \"\"\" \"\n        args:\n            packed_dataset_row: torch.Tensor with shape (BATCH_SIZE, PACKED_DATASET_ROW_SIZE)\n        returns:\n            torch.Tensor with shape: (BATCH_SIZE,1)\n        \"\"\"\n        #print(\"packed_dataset_rows.shape\",packed_dataset_rows.shape )\n        #print(\"BATCH_SIZE, PACKED_DATASET_ROW_SIZE\", BATCH_SIZE, PACKED_DATASET_ROW_SIZE)\n\n\n        assert packed_dataset_rows.shape == (BATCH_SIZE, PACKED_DATASET_ROW_SIZE)\n        (\n            product_features,\n            review_features,\n            product_title_bert_input_att,\n            product_title_bert_input_ids,\n            review_title_bert_input_att,\n            review_title_bert_input_ids,\n            review_text_bert_input_att,\n            review_text_bert_input_ids,\n            (\n                scraped_helpful,\n                scraped_review_features,\n                scraped_review_title_bert_input_att,\n                scraped_review_title_bert_input_ids,\n                scraped_review_text_bert_input_att,\n                scraped_review_text_bert_input_ids,\n            ),\n        ) = unpack_dataset_items(packed_dataset_rows)\n\n        ### CREATE REVIEW ENCODING\n        review_encoding = self.review_encoding_model(review_features, review_title_bert_input_att, review_title_bert_input_ids, review_text_bert_input_att, review_text_bert_input_ids)  # type: ignore\n        \n        assert review_encoding.shape == (BATCH_SIZE, REVIEW_ENCODING_MODEL_OUTDIM)\n\n        ### CREATE REVIEW ENCODINGS FOR ALL SCRAPED REVIEWS\n        ### THEN COMBINE THEM AND THEIR HELPFULNESS VIA THE TRANSFORMER\n\n        # transform (BATCH_SIZE, SCRAPED_REVIEW_LIMIT, 5 + 4 * BERT_TOKENIZER_LENGTH) into (BATCH_SIZE, SCRAPED_REVIEW_LIMIT, REVIEW_ENCODING_MODEL_OUTDIM)\n        transformer_input = torch.zeros(\n            (BATCH_SIZE, SCRAPED_REVIEW_LIMIT, 1 + REVIEW_ENCODING_MODEL_OUTDIM)\n        ).to(DEVICE)\n        for i in range(SCRAPED_REVIEW_LIMIT):\n            transformer_input[:, i, :] = torch.cat(\n            [self.review_encoding_model(\n                scraped_review_features[:, i, :],\n                scraped_review_title_bert_input_att[:, i, :],\n                scraped_review_title_bert_input_ids[:, i, :],\n                scraped_review_text_bert_input_att[:, i, :],\n                scraped_review_text_bert_input_ids[:, i, :],\n            ), scraped_helpful[:,i,:]], dim=1 ) # type: ignore\n        # REVIEW_ENCODING_MODEL_OUTDIM + 1 has to be divisible by 3 for this to work, bc. we use 3 attention heads\n\n        transformer_output = self.scraped_reviews_transformer(transformer_input)[:,-1,:] # type: ignore\n        assert transformer_output.shape == (BATCH_SIZE, 1+ REVIEW_ENCODING_MODEL_OUTDIM)\n\n        ### CREATE BERT EMBEDDING FOR PRODUCT TITLE\n        bert_product_title_embedding = self.review_encoding_model.bert(attention_mask=product_title_bert_input_att.int(), input_ids=product_title_bert_input_ids.int()).last_hidden_state[:,0,:] # type: ignore\n        assert bert_product_title_embedding.shape == (BATCH_SIZE, BERT_EMBEDDING_SIZE)\n        # linear layer connection all\n\n        ### COMBINE PRODUCT INFORMATION (features + title), CONTEXT (other review's encodings and their helpfulness) and REVIEW ENCODING into a single scalar: the real vs. fake prediction\n        catted = torch.cat([product_features, bert_product_title_embedding, review_encoding, transformer_output],dim=1)\n        return torch.sigmoid(self.outmlp(catted)) # type: ignore","metadata":{"id":"6doON378cEVB","execution":{"iopub.status.busy":"2022-12-15T13:37:14.355912Z","iopub.execute_input":"2022-12-15T13:37:14.356585Z","iopub.status.idle":"2022-12-15T13:37:14.371600Z","shell.execute_reply.started":"2022-12-15T13:37:14.356550Z","shell.execute_reply":"2022-12-15T13:37:14.370751Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"### Running","metadata":{"id":"uUZPmd-OcEVB"}},{"cell_type":"markdown","source":"## Create Datasets","metadata":{"id":"kAxRw-zJBWX0"}},{"cell_type":"code","source":"dataset = ReviewsDataSet(df, reviews_scraped)\ndataloader = DataLoader(dataset=dataset, batch_size=BATCH_SIZE)","metadata":{"id":"gEKW5OnVrZkS","colab":{"base_uri":"https://localhost:8080/"},"outputId":"137bd37e-f013-449c-d0ed-96a83aab13b7","execution":{"iopub.status.busy":"2022-12-15T13:37:14.373038Z","iopub.execute_input":"2022-12-15T13:37:14.373497Z","iopub.status.idle":"2022-12-15T13:45:31.008472Z","shell.execute_reply.started":"2022-12-15T13:37:14.373463Z","shell.execute_reply":"2022-12-15T13:45:31.007482Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"creating ReviewsDataSet (real/fake reviews: N=18107, context reviews: M=99889\n    bert tokeinzer working...\n    creating df_product_title_encoded...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  FutureWarning,\n","output_type":"stream"},{"name":"stdout","text":"    creating df_review_title_encoded...\n    creating df_review_text_encoded...\n    creating scraped_review_title_encoded...\n    creating scraped_review_text_encoded...\n","output_type":"stream"}]},{"cell_type":"code","source":"# import torch.utils.data as data\n# train_set_size = int(len(dataset) * 0.8)\n# val_set_size = len(dataset) - train_set_size\n# train_dataset, val_dataset = data.random_split(dataset, [train_set_size, val_set_size])\n# train_dataloader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE,drop_last=True)\n# val_dataloader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE,drop_last=True)","metadata":{"id":"jAqnMWW_3J8q","execution":{"iopub.status.busy":"2022-12-15T13:45:31.009771Z","iopub.execute_input":"2022-12-15T13:45:31.010583Z","iopub.status.idle":"2022-12-15T13:45:31.017744Z","shell.execute_reply.started":"2022-12-15T13:45:31.010546Z","shell.execute_reply":"2022-12-15T13:45:31.016657Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"import torch.utils.data as data\ntrain_set_size = int(len(dataset) * 0.8)\nval_set_size = len(dataset) - train_set_size\ntrain_dataset, val_dataset = data.random_split(dataset, [train_set_size, val_set_size])\ntrain_dataloader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE,drop_last=True)\n\nnew_val_set_size = int(len(val_dataset) * 0.5)\ntest_set_size = val_set_size - new_val_set_size\nval_dataset, test_dataset = data.random_split(val_dataset, [new_val_set_size, test_set_size])\nval_dataloader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE,drop_last=True)\ntest_dataloader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE,drop_last=True)","metadata":{"execution":{"iopub.status.busy":"2022-12-15T13:45:31.019121Z","iopub.execute_input":"2022-12-15T13:45:31.019547Z","iopub.status.idle":"2022-12-15T13:45:31.029985Z","shell.execute_reply.started":"2022-12-15T13:45:31.019514Z","shell.execute_reply":"2022-12-15T13:45:31.029068Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"for (input, labels) in val_dataloader:\n    ( product_features,\n        review_features,\n        product_title_bert_input_att,\n        product_title_bert_input_ids,\n        review_title_bert_input_ids,\n        review_title_bert_input_ids,\n        review_text_bert_input_att,\n        review_text_bert_input_ids,\n        scraped_block ) = unpack_dataset_items(input)\n    # this is just a test if we can get items from the dataset\n    break","metadata":{"id":"m_ep4QBkcEVC","execution":{"iopub.status.busy":"2022-12-15T13:45:31.031332Z","iopub.execute_input":"2022-12-15T13:45:31.031786Z","iopub.status.idle":"2022-12-15T13:45:32.596293Z","shell.execute_reply.started":"2022-12-15T13:45:31.031749Z","shell.execute_reply":"2022-12-15T13:45:32.595337Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"model = FakeDetectionModel().to(DEVICE)\n","metadata":{"id":"uWuURWqncEVD","execution":{"iopub.status.busy":"2022-12-15T13:45:32.597858Z","iopub.execute_input":"2022-12-15T13:45:32.598699Z","iopub.status.idle":"2022-12-15T13:45:34.252627Z","shell.execute_reply.started":"2022-12-15T13:45:32.598661Z","shell.execute_reply":"2022-12-15T13:45:34.251683Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"# TRAIN","metadata":{"id":"G2m16i2BFe-N"}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\ndef metrics(y, y_hat):\n  y_hat = np.nan_to_num(y_hat, nan = 0.0001)\n  \n  return accuracy_score(y, y_hat.round()) * 100","metadata":{"id":"9k3kIeGR0Ndm","execution":{"iopub.status.busy":"2022-12-15T13:45:34.253999Z","iopub.execute_input":"2022-12-15T13:45:34.254453Z","iopub.status.idle":"2022-12-15T13:45:34.617567Z","shell.execute_reply.started":"2022-12-15T13:45:34.254411Z","shell.execute_reply":"2022-12-15T13:45:34.616687Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_recall_curve, roc_auc_score, auc\ndef metrics(y, y_hat, typeMetric = 'PRC' ):\n    \n    precision, recall, thresholds = precision_recall_curve(y, y_hat)\n\n    if typeMetric == 'f1':\n      fscore = (2 * precision * recall) / (precision + recall)\n      ix = np.argmax(fscore)\n      return  fscore[ix]\n    elif typeMetric == 'recall':\n      ix = np.argmax(recall)\n      return recall[ix]\n    elif typeMetric == 'precision':\n      ix = np.argmax(precision)\n      return precision[ix]\n    elif typeMetric == 'AUROC':\n      return roc_auc_score(y, y_hat)\n    elif typeMetric == 'PRC':\n      return auc(recall, precision)\n    elif typeMetric == 'acc':\n      return accuracy_score(y, y_hat.round()) * 100","metadata":{"id":"3fNCwheWl9HY","execution":{"iopub.status.busy":"2022-12-15T13:45:34.619047Z","iopub.execute_input":"2022-12-15T13:45:34.619380Z","iopub.status.idle":"2022-12-15T13:45:34.627941Z","shell.execute_reply.started":"2022-12-15T13:45:34.619345Z","shell.execute_reply":"2022-12-15T13:45:34.626883Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"from transformers import AdamW\n\noptimizer = AdamW(model.parameters(), lr = 1e-3)\n#optimizer = torch.optim.Adam(model.parameters(), lr = 1e-4)\n\n","metadata":{"id":"_T3l8OY85e_E","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2ce6e046-6519-4e8f-9386-aa886884a83b","execution":{"iopub.status.busy":"2022-12-15T13:45:34.629782Z","iopub.execute_input":"2022-12-15T13:45:34.630246Z","iopub.status.idle":"2022-12-15T13:45:37.825819Z","shell.execute_reply.started":"2022-12-15T13:45:34.630212Z","shell.execute_reply":"2022-12-15T13:45:37.823831Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n","output_type":"stream"}]},{"cell_type":"code","source":"loss_f = nn.BCELoss()\n#loss_f = nn.BCEWithLogitsLoss()","metadata":{"id":"23vVUx_KJvsr","execution":{"iopub.status.busy":"2022-12-15T13:45:37.827179Z","iopub.execute_input":"2022-12-15T13:45:37.827625Z","iopub.status.idle":"2022-12-15T13:45:37.834927Z","shell.execute_reply.started":"2022-12-15T13:45:37.827587Z","shell.execute_reply":"2022-12-15T13:45:37.834002Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import tqdm_notebook\nepochs = 10\n\nprocess_factor = 1 # show every n times\n\n\npbarEpoch = tqdm_notebook(total = epochs)\npbarEpoch.set_description('Epoch: ')\n\n\nfor epoch in range(epochs):\n  y_hat = []\n  y = []\n  flag = True\n\n  loss_train = 0.0\n  acc_train  = 0.0\n\n  index = 0\n\n\n  model.train()\n  for (input, labels) in train_dataloader:\n    \n    o = model(input)\n\n   \n\n    # with torch.no_grad():\n    #   print(model.state_dict())\n    # o = torch.nan_to_num(o, 0.001)\n    # labels = torch.nan_to_num(labels, 0.001)\n    loss = loss_f(o, labels)\n\n    \n\n    loss.backward()\n    #torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n    optimizer.step()\n    optimizer.zero_grad()\n\n    \n    \n    predicted = o.cpu().detach().numpy()\n    ground_truth = labels.cpu().detach().numpy()\n    if flag:\n          y_hat = predicted\n          y = ground_truth\n          flag = False\n\n    y_hat = np.append(y_hat, predicted)\n    y = np.append(y, ground_truth)\n\n    acc_train = metrics(y, y_hat)\n    loss_train = loss.item()\n\n    if (index) % process_factor == 0:\n      \n      text = f'Training Stage ==> Epoch: {epoch} / {epochs - 1} | Step: {index} / {len(train_dataloader)} | Training loss: {loss.item():.5f} |  Training acc: {acc_train:.5f}'\n      print(text)\n\n    pbarEpoch.set_postfix({'Epoch':epoch,\n            'Training loss': loss_train, \n            'Training Acc': acc_train, \n            'Step': index,\n            'from': len(train_dataloader)\n            })\n    \n    \n    index+=1\n  \n  text = f'Training Stage ==> Epoch: {epoch} / {epochs - 1} | Training loss: {loss_train:.5f} |  Training Accuracy: {acc_train:.5f}'\n  print(text)\n\n# VALIDATE    \n\n    \n\n  index = 0\n  y_hat = []\n  y = []\n  flag = True\n\n  loss_val = 0.0\n  acc_val  = 0.\n  index = 0\n  with torch.no_grad():\n    model.eval()\n    for (input, labels) in val_dataloader:\n      o = model(input)\n      # o = torch.nan_to_num(o, 0.001)\n      loss = loss_f(o, labels)\n      \n      \n      predicted = o.cpu().detach().numpy()\n      ground_truth = labels.cpu().detach().numpy()\n      if flag:\n          y_hat = predicted\n          y = ground_truth\n          flag = False\n\n      y_hat = np.append(y_hat, predicted)\n      y = np.append(y, ground_truth)\n\n      acc_val = metrics(y, y_hat)\n      loss_val = loss.item()\n\n      pbarEpoch.set_postfix({'Epoch':epoch,\n            'Validation loss': loss_val, \n            'Validation Acc': acc_val, \n            'Step': index,\n            'from': len(val_dataloader)\n            })\n      \n      index +=1 \n\n    text = f'Validation Stage ==> Epoch: {epoch} / {epochs - 1} | Validation loss: {loss_val:.5f} |  Validation Accuracy: {acc_val:.5f}'\n    print(text)\n\n  pbarEpoch.update(1)\n  pbarEpoch.close()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":84,"referenced_widgets":["3a7fb52a5e234b669ddcc9728cb6e9e5","1b461a7071304c4195d8ee70f0a575bf","863ee13b969948f284148cf17eb536cc","018796e0ad424954af6eb45d29192478","cd7fc90e670942adb881dfe304b4d772","6e3a46a296e4431c93b8ea8ff01ad51a","fdd372c15b7d47e68919d7310ae41203","40e89d977e244ef399e726c146d864d8","5aaf4c415d9945c781b8194b01c8f757","20cf793e554e4969bec0b1a9d4740cc5","c2bb602182af495e9e6c55c4cff9eda9"]},"id":"WmQ2jaVVi-a_","outputId":"e0046e1c-5796-41a1-ee79-e3e185788a53","execution":{"iopub.status.busy":"2022-12-15T13:45:37.836847Z","iopub.execute_input":"2022-12-15T13:45:37.837341Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ec258e641d84fb2801986d2728af502"}},"metadata":{}},{"name":"stdout","text":"Training Stage ==> Epoch: 0 / 9 | Step: 0 / 56 | Training loss: 1.43231 |  Training acc: 0.55329\nTraining Stage ==> Epoch: 0 / 9 | Step: 1 / 56 | Training loss: 0.69896 |  Training acc: 0.54749\nTraining Stage ==> Epoch: 0 / 9 | Step: 2 / 56 | Training loss: 0.69315 |  Training acc: 0.53941\nTraining Stage ==> Epoch: 0 / 9 | Step: 3 / 56 | Training loss: 0.69315 |  Training acc: 0.53424\nTraining Stage ==> Epoch: 0 / 9 | Step: 4 / 56 | Training loss: 0.69315 |  Training acc: 0.53179\nTraining Stage ==> Epoch: 0 / 9 | Step: 5 / 56 | Training loss: 0.69315 |  Training acc: 0.52933\nTraining Stage ==> Epoch: 0 / 9 | Step: 6 / 56 | Training loss: 0.69315 |  Training acc: 0.52512\nTraining Stage ==> Epoch: 0 / 9 | Step: 7 / 56 | Training loss: 0.69315 |  Training acc: 0.52342\nTraining Stage ==> Epoch: 0 / 9 | Step: 8 / 56 | Training loss: 0.69315 |  Training acc: 0.52250\nTraining Stage ==> Epoch: 0 / 9 | Step: 9 / 56 | Training loss: 0.69315 |  Training acc: 0.52144\nTraining Stage ==> Epoch: 0 / 9 | Step: 10 / 56 | Training loss: 0.69315 |  Training acc: 0.52303\nTraining Stage ==> Epoch: 0 / 9 | Step: 11 / 56 | Training loss: 0.69315 |  Training acc: 0.52327\nTraining Stage ==> Epoch: 0 / 9 | Step: 12 / 56 | Training loss: 0.69315 |  Training acc: 0.52263\nTraining Stage ==> Epoch: 0 / 9 | Step: 13 / 56 | Training loss: 0.69315 |  Training acc: 0.52242\nTraining Stage ==> Epoch: 0 / 9 | Step: 14 / 56 | Training loss: 0.69315 |  Training acc: 0.52267\nTraining Stage ==> Epoch: 0 / 9 | Step: 15 / 56 | Training loss: 0.69315 |  Training acc: 0.52259\nTraining Stage ==> Epoch: 0 / 9 | Step: 16 / 56 | Training loss: 0.69315 |  Training acc: 0.52232\nTraining Stage ==> Epoch: 0 / 9 | Step: 17 / 56 | Training loss: 0.69315 |  Training acc: 0.52171\nTraining Stage ==> Epoch: 0 / 9 | Step: 18 / 56 | Training loss: 0.69315 |  Training acc: 0.52125\nTraining Stage ==> Epoch: 0 / 9 | Step: 19 / 56 | Training loss: 0.69315 |  Training acc: 0.52074\nTraining Stage ==> Epoch: 0 / 9 | Step: 20 / 56 | Training loss: 0.69315 |  Training acc: 0.52092\nTraining Stage ==> Epoch: 0 / 9 | Step: 21 / 56 | Training loss: 0.69315 |  Training acc: 0.52062\nTraining Stage ==> Epoch: 0 / 9 | Step: 22 / 56 | Training loss: 0.69315 |  Training acc: 0.51997\nTraining Stage ==> Epoch: 0 / 9 | Step: 23 / 56 | Training loss: 0.69315 |  Training acc: 0.51836\nTraining Stage ==> Epoch: 0 / 9 | Step: 24 / 56 | Training loss: 0.69315 |  Training acc: 0.51847\nTraining Stage ==> Epoch: 0 / 9 | Step: 25 / 56 | Training loss: 0.69315 |  Training acc: 0.51830\nTraining Stage ==> Epoch: 0 / 9 | Step: 26 / 56 | Training loss: 0.69315 |  Training acc: 0.51853\nTraining Stage ==> Epoch: 0 / 9 | Step: 27 / 56 | Training loss: 0.69315 |  Training acc: 0.51881\nTraining Stage ==> Epoch: 0 / 9 | Step: 28 / 56 | Training loss: 0.69315 |  Training acc: 0.51810\nTraining Stage ==> Epoch: 0 / 9 | Step: 29 / 56 | Training loss: 0.69315 |  Training acc: 0.51909\nTraining Stage ==> Epoch: 0 / 9 | Step: 30 / 56 | Training loss: 0.69315 |  Training acc: 0.51916\nTraining Stage ==> Epoch: 0 / 9 | Step: 31 / 56 | Training loss: 0.69315 |  Training acc: 0.51894\nTraining Stage ==> Epoch: 0 / 9 | Step: 32 / 56 | Training loss: 0.69315 |  Training acc: 0.51890\nTraining Stage ==> Epoch: 0 / 9 | Step: 33 / 56 | Training loss: 0.69315 |  Training acc: 0.51871\nTraining Stage ==> Epoch: 0 / 9 | Step: 34 / 56 | Training loss: 0.69315 |  Training acc: 0.51811\nTraining Stage ==> Epoch: 0 / 9 | Step: 35 / 56 | Training loss: 0.69315 |  Training acc: 0.51835\nTraining Stage ==> Epoch: 0 / 9 | Step: 36 / 56 | Training loss: 0.69315 |  Training acc: 0.51764\nTraining Stage ==> Epoch: 0 / 9 | Step: 37 / 56 | Training loss: 0.69315 |  Training acc: 0.51707\nTraining Stage ==> Epoch: 0 / 9 | Step: 38 / 56 | Training loss: 0.69315 |  Training acc: 0.51736\nTraining Stage ==> Epoch: 0 / 9 | Step: 39 / 56 | Training loss: 0.69315 |  Training acc: 0.51723\nTraining Stage ==> Epoch: 0 / 9 | Step: 40 / 56 | Training loss: 0.69315 |  Training acc: 0.51706\nTraining Stage ==> Epoch: 0 / 9 | Step: 41 / 56 | Training loss: 0.69315 |  Training acc: 0.51764\nTraining Stage ==> Epoch: 0 / 9 | Step: 42 / 56 | Training loss: 0.69315 |  Training acc: 0.51742\nTraining Stage ==> Epoch: 0 / 9 | Step: 43 / 56 | Training loss: 0.69315 |  Training acc: 0.51788\nTraining Stage ==> Epoch: 0 / 9 | Step: 44 / 56 | Training loss: 0.69315 |  Training acc: 0.51788\nTraining Stage ==> Epoch: 0 / 9 | Step: 45 / 56 | Training loss: 0.69315 |  Training acc: 0.51743\nTraining Stage ==> Epoch: 0 / 9 | Step: 46 / 56 | Training loss: 0.69315 |  Training acc: 0.51806\nTraining Stage ==> Epoch: 0 / 9 | Step: 47 / 56 | Training loss: 0.69315 |  Training acc: 0.51778\nTraining Stage ==> Epoch: 0 / 9 | Step: 48 / 56 | Training loss: 0.69315 |  Training acc: 0.51748\nTraining Stage ==> Epoch: 0 / 9 | Step: 49 / 56 | Training loss: 0.69315 |  Training acc: 0.51741\nTraining Stage ==> Epoch: 0 / 9 | Step: 50 / 56 | Training loss: 0.69315 |  Training acc: 0.51730\nTraining Stage ==> Epoch: 0 / 9 | Step: 51 / 56 | Training loss: 0.69315 |  Training acc: 0.51649\nTraining Stage ==> Epoch: 0 / 9 | Step: 52 / 56 | Training loss: 0.69315 |  Training acc: 0.51619\nTraining Stage ==> Epoch: 0 / 9 | Step: 53 / 56 | Training loss: 0.69315 |  Training acc: 0.51577\nTraining Stage ==> Epoch: 0 / 9 | Step: 54 / 56 | Training loss: 0.69315 |  Training acc: 0.51638\nTraining Stage ==> Epoch: 0 / 9 | Step: 55 / 56 | Training loss: 0.69315 |  Training acc: 0.51617\nTraining Stage ==> Epoch: 0 / 9 | Training loss: 0.69315 |  Training Accuracy: 0.51617\nValidation Stage ==> Epoch: 0 / 9 | Validation loss: 0.69315 |  Validation Accuracy: 0.74072\nTraining Stage ==> Epoch: 1 / 9 | Step: 0 / 56 | Training loss: 0.69315 |  Training acc: 0.76953\nTraining Stage ==> Epoch: 1 / 9 | Step: 1 / 56 | Training loss: 0.69315 |  Training acc: 0.76497\nTraining Stage ==> Epoch: 1 / 9 | Step: 2 / 56 | Training loss: 0.69315 |  Training acc: 0.75537\nTraining Stage ==> Epoch: 1 / 9 | Step: 3 / 56 | Training loss: 0.69315 |  Training acc: 0.75078\nTraining Stage ==> Epoch: 1 / 9 | Step: 4 / 56 | Training loss: 0.69315 |  Training acc: 0.74967\nTraining Stage ==> Epoch: 1 / 9 | Step: 5 / 56 | Training loss: 0.69315 |  Training acc: 0.74805\nTraining Stage ==> Epoch: 1 / 9 | Step: 6 / 56 | Training loss: 0.69315 |  Training acc: 0.74390\nTraining Stage ==> Epoch: 1 / 9 | Step: 7 / 56 | Training loss: 0.69315 |  Training acc: 0.74284\nTraining Stage ==> Epoch: 1 / 9 | Step: 8 / 56 | Training loss: 0.69315 |  Training acc: 0.74258\nTraining Stage ==> Epoch: 1 / 9 | Step: 9 / 56 | Training loss: 0.69315 |  Training acc: 0.74201\nTraining Stage ==> Epoch: 1 / 9 | Step: 10 / 56 | Training loss: 0.69315 |  Training acc: 0.74447\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'model_weights.pth')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"HsiVaO4pUTGt","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EVAL","metadata":{"id":"ypiuA8iDFbvE"}},{"cell_type":"code","source":"model.eval()\nall_preds = []\nall_labels = []\nfor (input, labels) in val_dataloader:\n    o = model(input)\n    #print(o)\n    all_preds.append(o.cpu().detach().numpy())\n    all_labels.append(labels.cpu().detach().numpy())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_labels = np.asarray(all_labels)\nall_preds_np = np.asarray(all_preds)\nnp.save(\"all_preds.npy\",all_preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install binclass-tools","metadata":{"id":"AG14VTLqukw1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\ndef show_conf_matrix(target, preds, set1 = \"\", model=\"\", run=None):\n    preds = np.argmax(preds, axis = 1)\n    confmat_DNN = confusion_matrix(target, preds)\n    print(\"CM - \" +set1 +  \" Set\")\n    print(\"-----------\")\n    print(confmat_DNN)\n    plt.figure(figsize=(4,4))\n    fig = sns.heatmap(confmat_DNN, annot=True,  linewidths=.5, square = True, cmap = 'Blues')\n    plt.ylabel('Actual')\n    plt.xlabel('Predicted')\n    plt.title(\"CM - \" +set1 +  \" Set\" , size = 15)\n\n    if run:\n        run[\"confusion-matrix\"] = fig","metadata":{"id":"cN0i1nehyzKD","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import bctools as bc\nimport numpy.ma as ma\no = all_preds\ntarget = all_labels[0]\n#o_np = o.cpu().detach().numpy()\npreds = np.where(np.isnan(o), ma.array(o, mask=np.isnan(o)).mean(axis=0), o)    \n#target = labels.cpu().detach().numpy()\n\n\n\nauROC_test = bc.curve_ROC_plot(true_y= target, predicted_proba = preds, title = \"AUROC - Test\" )  \nauPRC_test = bc.curve_PR_plot(true_y= target, predicted_proba = preds,  beta = 1, title = \"AUPRC - Test\" )\nshow_conf_matrix(target, preds, set1 = \"Test\", model=\"\", run=None)","metadata":{"id":"6HgTCt0Ku3mr","trusted":true},"execution_count":null,"outputs":[]}]}