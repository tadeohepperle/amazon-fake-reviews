{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The blackcellmagic extension is already loaded. To reload it, use:\n",
      "  %reload_ext blackcellmagic\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import typing\n",
    "import transformers\n",
    "from transformers import TFAutoModel, AutoTokenizer, BertTokenizer, AutoConfig, BertModel\n",
    "%load_ext blackcellmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"data/transformed/df.csv\",\n",
    "    dtype={\n",
    "        \"product_title\": str,\n",
    "        \"review_title\": str,\n",
    "        \"review_text\": str,\n",
    "        \"product_id\": str,\n",
    "    },\n",
    ")\n",
    "reviews_scraped = pd.read_csv(\n",
    "    \"data/transformed/reviews_scraped.csv\",\n",
    "    dtype={\"review_title\": str, \"review_text\": str, \"product_id\": str},\n",
    ")\n",
    "df = df[0:1000]\n",
    "\n",
    "reviews_scraped = reviews_scraped[0:2000]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_TOKENIZER_LENGTH: int = 256\n",
    "BERT_EMBEDDING_SIZE : int = 768\n",
    "DEVICE :torch.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "BERT_TOKENIZER = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "BERT_CONFIG, _ = AutoConfig.from_pretrained('bert-base-uncased', output_attention=True, return_unused_kwargs=True)\n",
    "SCRAPED_REVIEW_LIMIT = 10\n",
    "BATCH_SIZE=256"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "class BertInput(TypedDict):\n",
    "    attention_mask: torch.Tensor\n",
    "    \"\"\"shape: (1,MAX_SEQUENCE_LENGTH_BERT_TOKENIZER)\"\"\"\n",
    "    input_ids: torch.Tensor\n",
    "    \"\"\"shape: (1,MAX_SEQUENCE_LENGTH_BERT_TOKENIZER)\"\"\"\n",
    "\n",
    "\n",
    "class BertInputBatch:\n",
    "    def __init__(self, attention_mask: torch.Tensor, input_ids: torch.Tensor) -> None:\n",
    "        self.attention_mask = attention_mask\n",
    "        self.input_ids = input_ids\n",
    "\n",
    "    @staticmethod\n",
    "    def from_batch_encoding(\n",
    "        batch_encoding: transformers.tokenization_utils_base.BatchEncoding,\n",
    "    ):\n",
    "        return BertInputBatch(\n",
    "            torch.tensor(batch_encoding[\"attention_mask\"]),\n",
    "            torch.tensor(batch_encoding[\"input_ids\"]),\n",
    "        )\n",
    "\n",
    "    attention_mask: torch.Tensor\n",
    "    input_ids: torch.Tensor\n",
    "\n",
    "    @property\n",
    "    def shape(self) -> torch.Size:\n",
    "        return self.input_ids.shape\n",
    "\n",
    "    def __getitem__(self, i: int) -> BertInput:\n",
    "        return {\n",
    "            \"attention_mask\": self.attention_mask[i : i + 1, :],\n",
    "            \"input_ids\": self.input_ids[i : i + 1, :],\n",
    "        }\n",
    "\n",
    "\n",
    "# class ReviewDataSetItemInput(TypedDict):\n",
    "#     \"\"\"one fake/real review with X context reviews from the same product\"\"\"\n",
    "\n",
    "#     product_title_bert_input: BertInput\n",
    "#     review_title_bert_input: BertInput\n",
    "#     review_text_bert_input: BertInput\n",
    "\n",
    "#     review_features: torch.Tensor\n",
    "#     \"\"\"shape: (4)    Rating [1-5; 1] + Verified Purchase [0-1; 1] + SA Valence + Subjectivity [0.0-1.0; 2]\"\"\"\n",
    "\n",
    "#     product_features: torch.Tensor\n",
    "#     \"\"\"shape: (37)    Ratings (1-5) Ratio [0.0-1.0]; 5] + Rating Avg [f64; 1] + Rating Count [u64; 1] + Category [u64; 30]\"\"\"\n",
    "\n",
    "#     scraped_review_features: torch.Tensor\n",
    "#     \"\"\"shape: (X, 4)    Rating [1-5; 1] + Verified Purchase [0-1; 1] + SA Valence + Subjectivity [0.0-1.0; 2]\"\"\"\n",
    "\n",
    "#     scraped_helpful: torch.Tensor\n",
    "#     \"\"\"shape: (X, 1)    Helpfulness [u64; 1]\"\"\"\n",
    "\n",
    "#     scraped_review_texts: BertInputBatch\n",
    "\n",
    "#     scraped_review_titles: BertInputBatch\n",
    "\n",
    "PACKED_DATASET_ROW_SIZE = 37 + 4 + 6 * BERT_TOKENIZER_LENGTH + SCRAPED_REVIEW_LIMIT * (1 + 4 + 4 * BERT_TOKENIZER_LENGTH)\n",
    "\n",
    "class ReviewsDataSet(Dataset):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        df: pd.DataFrame of size M with columns:\n",
    "            - rating (1-5)\n",
    "            - verified (0-1)\n",
    "            - product_id (str)\n",
    "            - review_title (str)\n",
    "            - review_text (str)\n",
    "            - cat_0 - cat_29 (0-1)\n",
    "            - label (0-1)\n",
    "            - text_sentiment (0.0-1.0)\n",
    "            - text_subjectivity (0.0-1.0)\n",
    "            - rating_count (u64)\n",
    "            - rating_avg (1.0-5.0)\n",
    "            - rating1 - rating5  (0.0-1.0)\n",
    "            - product_title (str)\n",
    "\n",
    "        reviews_scraped:  pd.DataFrame of size N with columns:\n",
    "            - product_id (str)\n",
    "            - review_title (str)\n",
    "            - review_text (str)\n",
    "            - helpful (u64)\n",
    "            - verified (0-1)\n",
    "            - rating (1-5)\n",
    "            - text_sentiment (0.0-1.0)\n",
    "            - text_subjectivity (0.0-1.0)\n",
    "    \"\"\"\n",
    "\n",
    "    df: pd.DataFrame\n",
    "    reviews_scraped: pd.DataFrame\n",
    "\n",
    "    df_product_title_encoded: BertInputBatch\n",
    "    \"\"\"shape: (N, MAX_SEQUENCE_LENGTH_BERT_TOKENIZER)\"\"\"\n",
    "\n",
    "    df_review_title_encoded: BertInputBatch\n",
    "    \"\"\"shape: (N, MAX_SEQUENCE_LENGTH_BERT_TOKENIZER)\"\"\"\n",
    "\n",
    "    df_review_text_encoded: BertInputBatch\n",
    "    \"\"\"shape: (N, MAX_SEQUENCE_LENGTH_BERT_TOKENIZER)\"\"\"\n",
    "\n",
    "    review_feature_vector: torch.Tensor\n",
    "    \"\"\"shape: (N, 4)    Rating [1-5; 1] + Verified Purchase [0-1; 1] + SA Valence + Subjectivity [0.0-1.0; 2]\"\"\"\n",
    "\n",
    "    product_feature_vector: torch.Tensor\n",
    "    \"\"\"shape: (N, 37)    Ratings (1-5) Ratio [0.0-1.0]; 5] + Rating Avg [f64; 1] + Rating Count [u64; 1] + Category [u64; 30]\"\"\"\n",
    "\n",
    "    label_vector: torch.Tensor\n",
    "    \"\"\"shape: (N, 1) \"\"\"\n",
    "\n",
    "    scraped_review_feature_vector: torch.Tensor\n",
    "    \"\"\"shape: (M, 4)    Rating [1-5; 1] + Verified Purchase [0-1; 1] + SA Valence + Subjectivity [0.0-1.0; 2]\"\"\"\n",
    "\n",
    "    scraped_review_helpful: torch.Tensor\n",
    "    \"\"\"shape: (M, 1)    Helpfulness [u64; 1]\"\"\"\n",
    "\n",
    "    scraped_review_title_encoded: BertInputBatch\n",
    "    \"\"\"shape: (M, MAX_SEQUENCE_LENGTH_BERT_TOKENIZER)\"\"\"\n",
    "\n",
    "    scraped_review_text_encoded: BertInputBatch\n",
    "    \"\"\"shape: (M, MAX_SEQUENCE_LENGTH_BERT_TOKENIZER)\"\"\"\n",
    "\n",
    "    # product_id_indexes_map: dict[str, list[int]]\n",
    "    # \"\"\"For each product, maps the product id to the int indices for all scraped context reviews for this product\"\"\"\n",
    "\n",
    "    def __init__(self, df, reviews_scraped):\n",
    "\n",
    "        self.df = df\n",
    "        self.reviews_scraped = reviews_scraped\n",
    "        M = reviews_scraped.__len__()\n",
    "        N = df.__len__()\n",
    "\n",
    "        # use bert tokenizer to tokenize all strings of the\n",
    "        print(\n",
    "            f\"creating ReviewsDataSet (real/fake reviews: N={len(df)}, context reviews: M={len(reviews_scraped)}\"\n",
    "        )\n",
    "        print(f\"    bert tokeinzer working...\")\n",
    "\n",
    "        def bert_input_batch_tokenize(\n",
    "            list_of_strings: list[str],\n",
    "        ) -> BertInputBatch:\n",
    "            list_of_strings = [str(e) for e in list_of_strings]\n",
    "            return BertInputBatch.from_batch_encoding(\n",
    "                BERT_TOKENIZER.batch_encode_plus(\n",
    "                    list_of_strings,\n",
    "                    max_length=BERT_TOKENIZER_LENGTH,\n",
    "                    pad_to_max_length=True,\n",
    "                    truncation=True,\n",
    "                    return_token_type_ids=False,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        print(f\"    creating df_product_title_encoded...\")\n",
    "        self.df_product_title_encoded = bert_input_batch_tokenize(\n",
    "            df[\"product_title\"].tolist()\n",
    "        )\n",
    "\n",
    "        print(f\"    creating df_review_title_encoded...\")\n",
    "        self.df_review_title_encoded = bert_input_batch_tokenize(\n",
    "            df[\"review_title\"].tolist()\n",
    "        )\n",
    "\n",
    "        print(f\"    creating df_review_text_encoded...\")\n",
    "        self.df_review_text_encoded = bert_input_batch_tokenize(\n",
    "            df[\"review_text\"].tolist()\n",
    "        )\n",
    "\n",
    "        print(f\"    creating scraped_review_title_encoded...\")\n",
    "        self.scraped_review_title_encoded = bert_input_batch_tokenize(\n",
    "            reviews_scraped[\"review_title\"].tolist()\n",
    "        )\n",
    "\n",
    "        print(f\"    creating scraped_review_text_encoded...\")\n",
    "        self.scraped_review_text_encoded = bert_input_batch_tokenize(\n",
    "            reviews_scraped[\"review_text\"].tolist()\n",
    "        )\n",
    "\n",
    "        review_feature_cols = [\n",
    "            \"rating\",\n",
    "            \"verified\",\n",
    "            \"text_sentiment\",\n",
    "            \"text_subjectivity\",\n",
    "        ]\n",
    "        self.review_feature_vector = torch.tensor(df[review_feature_cols].to_numpy()).float()\n",
    "        self.label_vector = torch.tensor(df[[\"label\"]].to_numpy()).float()\n",
    "        self.scraped_review_feature_vector = torch.tensor(\n",
    "            reviews_scraped[review_feature_cols].to_numpy()\n",
    "        ).float()\n",
    "        self.scraped_review_helpful = torch.reshape(\n",
    "            torch.tensor(reviews_scraped[\"helpful\"].to_numpy()).float(), (M, 1)\n",
    "        )\n",
    "\n",
    "        product_feature_cols = [\n",
    "            \"rating_count\",\n",
    "            \"rating_avg\",\n",
    "            \"rating1\",\n",
    "            \"rating2\",\n",
    "            \"rating3\",\n",
    "            \"rating4\",\n",
    "            \"rating5\",\n",
    "        ] + [f\"cat_{i}\" for i in range(0, 30)]\n",
    "        self.product_feature_vector = torch.tensor(df[product_feature_cols].to_numpy()).float()\n",
    "\n",
    "    def __getitem__(self, index) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        product_id = self.df.loc[index, \"product_id\"]\n",
    "\n",
    "        # get indexes in scraped data where product id is the same\n",
    "        indices = torch.tensor(\n",
    "            reviews_scraped.index[\n",
    "                reviews_scraped[\"product_id\"] == product_id\n",
    "            ].to_numpy()\n",
    "        ).int()\n",
    "\n",
    "        def slice(tensor: torch.Tensor) -> torch.Tensor:\n",
    "            \"\"\"selects only the subset where index indicates product id is the same\"\"\"\n",
    "            return torch.index_select(tensor, 0, indices)\n",
    "\n",
    "        def zero_pad_ravel(tensor: torch.Tensor, X) -> torch.Tensor:\n",
    "            \"\"\"takes in a tensor of shape (N,D) appends zero elements or removes elements from the end to create an (X,D) shaped tensor and then reshapes that into a (X*D) shaped tensor\"\"\"\n",
    "            (N, D) = tensor.shape\n",
    "            return torch.reshape(\n",
    "                torch.nn.functional.pad(\n",
    "                    input=tensor[0:X, :],\n",
    "                    pad=(0, 0, 0, max(X - N, 0)),\n",
    "                    mode=\"constant\",\n",
    "                    value=0,\n",
    "                ),\n",
    "                (-1,),\n",
    "            )\n",
    "\n",
    "        # slice the tensors of relevant scraped reviews out of the total reviews:\n",
    "        scraped_helpful = slice(self.scraped_review_helpful)\n",
    "        _N = scraped_helpful.shape[0]  # is N\n",
    "        assert scraped_helpful.shape == (_N, 1)\n",
    "\n",
    "        scraped_review_features = slice(self.scraped_review_feature_vector)\n",
    "        assert scraped_review_features.shape == (_N, 4)\n",
    "\n",
    "        scraped_review_texts_att = slice(\n",
    "            self.scraped_review_text_encoded.attention_mask\n",
    "        )\n",
    "\n",
    "        assert scraped_review_texts_att.shape == (_N, BERT_TOKENIZER_LENGTH)\n",
    "\n",
    "        scraped_review_texts_ids = slice(self.scraped_review_text_encoded.input_ids)\n",
    "        assert scraped_review_texts_ids.shape == (_N, BERT_TOKENIZER_LENGTH)\n",
    "\n",
    "        scraped_review_titles_att = slice(\n",
    "            self.scraped_review_title_encoded.attention_mask\n",
    "        )\n",
    "        assert scraped_review_titles_att.shape == (_N, BERT_TOKENIZER_LENGTH)\n",
    "\n",
    "        scraped_review_titles_ids = slice(self.scraped_review_title_encoded.input_ids)\n",
    "        assert scraped_review_titles_ids.shape == (_N, BERT_TOKENIZER_LENGTH)\n",
    "\n",
    "        # combine all review data into a (X,) shaped tensor:\n",
    "        scraped_block = torch.cat(\n",
    "            (\n",
    "                scraped_helpful,\n",
    "                scraped_review_features,\n",
    "                scraped_review_texts_att,\n",
    "                scraped_review_texts_ids,\n",
    "                scraped_review_titles_att,\n",
    "                scraped_review_titles_ids,\n",
    "            ),\n",
    "            dim=1,\n",
    "        )\n",
    "        scraped_block_flat = zero_pad_ravel(scraped_block, SCRAPED_REVIEW_LIMIT)\n",
    "        assert scraped_block_flat.shape == (\n",
    "            SCRAPED_REVIEW_LIMIT * (1 + 4 + 4 * BERT_TOKENIZER_LENGTH),\n",
    "        )\n",
    "\n",
    "        product_title_bert_input_att = self.df_product_title_encoded[index][\n",
    "            \"attention_mask\"\n",
    "        ][0, :]\n",
    "        assert product_title_bert_input_att.shape == (BERT_TOKENIZER_LENGTH,)\n",
    "        product_title_bert_input_ids = self.df_product_title_encoded[index][\n",
    "            \"input_ids\"\n",
    "        ][0, :]\n",
    "        assert product_title_bert_input_ids.shape == (BERT_TOKENIZER_LENGTH,)\n",
    "        review_title_bert_input_att = self.df_review_title_encoded[index][\n",
    "            \"attention_mask\"\n",
    "        ][0, :]\n",
    "        assert review_title_bert_input_att.shape == (BERT_TOKENIZER_LENGTH,)\n",
    "        review_title_bert_input_ids = self.df_review_title_encoded[index][\"input_ids\"][\n",
    "            0, :\n",
    "        ]\n",
    "        assert review_title_bert_input_ids.shape == (BERT_TOKENIZER_LENGTH,)\n",
    "        review_text_bert_input_att = self.df_review_text_encoded[index][\n",
    "            \"attention_mask\"\n",
    "        ][0, :]\n",
    "        assert review_text_bert_input_att.shape == (BERT_TOKENIZER_LENGTH,)\n",
    "        review_text_bert_input_ids = self.df_review_text_encoded[index][\"input_ids\"][\n",
    "            0, :\n",
    "        ]\n",
    "        assert review_text_bert_input_ids.shape == (BERT_TOKENIZER_LENGTH,)\n",
    "\n",
    "        product_features = self.product_feature_vector[index]  # shape: (37)\n",
    "        assert product_features.shape == (37,)\n",
    "\n",
    "        review_features = self.review_feature_vector[index]  # shape: (4)\n",
    "        assert review_features.shape == (4,)\n",
    "\n",
    "        catted = torch.cat(\n",
    "            (\n",
    "                product_features,\n",
    "                review_features,\n",
    "                product_title_bert_input_att,\n",
    "                product_title_bert_input_ids,\n",
    "                review_title_bert_input_att,\n",
    "                review_title_bert_input_ids,\n",
    "                review_text_bert_input_att,\n",
    "                review_text_bert_input_ids,\n",
    "                scraped_block_flat,\n",
    "            ),\n",
    "            dim=0,\n",
    "        )\n",
    "        assert catted.shape == (PACKED_DATASET_ROW_SIZE,)\n",
    "        ##############################################################\n",
    "        ## Data layout in the catted tensor row, assuming BERT_TOKENIZER_LENGTH = 256 and SCRAPED_REVIEW_LIMIT = 10\n",
    "        ## | 37 | 4 | 256+256 | 256+256 | 256+256 | 10 * ( | 1 | 4 | 256+256 | 256+256 |)\n",
    "\n",
    "        label = self.label_vector[index]\n",
    "        return (catted, label)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.df.__len__()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### unpacking functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_dataset_items(packed_batch_tensor: torch.Tensor):\n",
    "    \"\"\"\n",
    "    expects packed_batch_tensor to be of shape\n",
    "    \"\"\"\n",
    "    assert packed_batch_tensor.shape[1] == PACKED_DATASET_ROW_SIZE\n",
    "    (B, T) = packed_batch_tensor.shape\n",
    "\n",
    "    c: int = 0\n",
    "\n",
    "    def next(n: int) -> torch.Tensor:\n",
    "        nonlocal c\n",
    "        slice = packed_batch_tensor[:, c : c + n]\n",
    "        c += n\n",
    "        return slice\n",
    "\n",
    "    product_features = next(37)\n",
    "    assert product_features.shape == (B, 37)\n",
    "\n",
    "    review_features = next(4)\n",
    "    assert review_features.shape == (B, 4)\n",
    "\n",
    "    product_title_bert_input_att = next(BERT_TOKENIZER_LENGTH)\n",
    "    product_title_bert_input_ids = next(BERT_TOKENIZER_LENGTH)\n",
    "    review_title_bert_input_att = next(BERT_TOKENIZER_LENGTH)\n",
    "    review_title_bert_input_ids = next(BERT_TOKENIZER_LENGTH)\n",
    "    review_text_bert_input_att = next(BERT_TOKENIZER_LENGTH)\n",
    "    review_text_bert_input_ids = next(BERT_TOKENIZER_LENGTH)\n",
    "    assert (\n",
    "        product_title_bert_input_att.shape\n",
    "        == product_title_bert_input_ids.shape\n",
    "        == review_title_bert_input_att.shape\n",
    "        == review_title_bert_input_ids.shape\n",
    "        == review_text_bert_input_att.shape\n",
    "        == review_text_bert_input_ids.shape\n",
    "        == (B, BERT_TOKENIZER_LENGTH)\n",
    "    )\n",
    "\n",
    "    _scraped_block_flat = next(\n",
    "        SCRAPED_REVIEW_LIMIT * (1 + 4 + 4 * BERT_TOKENIZER_LENGTH)\n",
    "    )\n",
    "    assert _scraped_block_flat.shape == (\n",
    "        B,\n",
    "        SCRAPED_REVIEW_LIMIT * (1 + 4 + 4 * BERT_TOKENIZER_LENGTH),\n",
    "    )\n",
    "\n",
    "    scraped_block = torch.reshape(\n",
    "        _scraped_block_flat,\n",
    "        (B, SCRAPED_REVIEW_LIMIT, (1 + 4 + 4 * BERT_TOKENIZER_LENGTH)),\n",
    "    )\n",
    "    assert scraped_block.shape == (\n",
    "        B,\n",
    "        SCRAPED_REVIEW_LIMIT,\n",
    "        (1 + 4 + 4 * BERT_TOKENIZER_LENGTH),\n",
    "    )\n",
    "\n",
    "    scraped_helpful = scraped_block[:, :, 0:1]\n",
    "    assert scraped_helpful.shape == (B, SCRAPED_REVIEW_LIMIT, 1)\n",
    "\n",
    "    scraped_review_features = scraped_block[:, :, 1:5]\n",
    "    assert scraped_review_features.shape == (B, SCRAPED_REVIEW_LIMIT, 4)\n",
    "\n",
    "    scraped_review_title_bert_input_att = scraped_block[\n",
    "        :, :, 5 : 5 + BERT_TOKENIZER_LENGTH\n",
    "    ]\n",
    "    scraped_review_title_bert_input_ids = scraped_block[\n",
    "        :, :, 5 + BERT_TOKENIZER_LENGTH : 5 + 2 * BERT_TOKENIZER_LENGTH\n",
    "    ]\n",
    "    scraped_review_text_bert_input_att = scraped_block[\n",
    "        :, :, 5 + 2 * BERT_TOKENIZER_LENGTH : 5 + 3 * BERT_TOKENIZER_LENGTH\n",
    "    ]\n",
    "    scraped_review_text_bert_input_ids = scraped_block[\n",
    "        :, :, 5 + 3 * BERT_TOKENIZER_LENGTH : 5 + 4 * BERT_TOKENIZER_LENGTH\n",
    "    ]\n",
    "\n",
    "    return (\n",
    "        product_features,\n",
    "        review_features,\n",
    "        product_title_bert_input_att,\n",
    "        product_title_bert_input_ids,\n",
    "        review_title_bert_input_att,\n",
    "        review_title_bert_input_ids,\n",
    "        review_text_bert_input_att,\n",
    "        review_text_bert_input_ids,\n",
    "        (\n",
    "            scraped_helpful,\n",
    "            scraped_review_features,\n",
    "            scraped_review_title_bert_input_att,\n",
    "            scraped_review_title_bert_input_ids,\n",
    "            scraped_review_text_bert_input_att,\n",
    "            scraped_review_text_bert_input_ids,\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import torch.nn as nn\n",
    "def create_mlp(layer_sizes: list[int]) -> nn.Sequential:\n",
    "    \"\"\"\n",
    "    creates an MLP with the given layer_sizes. The first element is the input size, the last one the output size\n",
    "    args:\n",
    "        layer_sizes: [input_dim, h1_dim, h2_dim, ...., out_dim]\"\"\"\n",
    "    assert layer_sizes.__len__() >= 2\n",
    "        \n",
    "    layers = []\n",
    "    for i in range(1, layer_sizes.__len__()):\n",
    "        layers.append((f\"hidden_layer_{i}\",nn.Linear(layer_sizes[i-1], layer_sizes[i]) ))\n",
    "        layers.append((f\"activation_{i}\",  nn.ReLU()))\n",
    "    return nn.Sequential(OrderedDict(layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewEncodingModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, freeze: bool = True, outdim=500) -> None:\n",
    "        super(ReviewEncodingModel, self).__init__()\n",
    "        self.bert = BertModel(BERT_CONFIG)\n",
    "        if freeze:\n",
    "            for param in self.bert.parameters():\n",
    "                param.requires_grad = False\n",
    "        self.out_mlp = create_mlp([BERT_EMBEDDING_SIZE*2+4, outdim])\n",
    "    \n",
    "    def forward(self, review_features: torch.Tensor, \n",
    "               review_title_bert_input_att: torch.Tensor,\n",
    "               review_title_bert_input_ids: torch.Tensor,\n",
    "               review_text_bert_input_att: torch.Tensor,\n",
    "               review_text_bert_input_ids: torch.Tensor, ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        args:\n",
    "            review_features: shape: (BATCH_SIZE, 5)\n",
    "            review_title_bert_input_att: shape: (BATCH_SIZE, BERT_TOKENIZER_LENGTH)\n",
    "            review_title_bert_input_ids: shape: (BATCH_SIZE, BERT_TOKENIZER_LENGTH)\n",
    "            review_text_bert_input_att: shape: (BATCH_SIZE, BERT_TOKENIZER_LENGTH)\n",
    "            review_text_bert_input_ids: shape: (BATCH_SIZE, BERT_TOKENIZER_LENGTH)\n",
    "        returns:\n",
    "            torch.Tensor of shape (BATCH_SIZE, OUTDIM)\n",
    "        \"\"\"\n",
    "\n",
    "        # max over all tokens in every dimension of the 768 dimensional embedding\n",
    "      \n",
    "        bert_title_embedding = self.bert(attention_mask=review_title_bert_input_att.int(), input_ids=review_title_bert_input_ids.int()).last_hidden_state[:,0,:]\n",
    "        assert bert_title_embedding.shape == (BATCH_SIZE, BERT_EMBEDDING_SIZE)\n",
    "\n",
    "        # max over all tokens in every dimension of the 768 dimensional embedding\n",
    "        bert_text_embedding = self.bert(attention_mask=review_text_bert_input_att.int(), input_ids=review_text_bert_input_ids.int()).last_hidden_state[:,0,:]\n",
    "        assert bert_title_embedding.shape == (BATCH_SIZE, BERT_EMBEDDING_SIZE)\n",
    "\n",
    "        # concat all on top of each other:\n",
    "        catted = torch.cat([bert_title_embedding, bert_text_embedding, review_features], dim=1)\n",
    "\n",
    "        # apply linear layer and relu:\n",
    "        return self.out_mlp(catted)\n",
    "\n",
    "        \n",
    "    def freeze_bert(self, freezed: bool) -> None:\n",
    "        for param in self.bert.parameters():\n",
    "                param.requires_grad =  not freezed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "REVIEW_ENCODING_MODEL_OUTDIM = 149\n",
    "# REVIEW_ENCODING_MODEL_OUTDIM + 1 has to be divisible by 3 for this to work, bc. we use 3 attention heads\n",
    "\n",
    "class FakeDetectionModel(torch.nn.Module):\n",
    "    review_encoding_model: ReviewEncodingModel\n",
    "    scraped_reviews_transformer: torch.nn.TransformerEncoderLayer\n",
    "    outmlp: nn.Sequential\n",
    "\n",
    "    def __init__(self):\n",
    "        super(FakeDetectionModel, self).__init__()\n",
    "        self.review_encoding_model: ReviewEncodingModel = ReviewEncodingModel(\n",
    "            freeze=True, outdim=REVIEW_ENCODING_MODEL_OUTDIM\n",
    "        )\n",
    "        self.scraped_reviews_transformer = torch.nn.TransformerEncoderLayer(\n",
    "            d_model=REVIEW_ENCODING_MODEL_OUTDIM+1, nhead=3, batch_first=True\n",
    "        )\n",
    "\n",
    "        LAST_FEATURES_DIM = 37 + (REVIEW_ENCODING_MODEL_OUTDIM + 1) + REVIEW_ENCODING_MODEL_OUTDIM +  BERT_EMBEDDING_SIZE\n",
    "        # LAST_FEATURES_DIM: product features + transformer output dimension + review encoded + bert embedding from product title\n",
    "        self.outmlp = create_mlp([LAST_FEATURES_DIM, 30, 20, 1])\n",
    "\n",
    "    def forward(self, packed_dataset_rows: torch.Tensor)-> torch.Tensor :\n",
    "        \"\"\" \"\n",
    "        args:\n",
    "            packed_dataset_row: torch.Tensor with shape (BATCH_SIZE, PACKED_DATASET_ROW_SIZE)\n",
    "        returns:\n",
    "            torch.Tensor with shape: (BATCH_SIZE,1)\n",
    "        \"\"\"\n",
    "        assert packed_dataset_rows.shape == (BATCH_SIZE, PACKED_DATASET_ROW_SIZE)\n",
    "        (\n",
    "            product_features,\n",
    "            review_features,\n",
    "            product_title_bert_input_att,\n",
    "            product_title_bert_input_ids,\n",
    "            review_title_bert_input_att,\n",
    "            review_title_bert_input_ids,\n",
    "            review_text_bert_input_att,\n",
    "            review_text_bert_input_ids,\n",
    "            (\n",
    "                scraped_helpful,\n",
    "                scraped_review_features,\n",
    "                scraped_review_title_bert_input_att,\n",
    "                scraped_review_title_bert_input_ids,\n",
    "                scraped_review_text_bert_input_att,\n",
    "                scraped_review_text_bert_input_ids,\n",
    "            ),\n",
    "        ) = unpack_dataset_items(packed_dataset_rows)\n",
    "\n",
    "        ### CREATE REVIEW ENCODING\n",
    "        review_encoding = self.review_encoding_model(review_features, review_title_bert_input_att, review_title_bert_input_ids, review_text_bert_input_att, review_text_bert_input_ids)  # type: ignore\n",
    "        assert review_encoding.shape == (BATCH_SIZE, REVIEW_ENCODING_MODEL_OUTDIM)\n",
    "\n",
    "        ### CREATE REVIEW ENCODINGS FOR ALL SCRAPED REVIEWS\n",
    "        ### THEN COMBINE THEM AND THEIR HELPFULNESS VIA THE TRANSFORMER\n",
    "\n",
    "        # transform (BATCH_SIZE, SCRAPED_REVIEW_LIMIT, 5 + 4 * BERT_TOKENIZER_LENGTH) into (BATCH_SIZE, SCRAPED_REVIEW_LIMIT, REVIEW_ENCODING_MODEL_OUTDIM)\n",
    "        transformer_input = torch.zeros(\n",
    "            (BATCH_SIZE, SCRAPED_REVIEW_LIMIT, 1 + REVIEW_ENCODING_MODEL_OUTDIM)\n",
    "        )\n",
    "        for i in range(SCRAPED_REVIEW_LIMIT):\n",
    "            transformer_input[:, i, :] = torch.cat(\n",
    "            [self.review_encoding_model(\n",
    "                scraped_review_features[:, i, :],\n",
    "                scraped_review_title_bert_input_att[:, i, :],\n",
    "                scraped_review_title_bert_input_ids[:, i, :],\n",
    "                scraped_review_text_bert_input_att[:, i, :],\n",
    "                scraped_review_text_bert_input_ids[:, i, :],\n",
    "            ), scraped_helpful[:,i,:]], dim=1 ) # type: ignore\n",
    "        # REVIEW_ENCODING_MODEL_OUTDIM + 1 has to be divisible by 3 for this to work, bc. we use 3 attention heads\n",
    "\n",
    "        transformer_output = self.scraped_reviews_transformer(transformer_input)[:,-1,:] # type: ignore\n",
    "        assert transformer_output.shape == (BATCH_SIZE, 1+ REVIEW_ENCODING_MODEL_OUTDIM)\n",
    "\n",
    "        ### CREATE BERT EMBEDDING FOR PRODUCT TITLE\n",
    "        bert_product_title_embedding = self.review_encoding_model.bert(attention_mask=product_title_bert_input_att.int(), input_ids=product_title_bert_input_ids.int()).last_hidden_state[:,0,:] # type: ignore\n",
    "        assert bert_product_title_embedding.shape == (BATCH_SIZE, BERT_EMBEDDING_SIZE)\n",
    "        # linear layer connection all\n",
    "\n",
    "        ### COMBINE PRODUCT INFORMATION (features + title), CONTEXT (other review's encodings and their helpfulness) and REVIEW ENCODING into a single scalar: the real vs. fake prediction\n",
    "        catted = torch.cat([product_features, bert_product_title_embedding, review_encoding, transformer_output],dim=1)\n",
    "        return torch.sigmoid(self.outmlp(catted)) # type: ignore"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating ReviewsDataSet (real/fake reviews: N=1000, context reviews: M=2000\n",
      "    bert tokeinzer working...\n",
      "    creating df_product_title_encoded...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tadeo\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2336: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    creating df_review_title_encoded...\n",
      "    creating df_review_text_encoded...\n",
      "    creating scraped_review_title_encoded...\n",
      "    creating scraped_review_text_encoded...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = ReviewsDataSet(df, reviews_scraped)\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (input, labels) in dataloader:\n",
    "    ( product_features,\n",
    "        review_features,\n",
    "        product_title_bert_input_att,\n",
    "        product_title_bert_input_ids,\n",
    "        review_title_bert_input_ids,\n",
    "        review_title_bert_input_ids,\n",
    "        review_text_bert_input_att,\n",
    "        review_text_bert_input_ids,\n",
    "        scraped_block ) = unpack_dataset_items(input)\n",
    "    # this is just a test if we can get items from the dataset\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FakeDetectionModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bg model\n",
      "tensor([[  101.,  6179.,   102.,  ...,     0.,     0.,     0.],\n",
      "        [  101.,  2047.,  3690.,  ...,     0.,     0.,     0.],\n",
      "        [  101.,  7929.,   102.,  ...,     0.,     0.,     0.],\n",
      "        ...,\n",
      "        [  101., 28305.,  2102.,  ...,     0.,     0.,     0.],\n",
      "        [  101.,  3835.,  3609.,  ...,     0.,     0.,     0.],\n",
      "        [  101.,  2009.,  1005.,  ...,     0.,     0.,     0.]])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\code\\financial_technology\\amazon-fake-reviews\\model2.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/financial_technology/amazon-fake-reviews/model2.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/financial_technology/amazon-fake-reviews/model2.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m (\u001b[39minput\u001b[39m, labels) \u001b[39min\u001b[39;00m dataloader:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/code/financial_technology/amazon-fake-reviews/model2.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     o \u001b[39m=\u001b[39m model(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/financial_technology/amazon-fake-reviews/model2.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mprint\u001b[39m(o)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/financial_technology/amazon-fake-reviews/model2.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tadeo\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32md:\\code\\financial_technology\\amazon-fake-reviews\\model2.ipynb Cell 18\u001b[0m in \u001b[0;36mFakeDetectionModel.forward\u001b[1;34m(self, packed_dataset_rows)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/financial_technology/amazon-fake-reviews/model2.ipynb#X23sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m transformer_input \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/financial_technology/amazon-fake-reviews/model2.ipynb#X23sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m     (BATCH_SIZE, SCRAPED_REVIEW_LIMIT, \u001b[39m1\u001b[39m \u001b[39m+\u001b[39m REVIEW_ENCODING_MODEL_OUTDIM)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/financial_technology/amazon-fake-reviews/model2.ipynb#X23sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/financial_technology/amazon-fake-reviews/model2.ipynb#X23sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(SCRAPED_REVIEW_LIMIT):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/financial_technology/amazon-fake-reviews/model2.ipynb#X23sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m     transformer_input[:, i, :] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/code/financial_technology/amazon-fake-reviews/model2.ipynb#X23sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m     [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreview_encoding_model(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/financial_technology/amazon-fake-reviews/model2.ipynb#X23sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m         scraped_review_features[:, i, :],\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/financial_technology/amazon-fake-reviews/model2.ipynb#X23sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m         scraped_review_title_bert_input_att[:, i, :],\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/financial_technology/amazon-fake-reviews/model2.ipynb#X23sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m         scraped_review_title_bert_input_ids[:, i, :],\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/financial_technology/amazon-fake-reviews/model2.ipynb#X23sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m         scraped_review_text_bert_input_att[:, i, :],\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/financial_technology/amazon-fake-reviews/model2.ipynb#X23sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m         scraped_review_text_bert_input_ids[:, i, :],\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/financial_technology/amazon-fake-reviews/model2.ipynb#X23sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m     ), scraped_helpful[:,i,:]], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m ) \u001b[39m# type: ignore\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/financial_technology/amazon-fake-reviews/model2.ipynb#X23sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m \u001b[39m# REVIEW_ENCODING_MODEL_OUTDIM + 1 has to be divisible by 3 for this to work, bc. we use 3 attention heads\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/financial_technology/amazon-fake-reviews/model2.ipynb#X23sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m transformer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscraped_reviews_transformer(transformer_input)[:,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,:] \u001b[39m# type: ignore\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tadeo\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32md:\\code\\financial_technology\\amazon-fake-reviews\\model2.ipynb Cell 18\u001b[0m in \u001b[0;36mReviewEncodingModel.forward\u001b[1;34m(self, review_features, review_title_bert_input_att, review_title_bert_input_ids, review_text_bert_input_att, review_text_bert_input_ids)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/financial_technology/amazon-fake-reviews/model2.ipynb#X23sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39massert\u001b[39;00m bert_title_embedding\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m (BATCH_SIZE, BERT_EMBEDDING_SIZE)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/financial_technology/amazon-fake-reviews/model2.ipynb#X23sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# max over all tokens in every dimension of the 768 dimensional embedding\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/code/financial_technology/amazon-fake-reviews/model2.ipynb#X23sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m bert_text_embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbert(attention_mask\u001b[39m=\u001b[39;49mreview_text_bert_input_att\u001b[39m.\u001b[39;49mint(), input_ids\u001b[39m=\u001b[39;49mreview_text_bert_input_ids\u001b[39m.\u001b[39;49mint())\u001b[39m.\u001b[39mlast_hidden_state[:,\u001b[39m0\u001b[39m,:]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/financial_technology/amazon-fake-reviews/model2.ipynb#X23sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39massert\u001b[39;00m bert_title_embedding\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m (BATCH_SIZE, BERT_EMBEDDING_SIZE)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/financial_technology/amazon-fake-reviews/model2.ipynb#X23sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m# concat all on top of each other:\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tadeo\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\tadeo\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1021\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1012\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m   1014\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[0;32m   1015\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[0;32m   1016\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1019\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[0;32m   1020\u001b[0m )\n\u001b[1;32m-> 1021\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[0;32m   1022\u001b[0m     embedding_output,\n\u001b[0;32m   1023\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[0;32m   1024\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m   1025\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m   1026\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[0;32m   1027\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[0;32m   1028\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m   1029\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1030\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1031\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1032\u001b[0m )\n\u001b[0;32m   1033\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1034\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tadeo\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\tadeo\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:610\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    601\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[0;32m    602\u001b[0m         create_custom_forward(layer_module),\n\u001b[0;32m    603\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    607\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    608\u001b[0m     )\n\u001b[0;32m    609\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 610\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[0;32m    611\u001b[0m         hidden_states,\n\u001b[0;32m    612\u001b[0m         attention_mask,\n\u001b[0;32m    613\u001b[0m         layer_head_mask,\n\u001b[0;32m    614\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    615\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    616\u001b[0m         past_key_value,\n\u001b[0;32m    617\u001b[0m         output_attentions,\n\u001b[0;32m    618\u001b[0m     )\n\u001b[0;32m    620\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    621\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\tadeo\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\tadeo\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:538\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    535\u001b[0m     cross_attn_present_key_value \u001b[39m=\u001b[39m cross_attention_outputs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m    536\u001b[0m     present_key_value \u001b[39m=\u001b[39m present_key_value \u001b[39m+\u001b[39m cross_attn_present_key_value\n\u001b[1;32m--> 538\u001b[0m layer_output \u001b[39m=\u001b[39m apply_chunking_to_forward(\n\u001b[0;32m    539\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeed_forward_chunk, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchunk_size_feed_forward, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseq_len_dim, attention_output\n\u001b[0;32m    540\u001b[0m )\n\u001b[0;32m    541\u001b[0m outputs \u001b[39m=\u001b[39m (layer_output,) \u001b[39m+\u001b[39m outputs\n\u001b[0;32m    543\u001b[0m \u001b[39m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tadeo\\anaconda3\\lib\\site-packages\\transformers\\pytorch_utils.py:246\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[39m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m    244\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat(output_chunks, dim\u001b[39m=\u001b[39mchunk_dim)\n\u001b[1;32m--> 246\u001b[0m \u001b[39mreturn\u001b[39;00m forward_fn(\u001b[39m*\u001b[39;49minput_tensors)\n",
      "File \u001b[1;32mc:\\Users\\tadeo\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:551\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    549\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfeed_forward_chunk\u001b[39m(\u001b[39mself\u001b[39m, attention_output):\n\u001b[0;32m    550\u001b[0m     intermediate_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate(attention_output)\n\u001b[1;32m--> 551\u001b[0m     layer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput(intermediate_output, attention_output)\n\u001b[0;32m    552\u001b[0m     \u001b[39mreturn\u001b[39;00m layer_output\n",
      "File \u001b[1;32mc:\\Users\\tadeo\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\tadeo\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:463\u001b[0m, in \u001b[0;36mBertOutput.forward\u001b[1;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states: torch\u001b[39m.\u001b[39mTensor, input_tensor: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m--> 463\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdense(hidden_states)\n\u001b[0;32m    464\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(hidden_states)\n\u001b[0;32m    465\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLayerNorm(hidden_states \u001b[39m+\u001b[39m input_tensor)\n",
      "File \u001b[1;32mc:\\Users\\tadeo\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\tadeo\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for (input, labels) in dataloader:\n",
    "    o = model(input)\n",
    "    print(o)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "780e02f01b3ae00d5e97f14df45fcdece40e9a09f09f224add9952588133a4cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
