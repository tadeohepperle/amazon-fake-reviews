{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The blackcellmagic extension is already loaded. To reload it, use:\n",
      "  %reload_ext blackcellmagic\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import typing\n",
    "import transformers\n",
    "from transformers import TFAutoModel, AutoTokenizer, BertTokenizer, AutoConfig, BertModel\n",
    "%load_ext blackcellmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"data/transformed/df.csv\",\n",
    "    dtype={\n",
    "        \"product_title\": str,\n",
    "        \"review_title\": str,\n",
    "        \"review_text\": str,\n",
    "        \"product_id\": str,\n",
    "    },\n",
    ")\n",
    "reviews_scraped = pd.read_csv(\n",
    "    \"data/transformed/reviews_scraped.csv\",\n",
    "    dtype={\"review_title\": str, \"review_text\": str, \"product_id\": str},\n",
    ")\n",
    "df = df[0:100]\n",
    "\n",
    "reviews_scraped = reviews_scraped[0:200]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_TOKENIZER_LENGTH: int = 256\n",
    "BERT_EMBEDDING_SIZE : int = 768\n",
    "DEVICE :torch.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "BERT_TOKENIZER = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "BERT_CONFIG, _ = AutoConfig.from_pretrained('bert-base-uncased', output_attention=True, return_unused_kwargs=True)\n",
    "SCRAPED_REVIEW_LIMIT = 10\n",
    "BATCH_SIZE=8"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "class BertInput(TypedDict):\n",
    "    attention_mask: torch.Tensor\n",
    "    \"\"\"shape: (1,MAX_SEQUENCE_LENGTH_BERT_TOKENIZER)\"\"\"\n",
    "    input_ids: torch.Tensor\n",
    "    \"\"\"shape: (1,MAX_SEQUENCE_LENGTH_BERT_TOKENIZER)\"\"\"\n",
    "\n",
    "\n",
    "class BertInputBatch:\n",
    "    def __init__(self, attention_mask: torch.Tensor, input_ids: torch.Tensor) -> None:\n",
    "        self.attention_mask = attention_mask\n",
    "        self.input_ids = input_ids\n",
    "\n",
    "    @staticmethod\n",
    "    def from_batch_encoding(\n",
    "        batch_encoding: transformers.tokenization_utils_base.BatchEncoding,\n",
    "    ):\n",
    "        return BertInputBatch(\n",
    "            torch.tensor(batch_encoding[\"attention_mask\"]),\n",
    "            torch.tensor(batch_encoding[\"input_ids\"]),\n",
    "        )\n",
    "\n",
    "    attention_mask: torch.Tensor\n",
    "    input_ids: torch.Tensor\n",
    "\n",
    "    @property\n",
    "    def shape(self) -> torch.Size:\n",
    "        return self.input_ids.shape\n",
    "\n",
    "    def __getitem__(self, i: int) -> BertInput:\n",
    "        return {\n",
    "            \"attention_mask\": self.attention_mask[i : i + 1, :],\n",
    "            \"input_ids\": self.input_ids[i : i + 1, :],\n",
    "        }\n",
    "\n",
    "\n",
    "# class ReviewDataSetItemInput(TypedDict):\n",
    "#     \"\"\"one fake/real review with X context reviews from the same product\"\"\"\n",
    "\n",
    "#     product_title_bert_input: BertInput\n",
    "#     review_title_bert_input: BertInput\n",
    "#     review_text_bert_input: BertInput\n",
    "\n",
    "#     review_features: torch.Tensor\n",
    "#     \"\"\"shape: (4)    Rating [1-5; 1] + Verified Purchase [0-1; 1] + SA Valence + Subjectivity [0.0-1.0; 2]\"\"\"\n",
    "\n",
    "#     product_features: torch.Tensor\n",
    "#     \"\"\"shape: (37)    Ratings (1-5) Ratio [0.0-1.0]; 5] + Rating Avg [f64; 1] + Rating Count [u64; 1] + Category [u64; 30]\"\"\"\n",
    "\n",
    "#     scraped_review_features: torch.Tensor\n",
    "#     \"\"\"shape: (X, 4)    Rating [1-5; 1] + Verified Purchase [0-1; 1] + SA Valence + Subjectivity [0.0-1.0; 2]\"\"\"\n",
    "\n",
    "#     scraped_helpful: torch.Tensor\n",
    "#     \"\"\"shape: (X, 1)    Helpfulness [u64; 1]\"\"\"\n",
    "\n",
    "#     scraped_review_texts: BertInputBatch\n",
    "\n",
    "#     scraped_review_titles: BertInputBatch\n",
    "\n",
    "PACKED_DATASET_ROW_SIZE = 37 + 4 + 6 * BERT_TOKENIZER_LENGTH + SCRAPED_REVIEW_LIMIT * (1 + 4 + 4 * BERT_TOKENIZER_LENGTH)\n",
    "\n",
    "class ReviewsDataSet(Dataset):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        df: pd.DataFrame of size M with columns:\n",
    "            - rating (1-5)\n",
    "            - verified (0-1)\n",
    "            - product_id (str)\n",
    "            - review_title (str)\n",
    "            - review_text (str)\n",
    "            - cat_0 - cat_29 (0-1)\n",
    "            - label (0-1)\n",
    "            - text_sentiment (0.0-1.0)\n",
    "            - text_subjectivity (0.0-1.0)\n",
    "            - rating_count (u64)\n",
    "            - rating_avg (1.0-5.0)\n",
    "            - rating1 - rating5  (0.0-1.0)\n",
    "            - product_title (str)\n",
    "\n",
    "        reviews_scraped:  pd.DataFrame of size N with columns:\n",
    "            - product_id (str)\n",
    "            - review_title (str)\n",
    "            - review_text (str)\n",
    "            - helpful (u64)\n",
    "            - verified (0-1)\n",
    "            - rating (1-5)\n",
    "            - text_sentiment (0.0-1.0)\n",
    "            - text_subjectivity (0.0-1.0)\n",
    "    \"\"\"\n",
    "\n",
    "    df: pd.DataFrame\n",
    "    reviews_scraped: pd.DataFrame\n",
    "\n",
    "    df_product_title_encoded: BertInputBatch\n",
    "    \"\"\"shape: (N, MAX_SEQUENCE_LENGTH_BERT_TOKENIZER)\"\"\"\n",
    "\n",
    "    df_review_title_encoded: BertInputBatch\n",
    "    \"\"\"shape: (N, MAX_SEQUENCE_LENGTH_BERT_TOKENIZER)\"\"\"\n",
    "\n",
    "    df_review_text_encoded: BertInputBatch\n",
    "    \"\"\"shape: (N, MAX_SEQUENCE_LENGTH_BERT_TOKENIZER)\"\"\"\n",
    "\n",
    "    review_feature_vector: torch.Tensor\n",
    "    \"\"\"shape: (N, 4)    Rating [1-5; 1] + Verified Purchase [0-1; 1] + SA Valence + Subjectivity [0.0-1.0; 2]\"\"\"\n",
    "\n",
    "    product_feature_vector: torch.Tensor\n",
    "    \"\"\"shape: (N, 37)    Ratings (1-5) Ratio [0.0-1.0]; 5] + Rating Avg [f64; 1] + Rating Count [u64; 1] + Category [u64; 30]\"\"\"\n",
    "\n",
    "    label_vector: torch.Tensor\n",
    "    \"\"\"shape: (N, 1) \"\"\"\n",
    "\n",
    "    scraped_review_feature_vector: torch.Tensor\n",
    "    \"\"\"shape: (M, 4)    Rating [1-5; 1] + Verified Purchase [0-1; 1] + SA Valence + Subjectivity [0.0-1.0; 2]\"\"\"\n",
    "\n",
    "    scraped_review_helpful: torch.Tensor\n",
    "    \"\"\"shape: (M, 1)    Helpfulness [u64; 1]\"\"\"\n",
    "\n",
    "    scraped_review_title_encoded: BertInputBatch\n",
    "    \"\"\"shape: (M, MAX_SEQUENCE_LENGTH_BERT_TOKENIZER)\"\"\"\n",
    "\n",
    "    scraped_review_text_encoded: BertInputBatch\n",
    "    \"\"\"shape: (M, MAX_SEQUENCE_LENGTH_BERT_TOKENIZER)\"\"\"\n",
    "\n",
    "    # product_id_indexes_map: dict[str, list[int]]\n",
    "    # \"\"\"For each product, maps the product id to the int indices for all scraped context reviews for this product\"\"\"\n",
    "\n",
    "    def __init__(self, df, reviews_scraped):\n",
    "\n",
    "        self.df = df\n",
    "        self.reviews_scraped = reviews_scraped\n",
    "        M = reviews_scraped.__len__()\n",
    "        N = df.__len__()\n",
    "\n",
    "        # use bert tokenizer to tokenize all strings of the\n",
    "        print(\n",
    "            f\"creating ReviewsDataSet (real/fake reviews: N={len(df)}, context reviews: M={len(reviews_scraped)}\"\n",
    "        )\n",
    "        print(f\"    bert tokeinzer working...\")\n",
    "\n",
    "        def bert_input_batch_tokenize(\n",
    "            list_of_strings: list[str],\n",
    "        ) -> BertInputBatch:\n",
    "            list_of_strings = [str(e) for e in list_of_strings]\n",
    "            return BertInputBatch.from_batch_encoding(\n",
    "                BERT_TOKENIZER.batch_encode_plus(\n",
    "                    list_of_strings,\n",
    "                    max_length=BERT_TOKENIZER_LENGTH,\n",
    "                    pad_to_max_length=True,\n",
    "                    truncation=True,\n",
    "                    return_token_type_ids=False,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        print(f\"    creating df_product_title_encoded...\")\n",
    "        self.df_product_title_encoded = bert_input_batch_tokenize(\n",
    "            df[\"product_title\"].tolist()\n",
    "        )\n",
    "\n",
    "        print(f\"    creating df_review_title_encoded...\")\n",
    "        self.df_review_title_encoded = bert_input_batch_tokenize(\n",
    "            df[\"review_title\"].tolist()\n",
    "        )\n",
    "\n",
    "        print(f\"    creating df_review_text_encoded...\")\n",
    "        self.df_review_text_encoded = bert_input_batch_tokenize(\n",
    "            df[\"review_text\"].tolist()\n",
    "        )\n",
    "\n",
    "        print(f\"    creating scraped_review_title_encoded...\")\n",
    "        self.scraped_review_title_encoded = bert_input_batch_tokenize(\n",
    "            reviews_scraped[\"review_title\"].tolist()\n",
    "        )\n",
    "\n",
    "        print(f\"    creating scraped_review_text_encoded...\")\n",
    "        self.scraped_review_text_encoded = bert_input_batch_tokenize(\n",
    "            reviews_scraped[\"review_text\"].tolist()\n",
    "        )\n",
    "\n",
    "        review_feature_cols = [\n",
    "            \"rating\",\n",
    "            \"verified\",\n",
    "            \"text_sentiment\",\n",
    "            \"text_subjectivity\",\n",
    "        ]\n",
    "        self.review_feature_vector = torch.tensor(df[review_feature_cols].to_numpy())\n",
    "        self.label_vector = torch.tensor(df[[\"label\"]].to_numpy())\n",
    "        self.scraped_review_feature_vector = torch.tensor(\n",
    "            reviews_scraped[review_feature_cols].to_numpy()\n",
    "        )\n",
    "        self.scraped_review_helpful = torch.reshape(\n",
    "            torch.tensor(reviews_scraped[\"helpful\"].to_numpy()), (M, 1)\n",
    "        )\n",
    "\n",
    "        product_feature_cols = [\n",
    "            \"rating_count\",\n",
    "            \"rating_avg\",\n",
    "            \"rating1\",\n",
    "            \"rating2\",\n",
    "            \"rating3\",\n",
    "            \"rating4\",\n",
    "            \"rating5\",\n",
    "        ] + [f\"cat_{i}\" for i in range(0, 30)]\n",
    "        self.product_feature_vector = torch.tensor(df[product_feature_cols].to_numpy())\n",
    "\n",
    "    def __getitem__(self, index) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        product_id = self.df.loc[index, \"product_id\"]\n",
    "\n",
    "        # get indexes in scraped data where product id is the same\n",
    "        indexes = torch.tensor(\n",
    "            reviews_scraped.index[\n",
    "                reviews_scraped[\"product_id\"] == product_id\n",
    "            ].to_numpy()\n",
    "        )\n",
    "\n",
    "        def slice(tensor: torch.Tensor) -> torch.Tensor:\n",
    "            \"\"\"selects only the subset where index indicates product id is the same\"\"\"\n",
    "            return torch.index_select(tensor, 0, indexes)\n",
    "\n",
    "        def zero_pad_ravel(tensor: torch.Tensor, X) -> torch.Tensor:\n",
    "            \"\"\"takes in a tensor of shape (N,D) appends zero elements or removes elements from the end to create an (X,D) shaped tensor and then reshapes that into a (X*D) shaped tensor\"\"\"\n",
    "            (N, D) = tensor.shape\n",
    "            return torch.reshape(\n",
    "                torch.nn.functional.pad(\n",
    "                    input=tensor[0:X, :],\n",
    "                    pad=(0, 0, 0, max(X - N, 0)),\n",
    "                    mode=\"constant\",\n",
    "                    value=0,\n",
    "                ),\n",
    "                (-1,),\n",
    "            )\n",
    "\n",
    "        # slice the tensors of relevant scraped reviews out of the total reviews:\n",
    "        scraped_helpful = slice(self.scraped_review_helpful)\n",
    "        _N = scraped_helpful.shape[0]  # is N\n",
    "        assert scraped_helpful.shape == (_N, 1)\n",
    "\n",
    "        scraped_review_features = slice(self.scraped_review_feature_vector)\n",
    "        assert scraped_review_features.shape == (_N, 4)\n",
    "\n",
    "        scraped_review_texts_att = slice(\n",
    "            self.scraped_review_text_encoded.attention_mask\n",
    "        )\n",
    "\n",
    "        assert scraped_review_texts_att.shape == (_N, BERT_TOKENIZER_LENGTH)\n",
    "\n",
    "        scraped_review_texts_ids = slice(self.scraped_review_text_encoded.input_ids)\n",
    "        assert scraped_review_texts_ids.shape == (_N, BERT_TOKENIZER_LENGTH)\n",
    "\n",
    "        scraped_review_titles_att = slice(\n",
    "            self.scraped_review_title_encoded.attention_mask\n",
    "        )\n",
    "        assert scraped_review_titles_att.shape == (_N, BERT_TOKENIZER_LENGTH)\n",
    "\n",
    "        scraped_review_titles_ids = slice(self.scraped_review_title_encoded.input_ids)\n",
    "        assert scraped_review_titles_ids.shape == (_N, BERT_TOKENIZER_LENGTH)\n",
    "\n",
    "        # combine all review data into a (X,) shaped tensor:\n",
    "        scraped_block = torch.cat(\n",
    "            (\n",
    "                scraped_helpful,\n",
    "                scraped_review_features,\n",
    "                scraped_review_texts_att,\n",
    "                scraped_review_texts_ids,\n",
    "                scraped_review_titles_att,\n",
    "                scraped_review_titles_ids,\n",
    "            ),\n",
    "            dim=1,\n",
    "        )\n",
    "        scraped_block_flat = zero_pad_ravel(scraped_block, SCRAPED_REVIEW_LIMIT)\n",
    "        assert scraped_block_flat.shape == (\n",
    "            SCRAPED_REVIEW_LIMIT * (1 + 4 + 4 * BERT_TOKENIZER_LENGTH),\n",
    "        )\n",
    "\n",
    "        product_title_bert_input_att = self.df_product_title_encoded[index][\n",
    "            \"attention_mask\"\n",
    "        ][0, :]\n",
    "        assert product_title_bert_input_att.shape == (BERT_TOKENIZER_LENGTH,)\n",
    "        product_title_bert_input_ids = self.df_product_title_encoded[index][\n",
    "            \"input_ids\"\n",
    "        ][0, :]\n",
    "        assert product_title_bert_input_ids.shape == (BERT_TOKENIZER_LENGTH,)\n",
    "        review_title_bert_input_att = self.df_review_title_encoded[index][\n",
    "            \"attention_mask\"\n",
    "        ][0, :]\n",
    "        assert review_title_bert_input_att.shape == (BERT_TOKENIZER_LENGTH,)\n",
    "        review_title_bert_input_ids = self.df_review_title_encoded[index][\"input_ids\"][\n",
    "            0, :\n",
    "        ]\n",
    "        assert review_title_bert_input_ids.shape == (BERT_TOKENIZER_LENGTH,)\n",
    "        review_text_bert_input_att = self.df_review_text_encoded[index][\n",
    "            \"attention_mask\"\n",
    "        ][0, :]\n",
    "        assert review_text_bert_input_att.shape == (BERT_TOKENIZER_LENGTH,)\n",
    "        review_text_bert_input_ids = self.df_review_text_encoded[index][\"input_ids\"][\n",
    "            0, :\n",
    "        ]\n",
    "        assert review_text_bert_input_ids.shape == (BERT_TOKENIZER_LENGTH,)\n",
    "\n",
    "        product_features = self.product_feature_vector[index]  # shape: (37)\n",
    "        assert product_features.shape == (37,)\n",
    "\n",
    "        review_features = self.review_feature_vector[index]  # shape: (4)\n",
    "        assert review_features.shape == (4,)\n",
    "\n",
    "        catted = torch.cat(\n",
    "            (\n",
    "                product_features,\n",
    "                review_features,\n",
    "                product_title_bert_input_att,\n",
    "                product_title_bert_input_ids,\n",
    "                review_title_bert_input_att,\n",
    "                review_title_bert_input_ids,\n",
    "                review_text_bert_input_att,\n",
    "                review_text_bert_input_ids,\n",
    "                scraped_block_flat,\n",
    "            ),\n",
    "            dim=0,\n",
    "        )\n",
    "        assert catted.shape == (PACKED_DATASET_ROW_SIZE,)\n",
    "        ##############################################################\n",
    "        ## Data layout in the catted tensor row, assuming BERT_TOKENIZER_LENGTH = 256 and SCRAPED_REVIEW_LIMIT = 10\n",
    "        ## | 37 | 4 | 256+256 | 256+256 | 256+256 | 10 * ( | 1 | 4 | 256+256 | 256+256 |)\n",
    "\n",
    "        label = self.label_vector[index]\n",
    "        return (catted, label)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.df.__len__()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### unpacking functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_dataset_items(packed_batch_tensor: torch.Tensor):\n",
    "    \"\"\"\n",
    "    expects packed_batch_tensor to be of shape\n",
    "    \"\"\"\n",
    "    assert packed_batch_tensor.shape[1] == PACKED_DATASET_ROW_SIZE\n",
    "    (B, T) = packed_batch_tensor.shape\n",
    "\n",
    "    c: int = 0\n",
    "\n",
    "    def next(n: int) -> torch.Tensor:\n",
    "        nonlocal c\n",
    "        slice = packed_batch_tensor[:, c : c + n]\n",
    "        c += n\n",
    "        return slice\n",
    "\n",
    "    product_features = next(37)\n",
    "    assert product_features.shape == (B, 37)\n",
    "\n",
    "    review_features = next(4)\n",
    "    assert review_features.shape == (B, 4)\n",
    "\n",
    "    product_title_bert_input_att = next(BERT_TOKENIZER_LENGTH)\n",
    "    product_title_bert_input_ids = next(BERT_TOKENIZER_LENGTH)\n",
    "    review_title_bert_input_att = next(BERT_TOKENIZER_LENGTH)\n",
    "    review_title_bert_input_ids = next(BERT_TOKENIZER_LENGTH)\n",
    "    review_text_bert_input_att = next(BERT_TOKENIZER_LENGTH)\n",
    "    review_text_bert_input_ids = next(BERT_TOKENIZER_LENGTH)\n",
    "    assert (\n",
    "        product_title_bert_input_att.shape\n",
    "        == product_title_bert_input_ids.shape\n",
    "        == review_title_bert_input_att.shape\n",
    "        == review_title_bert_input_ids.shape\n",
    "        == review_text_bert_input_att.shape\n",
    "        == review_text_bert_input_ids.shape\n",
    "        == (B, BERT_TOKENIZER_LENGTH)\n",
    "    )\n",
    "\n",
    "    _scraped_block_flat = next(\n",
    "        SCRAPED_REVIEW_LIMIT * (1 + 4 + 4 * BERT_TOKENIZER_LENGTH)\n",
    "    )\n",
    "    assert _scraped_block_flat.shape == (\n",
    "        B,\n",
    "        SCRAPED_REVIEW_LIMIT * (1 + 4 + 4 * BERT_TOKENIZER_LENGTH),\n",
    "    )\n",
    "\n",
    "    scraped_block = torch.reshape(\n",
    "        _scraped_block_flat,\n",
    "        (B, SCRAPED_REVIEW_LIMIT, (1 + 4 + 4 * BERT_TOKENIZER_LENGTH)),\n",
    "    )\n",
    "    assert scraped_block.shape == (\n",
    "        B,\n",
    "        SCRAPED_REVIEW_LIMIT,\n",
    "        (1 + 4 + 4 * BERT_TOKENIZER_LENGTH),\n",
    "    )\n",
    "\n",
    "    scraped_helpful = scraped_block[:, :, 0:1]\n",
    "    assert scraped_helpful.shape == (B, SCRAPED_REVIEW_LIMIT, 1)\n",
    "\n",
    "    scraped_review_features = scraped_block[:, :, 1:5]\n",
    "    assert scraped_review_features.shape == (B, SCRAPED_REVIEW_LIMIT, 4)\n",
    "\n",
    "    scraped_review_title_bert_input_att = scraped_block[\n",
    "        :, :, 5 : 5 + BERT_TOKENIZER_LENGTH\n",
    "    ]\n",
    "    scraped_review_title_bert_input_ids = scraped_block[\n",
    "        :, :, 5 + BERT_TOKENIZER_LENGTH : 5 + 2 * BERT_TOKENIZER_LENGTH\n",
    "    ]\n",
    "    scraped_review_text_bert_input_att = scraped_block[\n",
    "        :, :, 5 + 2 * BERT_TOKENIZER_LENGTH : 5 + 3 * BERT_TOKENIZER_LENGTH\n",
    "    ]\n",
    "    scraped_review_text_bert_input_ids = scraped_block[\n",
    "        :, :, 5 + 3 * BERT_TOKENIZER_LENGTH : 5 + 4 * BERT_TOKENIZER_LENGTH\n",
    "    ]\n",
    "\n",
    "    return (\n",
    "        product_features,\n",
    "        review_features,\n",
    "        product_title_bert_input_att,\n",
    "        product_title_bert_input_ids,\n",
    "        review_title_bert_input_ids,\n",
    "        review_title_bert_input_ids,\n",
    "        review_text_bert_input_att,\n",
    "        review_text_bert_input_ids,\n",
    "        (\n",
    "            scraped_helpful,\n",
    "            scraped_review_features,\n",
    "            scraped_review_title_bert_input_att,\n",
    "            scraped_review_title_bert_input_ids,\n",
    "            scraped_review_text_bert_input_att,\n",
    "            scraped_review_text_bert_input_ids,\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import torch.nn as nn\n",
    "def create_mlp(layer_sizes: list[int]) -> nn.Sequential:\n",
    "    \"\"\"\n",
    "    args:\n",
    "        layer_sizes: [input_dim, h1_dim, h2_dim, ...., out_dim]\"\"\"\n",
    "    assert layer_sizes.__len__() >= 2\n",
    "        \n",
    "    layers = []\n",
    "    for i in range(1, layer_sizes.__len__()+1):\n",
    "        layers.append((f\"hidden_layer_{i}\",nn.Linear(layer_sizes[i-1], layer_sizes[i+1]) ))\n",
    "        layers.append((f\"activation_{i}\",  nn.ReLU()))\n",
    "    return nn.Sequential(OrderedDict(layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewEncodingModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, freeze: bool = True, outdim=500) -> None:\n",
    "        self.bert = BertModel(BERT_CONFIG)\n",
    "        if freeze:\n",
    "            for param in self.bert.parameters():\n",
    "                param.requires_grad = False\n",
    "        self.out_mlp = create_mlp([BERT_EMBEDDING_SIZE*2+4, outdim])\n",
    "    \n",
    "    def forward(self, review_features: torch.Tensor, \n",
    "               review_title_bert_input_att: torch.Tensor,\n",
    "               review_title_bert_input_ids: torch.Tensor,\n",
    "               review_text_bert_input_att: torch.Tensor,\n",
    "               review_text_bert_input_ids: torch.Tensor, ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        args:\n",
    "            review_features: shape: (BATCH_SIZE, 5)\n",
    "            review_title_bert_input_att: shape: (BATCH_SIZE, BERT_TOKENIZER_LENGTH)\n",
    "            review_title_bert_input_ids: shape: (BATCH_SIZE, BERT_TOKENIZER_LENGTH)\n",
    "            review_text_bert_input_att: shape: (BATCH_SIZE, BERT_TOKENIZER_LENGTH)\n",
    "            review_text_bert_input_ids: shape: (BATCH_SIZE, BERT_TOKENIZER_LENGTH)\n",
    "        returns:\n",
    "            torch.Tensor of shape (BATCH_SIZE, OUTDIM)\n",
    "        \"\"\"\n",
    "\n",
    "        # max over all tokens in every dimension of the 768 dimensional embedding\n",
    "        bert_title_embedding = torch.max(self.bert(attention_mask=review_title_bert_input_att, input_ids=review_title_bert_input_ids), dim=1)\n",
    "        assert bert_title_embedding.shape == (BATCH_SIZE, BERT_EMBEDDING_SIZE)\n",
    "\n",
    "        # max over all tokens in every dimension of the 768 dimensional embedding\n",
    "        bert_text_embedding = torch.max(self.bert(attention_mask=review_text_bert_input_att, input_ids=review_text_bert_input_ids), dim=1)\n",
    "        assert bert_title_embedding.shape == (BATCH_SIZE, BERT_EMBEDDING_SIZE)\n",
    "\n",
    "        # concat all on top of each other:\n",
    "        catted = torch.cat([bert_title_embedding, bert_text_embedding, review_features], dim=1)\n",
    "\n",
    "        # apply linear layer and relu:\n",
    "        return self.out_mlp(catted)\n",
    "\n",
    "        \n",
    "    def freeze_bert(self, freezed: bool) -> None:\n",
    "        for param in self.bert.parameters():\n",
    "                param.requires_grad =  not freezed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "REVIEW_ENCODING_MODEL_OUTDIM = 149\n",
    "# REVIEW_ENCODING_MODEL_OUTDIM + 1 has to be divisible by 3 for this to work, bc. we use 3 attention heads\n",
    "\n",
    "\n",
    "class FakeDetectionModelParameters:\n",
    "\n",
    "    review_encoding_model: ReviewEncodingModel\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.review_encoding_model: ReviewEncodingModel = ReviewEncodingModel(\n",
    "            freeze=True, outdim=REVIEW_ENCODING_MODEL_OUTDIM\n",
    "        )\n",
    "        self.scraped_reviews_transformer = torch.nn.TransformerEncoderLayer(\n",
    "            d_model=REVIEW_ENCODING_MODEL_OUTDIM+1, nhead=3, batch_first=True\n",
    "        )\n",
    "\n",
    "        LAST_FEATURES_DIM = 37 + (REVIEW_ENCODING_MODEL_OUTDIM + 1) + REVIEW_ENCODING_MODEL_OUTDIM +  BERT_EMBEDDING_SIZE\n",
    "        # LAST_FEATURES_DIM: product features + transformer output dimension + review encoded + bert embedding from product title\n",
    "        self.outmlp = create_mlp([LAST_FEATURES_DIM, 30, 20, 1])\n",
    "\n",
    "\n",
    "class FakeDetectionModel(torch.nn.Module):\n",
    "    def __init__(self, parameters: FakeDetectionModelParameters):\n",
    "        pass\n",
    "\n",
    "    def forward(self, packed_dataset_rows: torch.Tensor)-> torch.Tensor :\n",
    "        \"\"\" \"\n",
    "        args:\n",
    "            packed_dataset_row: torch.Tensor with shape (BATCH_SIZE, PACKED_DATASET_ROW_SIZE)\n",
    "        returns:\n",
    "            torch.Tensor with shape: (BATCH_SIZE,1)\n",
    "        \"\"\"\n",
    "        assert packed_dataset_rows.shape == (BATCH_SIZE, PACKED_DATASET_ROW_SIZE)\n",
    "        (\n",
    "            product_features,\n",
    "            review_features,\n",
    "            product_title_bert_input_att,\n",
    "            product_title_bert_input_ids,\n",
    "            review_title_bert_input_att,\n",
    "            review_title_bert_input_ids,\n",
    "            review_text_bert_input_att,\n",
    "            review_text_bert_input_ids,\n",
    "            (\n",
    "                scraped_helpful,\n",
    "                scraped_review_features,\n",
    "                scraped_review_title_bert_input_att,\n",
    "                scraped_review_title_bert_input_ids,\n",
    "                scraped_review_text_bert_input_att,\n",
    "                scraped_review_text_bert_input_ids,\n",
    "            ),\n",
    "        ) = unpack_dataset_items(packed_dataset_rows)\n",
    "\n",
    "        ### CREATE REVIEW ENCODING\n",
    "        review_encoding = self.review_encoding_model(review_features, review_title_bert_input_att, review_title_bert_input_ids, review_text_bert_input_att, review_text_bert_input_ids)  # type: ignore\n",
    "        assert review_encoding.shape == (BATCH_SIZE, REVIEW_ENCODING_MODEL_OUTDIM)\n",
    "\n",
    "        ### CREATE REVIEW ENCODINGS FOR ALL SCRAPED REVIEWS\n",
    "        ### THEN COMBINE THEM AND THEIR HELPFULNESS VIA THE TRANSFORMER\n",
    "\n",
    "        # transform (BATCH_SIZE, SCRAPED_REVIEW_LIMIT, 5 + 4 * BERT_TOKENIZER_LENGTH) into (BATCH_SIZE, SCRAPED_REVIEW_LIMIT, REVIEW_ENCODING_MODEL_OUTDIM)\n",
    "        transformer_input = torch.zeros(\n",
    "            (BATCH_SIZE, SCRAPED_REVIEW_LIMIT, 3 + REVIEW_ENCODING_MODEL_OUTDIM)\n",
    "        )\n",
    "        for i in range(SCRAPED_REVIEW_LIMIT):\n",
    "            transformer_input[:, i, :] = torch.cat(\n",
    "            [self.review_encoding_model(\n",
    "                scraped_review_features[:, i, :],\n",
    "                scraped_review_title_bert_input_att[:, i, :],\n",
    "                scraped_review_title_bert_input_ids[:, i, :],\n",
    "                scraped_review_text_bert_input_att[:, i, :],\n",
    "                scraped_review_text_bert_input_ids[:, i, :],\n",
    "            ), scraped_helpful], dim=1 )# type: ignore\n",
    "        # REVIEW_ENCODING_MODEL_OUTDIM + 1 has to be divisible by 3 for this to work, bc. we use 3 attention heads\n",
    "             \n",
    "        transformer_output = self.scraped_reviews_transformer(transformer_input) # type: ignore\n",
    "        assert transformer_output.shape == (BATCH_SIZE, REVIEW_ENCODING_MODEL_OUTDIM)\n",
    "\n",
    "        ### CREATE BERT EMBEDDING FOR PRODUCT TITLE\n",
    "        bert_product_title_embedding = self.review_encoding_model.bert(attention_mask=product_title_bert_input_att, input_ids=product_title_bert_input_ids) # type: ignore\n",
    "        assert bert_product_title_embedding.shape == (BATCH_SIZE, BERT_EMBEDDING_SIZE)\n",
    "        # linear layer connection all\n",
    "\n",
    "        ### COMBINE PRODUCT INFORMATION (features + title), CONTEXT (other review's encodings and their helpfulness) and REVIEW ENCODING into a single scalar: the real vs. fake prediction\n",
    "        catted = torch.cat([product_features, review_encoding, bert_product_title_embedding],dim=1)\n",
    "        return torch.sigmoid(self.outmlp(catted)) # type: ignore"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating ReviewsDataSet (real/fake reviews: N=100, context reviews: M=200\n",
      "    bert tokeinzer working...\n",
      "    creating df_product_title_encoded...\n",
      "    creating df_review_title_encoded...\n",
      "    creating df_review_text_encoded...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tadeo\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2336: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    creating scraped_review_title_encoded...\n",
      "    creating scraped_review_text_encoded...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = ReviewsDataSet(df, reviews_scraped)\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 10, 1]) torch.Size([8, 10, 1029])\n"
     ]
    }
   ],
   "source": [
    "for (input, labels) in dataloader:\n",
    "    ( product_features,\n",
    "        review_features,\n",
    "        product_title_bert_input_att,\n",
    "        product_title_bert_input_ids,\n",
    "        review_title_bert_input_ids,\n",
    "        review_title_bert_input_ids,\n",
    "        review_text_bert_input_att,\n",
    "        review_text_bert_input_ids,\n",
    "        scraped_block ) = unpack_dataset_items(input)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "780e02f01b3ae00d5e97f14df45fcdece40e9a09f09f224add9952588133a4cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
