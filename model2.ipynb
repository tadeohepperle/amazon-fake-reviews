{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The blackcellmagic extension is already loaded. To reload it, use:\n",
      "  %reload_ext blackcellmagic\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import typing\n",
    "import transformers\n",
    "from transformers import TFAutoModel, AutoTokenizer, BertTokenizer\n",
    "%load_ext blackcellmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"data/transformed/df.csv\",\n",
    "    dtype={\n",
    "        \"product_title\": str,\n",
    "        \"review_title\": str,\n",
    "        \"review_text\": str,\n",
    "        \"product_id\": str,\n",
    "    },\n",
    ")\n",
    "reviews_scraped = pd.read_csv(\n",
    "    \"data/transformed/reviews_scraped.csv\",\n",
    "    dtype={\"review_title\": str, \"review_text\": str, \"product_id\": str},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH_BERT_TOKENIZER: int = 512\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "BERT_TOKENIZER = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import List\n",
    "from typing import TypedDict\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "class BertInput(TypedDict):\n",
    "    attention_mask: torch.Tensor\n",
    "    input_ids: torch.Tensor\n",
    "\n",
    "\n",
    "class BertInputBatch:\n",
    "    def __init__(self, attention_mask: torch.Tensor, input_ids: torch.Tensor) -> None:\n",
    "        self.attention_mask = attention_mask\n",
    "        self.input_ids = input_ids\n",
    "\n",
    "    @staticmethod\n",
    "    def from_batch_encoding(\n",
    "        batch_encoding: transformers.tokenization_utils_base.BatchEncoding,\n",
    "    ):\n",
    "        return BertInputBatch(\n",
    "            torch.tensor(batch_encoding[\"attention_mask\"]),\n",
    "            torch.tensor(batch_encoding[\"input_ids\"]),\n",
    "        )\n",
    "\n",
    "    attention_mask: torch.Tensor\n",
    "    input_ids: torch.Tensor\n",
    "\n",
    "    @property\n",
    "    def shape(self) -> torch.Size:\n",
    "        return self.input_ids.shape\n",
    "\n",
    "    def __getitem__(self, i: int) -> BertInput:\n",
    "        return {\n",
    "            \"attention_mask\": self.attention_mask[i, :],\n",
    "            \"input_ids\": self.input_ids[i, :],\n",
    "        }\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ReviewDataSetItem(TypedDict):\n",
    "    \"\"\"one fake/real review with X context reviews from the same product\"\"\"\n",
    "\n",
    "    product_title_bert_input: BertInput\n",
    "    review_title_bert_input: BertInput\n",
    "    review_text_bert_input: BertInput\n",
    "\n",
    "    review_features: torch.Tensor\n",
    "    \"\"\"shape: (4)    Rating [1-5; 1] + Verified Purchase [0-1; 1] + SA Valence + Subjectivity [0.0-1.0; 2]\"\"\"\n",
    "\n",
    "    product_features: torch.Tensor\n",
    "    \"\"\"shape: (37)    Ratings (1-5) Ratio [0.0-1.0]; 5] + Rating Avg [f64; 1] + Rating Count [u64; 1] + Category [u64; 30]\"\"\"\n",
    "\n",
    "    scraped_review_features: torch.Tensor\n",
    "    \"\"\"shape: (X, 4)    Rating [1-5; 1] + Verified Purchase [0-1; 1] + SA Valence + Subjectivity [0.0-1.0; 2]\"\"\"\n",
    "\n",
    "    scraped_helpful: torch.Tensor\n",
    "    \"\"\"shape: (X, 1)    Helpfulness [u64; 1]\"\"\"\n",
    "\n",
    "    scraped_review_texts: BertInputBatch\n",
    "\n",
    "    scraped_review_titles: BertInputBatch\n",
    "\n",
    "\n",
    "class ReviewsDataSet(Dataset):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        df: pd.DataFrame of size M with columns:\n",
    "            - rating (1-5)\n",
    "            - verified (0-1)\n",
    "            - product_id (str)\n",
    "            - review_title (str)\n",
    "            - review_text (str)\n",
    "            - cat_0 - cat_29 (0-1)\n",
    "            - label (0-1)\n",
    "            - text_sentiment (0.0-1.0)\n",
    "            - text_subjectivity (0.0-1.0)\n",
    "            - rating_count (u64)\n",
    "            - rating_avg (1.0-5.0)\n",
    "            - rating1 - rating5  (0.0-1.0)\n",
    "            - product_title (str)\n",
    "\n",
    "        reviews_scraped:  pd.DataFrame of size N with columns:\n",
    "            - product_id (str)\n",
    "            - review_title (str)\n",
    "            - review_text (str)\n",
    "            - helpful (u64)\n",
    "            - verified (0-1)\n",
    "            - rating (1-5)\n",
    "            - text_sentiment (0.0-1.0)\n",
    "            - text_subjectivity (0.0-1.0)\n",
    "    \"\"\"\n",
    "\n",
    "    df: pd.DataFrame\n",
    "    reviews_scraped: pd.DataFrame\n",
    "\n",
    "    df_product_title_encoded: BertInputBatch\n",
    "    \"\"\"shape: (N, MAX_SEQUENCE_LENGTH_BERT_TOKENIZER)\"\"\"\n",
    "\n",
    "    df_review_title_encoded: BertInputBatch\n",
    "    \"\"\"shape: (N, MAX_SEQUENCE_LENGTH_BERT_TOKENIZER)\"\"\"\n",
    "\n",
    "    df_review_text_encoded: BertInputBatch\n",
    "    \"\"\"shape: (N, MAX_SEQUENCE_LENGTH_BERT_TOKENIZER)\"\"\"\n",
    "\n",
    "    review_feature_vector: torch.Tensor\n",
    "    \"\"\"shape: (N, 4)    Rating [1-5; 1] + Verified Purchase [0-1; 1] + SA Valence + Subjectivity [0.0-1.0; 2]\"\"\"\n",
    "\n",
    "    product_feature_vector: torch.Tensor\n",
    "    \"\"\"shape: (N, 37)    Ratings (1-5) Ratio [0.0-1.0]; 5] + Rating Avg [f64; 1] + Rating Count [u64; 1] + Category [u64; 30]\"\"\"\n",
    "\n",
    "    scraped_review_feature_vector: torch.Tensor\n",
    "    \"\"\"shape: (M, 4)    Rating [1-5; 1] + Verified Purchase [0-1; 1] + SA Valence + Subjectivity [0.0-1.0; 2]\"\"\"\n",
    "\n",
    "    scraped_review_helpful: torch.Tensor\n",
    "    \"\"\"shape: (M, 1)    Helpfulness [u64; 1]\"\"\"\n",
    "\n",
    "    scraped_review_title_encoded: BertInputBatch\n",
    "    \"\"\"shape: (M, MAX_SEQUENCE_LENGTH_BERT_TOKENIZER)\"\"\"\n",
    "\n",
    "    scraped_review_text_encoded: BertInputBatch\n",
    "    \"\"\"shape: (M, MAX_SEQUENCE_LENGTH_BERT_TOKENIZER)\"\"\"\n",
    "\n",
    "    # product_id_indexes_map: dict[str, list[int]]\n",
    "    # \"\"\"For each product, maps the product id to the int indices for all scraped context reviews for this product\"\"\"\n",
    "\n",
    "    def __init__(self, df, reviews_scraped):\n",
    "\n",
    "        # use bert tokenizer to tokenize all strings of the\n",
    "        print(\n",
    "            f\"creating ReviewsDataSet (real/fake reviews: N={len(df)}, context reviews: M={len(reviews_scraped)}\"\n",
    "        )\n",
    "        print(f\"    bert tokeinzer working...\")\n",
    "        def bert_input_batch_tokenize(\n",
    "            list_of_strings: list[str],\n",
    "        ) -> BertInputBatch:\n",
    "            return BertInputBatch.from_batch_encoding(\n",
    "                BERT_TOKENIZER.batch_encode_plus(\n",
    "                    list_of_strings,\n",
    "                    max_length=MAX_SEQUENCE_LENGTH_BERT_TOKENIZER,\n",
    "                    pad_to_max_length=True,\n",
    "                    truncation=True,\n",
    "                    return_token_type_ids=False,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # print(f\"    creating df_product_title_encoded...\")\n",
    "        # self.df_product_title_encoded = bert_input_batch_tokenize(\n",
    "        #     df[\"product_title\"].tolist()\n",
    "        # )\n",
    "\n",
    "        # print(f\"    creating df_review_title_encoded...\")\n",
    "        # self.df_review_title_encoded = bert_input_batch_tokenize(\n",
    "        #     df[\"review_title\"].tolist()\n",
    "        # )\n",
    "\n",
    "        # print(f\"    creating df_review_text_encoded...\")\n",
    "        # self.df_review_text_encoded = bert_input_batch_tokenize(\n",
    "        #     df[\"review_text\"].tolist()\n",
    "        # )\n",
    "\n",
    "        # print(f\"    creating scraped_review_title_encoded...\")\n",
    "        # self.scraped_review_title_encoded = bert_input_batch_tokenize(\n",
    "        #     reviews_scraped[\"review_title\"].tolist()\n",
    "        # )\n",
    "\n",
    "        print(f\"    creating scraped_review_text_encoded...\")\n",
    "        self.scraped_review_text_encoded = bert_input_batch_tokenize(\n",
    "            reviews_scraped[\"review_text\"].tolist()\n",
    "        )\n",
    "        return\n",
    "\n",
    "        review_feature_cols = [\n",
    "            \"rating\",\n",
    "            \"verified\",\n",
    "            \"text_sentiment\",\n",
    "            \"text_subjectivity\",\n",
    "        ]\n",
    "        self.review_feature_vector = torch.tensor(df[review_feature_cols])\n",
    "        self.scraped_review_feature_vector = torch.tensor(\n",
    "            reviews_scraped[review_feature_cols]\n",
    "        )\n",
    "        self.scraped_review_helpfulness = torch.tensor(reviews_scraped[\"helpful\"])\n",
    "\n",
    "        product_feature_cols = [\n",
    "            \"rating_count\",\n",
    "            \"rating_avg\",\n",
    "            \"rating1\",\n",
    "            \"rating2\",\n",
    "            \"rating3\",\n",
    "            \"rating4\",\n",
    "            \"rating5\",\n",
    "        ] + [f\"cat_{i}\" for i in range(0, 30)]\n",
    "        self.product_feature_vector = torch.tensor(df[product_feature_cols])\n",
    "\n",
    "    def __getitem__(self, index) -> ReviewDataSetItem:\n",
    "        product_id: str = df[index][\"product_id\"]\n",
    "\n",
    "        # get indexes in scraped data where product id is the same\n",
    "        indexes = torch.tensor(\n",
    "            reviews_scraped.index[reviews_scraped[\"product_id\"] == product_id].tolist()\n",
    "        )\n",
    "\n",
    "        def slice(tensor: torch.Tensor) -> torch.Tensor:\n",
    "            \"\"\"selects only the subset where index indicates product id is the same\"\"\"\n",
    "            return torch.index_select(tensor, 0, indexes)\n",
    "\n",
    "        scraped_helpful = slice(self.scraped_review_helpful)\n",
    "        scraped_review_features = slice(self.scraped_review_feature_vector)\n",
    "\n",
    "        scraped_review_texts_att = slice(\n",
    "            self.scraped_review_text_encoded.attention_mask\n",
    "        )\n",
    "        scraped_review_texts_ids = slice(self.scraped_review_text_encoded.input_ids)\n",
    "        scraped_review_texts = BertInputBatch(\n",
    "            scraped_review_texts_att, scraped_review_texts_ids\n",
    "        )\n",
    "\n",
    "        scraped_review_titles_att = slice(\n",
    "            self.scraped_review_title_encoded.attention_mask\n",
    "        )\n",
    "        scraped_review_titles_ids = slice(self.scraped_review_title_encoded.input_ids)\n",
    "        scraped_review_titles = BertInputBatch(\n",
    "            scraped_review_titles_att, scraped_review_titles_ids\n",
    "        )\n",
    "\n",
    "        return ReviewDataSetItem(\n",
    "            product_title_bert_input=self.df_product_title_encoded[index],\n",
    "            review_text_bert_input=self.df_review_text_encoded[index],\n",
    "            review_title_bert_input=self.df_review_title_encoded[index],\n",
    "            product_features=self.product_feature_vector[index],\n",
    "            review_features=self.review_feature_vector[index],\n",
    "            scraped_helpful=scraped_helpful,\n",
    "            scraped_review_features=scraped_review_features,\n",
    "            scraped_review_texts=scraped_review_texts,\n",
    "            scraped_review_titles=scraped_review_titles,\n",
    "        )\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.df.__len__()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example DatasetClass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "# dataset = ReviewsDataSet(df, reviews_scraped)\n",
    "# # df[\"product_title\"].tolist()\n",
    "for o in reviews_scraped[\"review_text\"].tolist():\n",
    "    if(type(o) != str):\n",
    "        print(o)\n",
    "    else:\n",
    "        print(\"ashdsadds\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = DataLoader(dataset = train, batch_size = 2, shuffle = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeDetectionModelParameters():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "class FakeDetectionModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, parameters: FakeDetectionModelParameters):\n",
    "        pass\n",
    "\n",
    "    def forward(self, df_row):\n",
    "        \"\"\"\"\n",
    "            row_in_fake_real_products_df is a df with the following columns:\n",
    "                - product_title\n",
    "                - review_title\n",
    "                - rating1, rating2, rating3, rating4, rating5 (the percentages of ratings from each brackets, as values between 0.0 and 1.0)\n",
    "                - \n",
    "        \"\"\"\n",
    "        pass\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "780e02f01b3ae00d5e97f14df45fcdece40e9a09f09f224add9952588133a4cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
